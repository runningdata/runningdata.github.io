
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <script type="text/javascript">
    (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
    })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');
    
    _st('install','yNiKTKaAnwd1uuxVMfiE','2.0.0');
  </script>
  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?5b99dfd487346155d274c0c49c3fb869";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
  </script>

  
    <title>Will&#39;s Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Will Chen">
    

    
    <meta name="description" content="左右水色 右手天光">
<meta property="og:type" content="website">
<meta property="og:title" content="Will's Blog">
<meta property="og:url" content="https://runningdata.github.io/page/10/index.html">
<meta property="og:site_name" content="Will's Blog">
<meta property="og:description" content="左右水色 右手天光">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Will's Blog">
<meta name="twitter:description" content="左右水色 右手天光">

    
    <link rel="alternative" href="/atom.xml" title="Will&#39;s Blog" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="Will&#39;s Blog" title="Will&#39;s Blog"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Will&#39;s Blog">Will&#39;s Blog</a></h1>
				<h2 class="blog-motto">简易 变易 不易</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">首页</a></li>
					
						<li><a href="/archives">归档</a></li>
					
						<li><a href="/about">关于</a></li>
					
					<li>
 					
                                                <form class="search" action="/search/index.html" method="get" accept-charset="utf-8" target="_blank">
                                                        <label>搜索</label>
                                                <input name="s" type="hidden" value= null ><input type="text" name="q" size="30" placeholder="搜索"><br>
                                                </form>
					
					</li>
				</ul>
			</nav>			
</div>

    </header>
    <div id="container">
      <div id="main">

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/07/03/RunningData执行用户迁移计划/" title="RunningData执行用户迁移计划" itemprop="url">RunningData执行用户迁移计划</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-07-03T06:41:20.000Z" itemprop="datePublished"> 发表于 2017-07-03</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="超级用户准备"><a href="#超级用户准备" class="headerlink" title="超级用户准备"></a>超级用户准备</h2><ul>
<li>jlc</li>
<li>wplan</li>
<li>xiaov</li>
</ul>
<h2 id="文件权限"><a href="#文件权限" class="headerlink" title="文件权限"></a>文件权限</h2><h4 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h4><ul>
<li>所有数仓调整owner为所在事业部的超级用户<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">hdfs dfs -chown jlc:jlc -R /log/statistics</div><div class="line"></div><div class="line"></div><div class="line">hdfs dfs -ls /apps/hive/warehouse/ | awk &apos;&#123;print(&quot;hdfs dfs -chown -R &quot;, $4, &quot;:&quot;,$4, $8)&#125;&apos;</div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="本地"><a href="#本地" class="headerlink" title="本地"></a>本地</h4><table>
<thead>
<tr>
<th>名称</th>
<th>位置</th>
<th>操作q</th>
</tr>
</thead>
<tbody>
<tr>
<td>sqoop目录权限</td>
<td>/server/app/sqoop</td>
<td>rm -vfr /server/app/sqoop/vo</td>
</tr>
<tr>
<td></td>
<td></td>
<td>/server/metamap/metamap_django</td>
<td>/server/metamap/metamap_django/*.java</td>
</tr>
</tbody>
</table>
<h2 id="azkaban执行用户"><a href="#azkaban执行用户" class="headerlink" title="azkaban执行用户"></a>azkaban执行用户</h2><ul>
<li>sqoop</li>
<li>hive</li>
</ul>
<p>需要修改M2H，H2H，H2M以及新版本的generate_job_file里的执行用户，包含两个地方</p>
<ul>
<li>生成执行脚本</li>
<li>生成命令【测试执行】</li>
</ul>
<p>在settings文件中添加参数USE_ROOT</p>
<h2 id="jenkins调度"><a href="#jenkins调度" class="headerlink" title="jenkins调度"></a>jenkins调度</h2><p>资产匹配问题: 62远程调用106上的脚步任务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Message from syslogd@datanode17 at Jul  3 15:50:52 ...</div><div class="line"> kernel:BUG: soft lockup - CPU#7 stuck for 67s! [python:2708]</div></pre></td></tr></table></figure></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/06/26/关于kylin分时段merge之后体积变小/" title="关于kylin分时段merge之后体积变小" itemprop="url">关于kylin分时段merge之后体积变小</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-06-26T11:01:24.000Z" itemprop="datePublished"> 发表于 2017-06-26</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>我们设置了一个cube，指定的mandatory dimension为create_year，问了一下，说是因为有按照年去查询指标的需求。</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>mandatory dimension: create_year</p>
<p>自动merge : 7天、28天</p>
<h2 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h2><p>merge之前单天的数据大小平均为3G，而单周的数据大小平均为11G。</p>
<p>就是说： <strong>merge完之后数据变小了</strong>！</p>
<p>那么为什么呢？</p>
<p>几个人想了好半天，终于有个同事想到了….就是因为对于不包含merge时间【一般是天】的所有其他维度的组合，都减少了6倍的大小。</p>
<p>那么，由此延伸，我们是可以将create_day设置为mandatory dimension的，这样每天的cube就会减少很多大小，merge以后也不会有对应的压缩。这样对于单天记录的体积会有很大压缩提升。。。</p>
<p>那么对于年指标的查询应该怎样处理呢？由于这种比较少，建议可以前端解决。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/06/25/hbase频繁挂掉/" title="hbase频繁挂掉" itemprop="url">hbase频繁挂掉</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-06-25T01:57:58.000Z" itemprop="datePublished"> 发表于 2017-06-25</time>
    
  </p>
</header>
    <div class="article-content">
        
        <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">2017-06-25 09:42:34,262 ERROR [RS_OPEN_REGION-datanode20:16020-0] coprocessor.CoprocessorHost: The coprocessor org.apache.kylin.stora</div><div class="line">ge.hbase.cube.v2.coprocessor.endpoint.CubeVisitService threw org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyExcep</div><div class="line">tion): Operation category READ is not supported in state standby</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line">2017-06-25 09:42:34,336 FATAL [RS_OPEN_REGION-datanode20:16020-2] regionserver.HRegionServer: ABORTING region server datanode20.yinke</div><div class="line">r.com,16020,1498354685968: The coprocessor org.apache.kylin.storage.hbase.cube.v1.coprocessor.observer.AggregateRegionObserver threw </div><div class="line">org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state stan</div><div class="line">dby</div><div class="line"></div><div class="line"></div><div class="line">2017-06-25 09:42:34,336 FATAL [RS_OPEN_REGION-datanode20:16020-2] regionserver.HRegionServer: RegionServer abort: loaded coprocessors are: [org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint]</div><div class="line"></div><div class="line"></div><div class="line">2017-06-25 09:42:34,338 FATAL [RS_OPEN_REGION-datanode20:16020-0] regionserver.HRegionServer: ABORTING region server datanode20.will.com,16020,1498354685968: The coprocessor org.apache.kylin.storage.hbase.cube.v1.coprocessor.observer.AggregateRegionObserver threw org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby</div><div class="line"></div><div class="line"></div><div class="line">2017-06-25 09:42:34,370 INFO  [RS_OPEN_REGION-datanode20:16020-1] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.k</div><div class="line">ylin.storage.hbase.cube.v2.coprocessor.endpoint.CubeVisitService from HTD of KYLIN_4L40B34P11 successfully.</div><div class="line">2017-06-25 09:42:34,379 ERROR [RS_OPEN_REGION-datanode20:16020-2] handler.OpenRegionHandler: Failed open of region=KYLIN_HBWCQ5ZQR1,\</div><div class="line">x001,1494915979852.71f4a908f1e460ac95dfadcf5ab8ecfd., starting to roll back the global memstore size.</div><div class="line">2017-06-25 09:42:34,381 INFO  [RS_OPEN_REGION-datanode20:16020-2] coordination.ZkOpenRegionCoordination: Opening of region &#123;ENCODED =</div><div class="line">&gt; 71f4a908f1e460ac95dfadcf5ab8ecfd, NAME =&gt; &apos;KYLIN_HBWCQ5ZQR1,\x001,1494915979852.71f4a908f1e460ac95dfadcf5ab8ecfd.&apos;, STARTKEY =&gt; &apos;\x</div><div class="line">001&apos;, ENDKEY =&gt; &apos;\x002&apos;&#125; failed, transitioning from OPENING to FAILED_OPEN in ZK, expecting version 3</div><div class="line">2017-06-25 09:42:34,382 ERROR [RS_OPEN_REGION-datanode20:16020-0] handler.OpenRegionHandler: Failed open of region=KYLIN_HBWCQ5ZQR1,\</div><div class="line">x00\x15,1494915979852.c4940efcc8efa3f3a9b7c2a546a1d1f5., starting to roll back the global memstore size.</div><div class="line">org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state stan</div><div class="line">dby</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">java.io.IOException: Cannot append; log is closed</div><div class="line">        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.append(FSHLog.java:1223)</div><div class="line">        at org.apache.hadoop.hbase.regionserver.wal.WALUtil.writeRegionEventMarker(WALUtil.java:95)</div><div class="line">        at org.apache.hadoop.hbase.regionserver.HRegion.writeRegionOpenMarker(HRegion.java:978)</div><div class="line">        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:6335)</div><div class="line">        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:6289)</div><div class="line">        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:6260)</div><div class="line">        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:6216)</div><div class="line">        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:6167)</div><div class="line">        at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.openRegion(OpenRegionHandler.java:362)</div><div class="line">        ...............</div><div class="line">2017-06-25 09:42:44,168 INFO  [regionserver/datanode20.will.com/10.2.19.109:16020.logRoller] regionserver.LogRoller: LogRoller exit</div><div class="line">ing.</div><div class="line">2017-06-25 09:42:44,168 INFO  [regionserver/datanode20.will.com/10.2.19.109:16020] regionserver.CompactSplitThread: Waiting for Spl</div><div class="line">it Thread to finish...</div><div class="line">2017-06-25 09:42:44,168 INFO  [regionserver/datanode20.will.com/10.2.19.109:16020] regionserver.CompactSplitThread: Waiting for Mer</div><div class="line">ge Thread to finish...</div><div class="line">2017-06-25 09:42:44,168 INFO  [regionserver/datanode20.will.com/10.2.19.109:16020] regionserver.CompactSplitThread: Waiting for Lar</div><div class="line">ge Compaction Thread to finish...</div><div class="line">2017-06-25 09:42:44,168 INFO  [regionserver/datanode20.will.com/10.2.19.109:16020] regionserver.CompactSplitThread: Waiting for Sma</div><div class="line">ll Compaction Thread to finish...</div><div class="line">2017-06-25 09:42:44,170 INFO  [regionserver/datanode20.will.com/10.2.19.109:16020.leaseChecker] regionserver.Leases: regionserver/d</div><div class="line">atanode20.will.com/10.2.19.109:16020.leaseChecker closing leases</div><div class="line">2017-06-25 09:42:44,171 INFO  [regionserver/datanode20.will.com/10.2.19.109:16020.leaseChecker] regionserver.Leases: regionserver/d</div><div class="line">atanode20.will.com/10.2.19.109:16020.leaseChecker closed leases</div><div class="line">2017-06-25 09:42:44,183 INFO  [regionserver/datanode20.will.com/10.2.19.109:16020] ipc.RpcServer: Stopping server on 16020</div></pre></td></tr></table></figure>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/06/22/NN-HA后引发的问题/" title="NN-HA后引发的问题" itemprop="url">NN-HA后引发的问题</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-06-22T03:19:07.000Z" itemprop="datePublished"> 发表于 2017-06-22</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h6 id="最表面问题"><a href="#最表面问题" class="headerlink" title="最表面问题:"></a>最表面问题:</h6><p>几乎所有用户执行权限都出现问题。</p>
<h6 id="问题原因："><a href="#问题原因：" class="headerlink" title="问题原因："></a>问题原因：</h6><ul>
<li>所有HDFS之上的应用都是使用linux的posix文件权限控制</li>
<li>当Active NN是DN17的时候，DN17本机并没有这些用户的相关权限信息。<h6 id="解决方法："><a href="#解决方法：" class="headerlink" title="解决方法："></a>解决方法：</h6></li>
<li>尝试copyNN01的用户以及组信息到DN17<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">/etc/passwd</div><div class="line">/etc/shadow</div><div class="line"></div><div class="line"></div><div class="line">/etc/group</div><div class="line">/etc/gshadow</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">[root@namenode01 hdfs]# cat /etc/group | grep xiaov</div><div class="line">xiaov:x:1015:zhoujian,wangchenqi,zhangyuntao,wangxu,wanghao_fengkong,linzhixin,yangqiankun,tianye,zhaoyanchao,tinyv,wangyin,lihaoyue,zhuxiuwei,yangluan,qizhenpeng,zhanglining,xiaovtest,yanghuanyuzi,zhanghaigang,shichengjie,luanzhiwei,wangyasen,kangyimin,luiyahui,liuyahui,liulinyuan,caoyunqing,tianyang,chengyao,gezhao,hehaojun,hujunjie,liuwei,xiongpeng</div><div class="line">xiaovtest:x:1040:</div><div class="line">metastoremanager:x:1041:xiaovtest,wangchenqi</div></pre></td></tr></table></figure>
</li>
</ul>
<p>将上面所有的用户保存到另一台的xiaov文件中，然后执行下面的逻辑：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">for name in `cat xiaov | awk &apos;&#123;split($0, atr,&quot;,&quot;);   </div><div class="line"> </div><div class="line"> for (i=0;i&lt;length(atr);i++) &#123;</div><div class="line"> print(atr[i])</div><div class="line"> &#125;</div><div class="line"> &#125;&apos;`;</div><div class="line">do</div><div class="line">useradd $name -G xiaov</div><div class="line">done</div></pre></td></tr></table></figure></p>
<ul>
<li>使用fabric维护用户权限相关信息，每次都同时操作两台NN。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">-- fabric.py</div><div class="line"></div><div class="line">nns=(&apos;namenode01.will.com&apos;, &apos;datanode17.will.com&apos;)</div><div class="line"></div><div class="line">env.roledefs = &#123;</div><div class="line">    &apos;services&apos;: services,</div><div class="line">    &apos;datanodes&apos;: datanodes,</div><div class="line">    &apos;tmp&apos;: tmpnodes,</div><div class="line">    &apos;nns&apos;: nns</div><div class="line">&#125;</div><div class="line"></div><div class="line">------------------</div><div class="line"></div><div class="line">[root@datanode21 ~]# fab cmd:roles=nns,cmd=&quot;echo hello from `hostname`&quot;</div><div class="line">This text is green!</div><div class="line">This sentence is red, except for these words, which are green.</div><div class="line">[namenode01.will.com] Executing task &apos;cmd&apos;</div><div class="line">[namenode01.will.com] run: echo hello from datanode21.will.com</div><div class="line">[namenode01.will.com] out: hello from datanode21.will.com</div><div class="line">[namenode01.will.com] out: </div><div class="line"></div><div class="line">[datanode17.will.com] Executing task &apos;cmd&apos;</div><div class="line">[datanode17.will.com] run: echo hello from datanode21.will.com</div><div class="line">[datanode17.will.com] out: hello from datanode21.will.com</div><div class="line">[datanode17.will.com] out: </div><div class="line"></div><div class="line"></div><div class="line">Done.</div><div class="line">Disconnecting from datanode17.will.com... done.</div><div class="line">Disconnecting from namenode01.will.com... done</div></pre></td></tr></table></figure>
<h4 id="NN切换的相关日志"><a href="#NN切换的相关日志" class="headerlink" title="NN切换的相关日志"></a>NN切换的相关日志</h4><p>NN01的log。</p>
<p>出现这个错误后，NN自己直接shutdown<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line">2017-06-15 22:35:35,329 WARN  client.QuorumJournalManager (QuorumCall.java:waitFor(134)) - Waited 18014 ms (timeout=20000 ms) for a r</div><div class="line">esponse for sendEdits. Succeeded so far: [10.2.19.121:8485]</div><div class="line">2017-06-15 22:35:36,331 WARN  client.QuorumJournalManager (QuorumCall.java:waitFor(134)) - Waited 19015 ms (timeout=20000 ms) for a r</div><div class="line">esponse for sendEdits. Succeeded so far: [10.2.19.121:8485]</div><div class="line">2017-06-15 22:35:37,317 FATAL namenode.FSEditLog (JournalSet.java:mapJournalsAndReportErrors(398)) - Error: flush failed for required</div><div class="line"> journal (JournalAndStream(mgr=QJM to [10.2.19.123:8485, 10.2.19.127:8485, 10.2.19.121:8485], stream=QuorumOutputStream starting at t</div><div class="line">xid 118442295))</div><div class="line">java.io.IOException: Timed out waiting 20000ms for a quorum of nodes to respond.</div><div class="line">        at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:137)</div><div class="line">        at org.apache.hadoop.hdfs.qjournal.client.QuorumOutputStream.flushAndSync(QuorumOutputStream.java:107)</div><div class="line">        at org.apache.hadoop.hdfs.server.namenode.EditLogOutputStream.flush(EditLogOutputStream.java:113)</div><div class="line">        at org.apache.hadoop.hdfs.server.namenode.EditLogOutputStream.flush(EditLogOutputStream.java:107)</div><div class="line">        at org.apache.hadoop.hdfs.server.namenode.JournalSet$JournalSetOutputStream$8.apply(JournalSet.java:533)</div><div class="line">        at org.apache.hadoop.hdfs.server.namenode.JournalSet.mapJournalsAndReportErrors(JournalSet.java:393)</div><div class="line">        at org.apache.hadoop.hdfs.server.namenode.JournalSet.access$100(JournalSet.java:57)</div><div class="line">        at org.apache.hadoop.hdfs.server.namenode.JournalSet$JournalSetOutputStream.flush(JournalSet.java:529)</div><div class="line">        at org.apache.hadoop.hdfs.server.namenode.FSEditLog.logSync(FSEditLog.java:647)</div><div class="line">        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2512)</div><div class="line">        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2377)</div><div class="line">        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:708)</div><div class="line">        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTran</div><div class="line">slatorPB.java:405)</div><div class="line">        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamen</div><div class="line">odeProtocolProtos.java)</div><div class="line">        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)</div><div class="line">        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)</div><div class="line">        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2206)</div><div class="line">        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2202)</div><div class="line">        at java.security.AccessController.doPrivileged(Native Method)</div><div class="line">        at javax.security.auth.Subject.doAs(Subject.java:422)</div><div class="line">        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1709)</div><div class="line">        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2200)</div><div class="line">2017-06-15 22:35:37,318 WARN  client.QuorumJournalManager (QuorumOutputStream.java:abort(72)) - Aborting QuorumOutputStream starting </div><div class="line">at txid 118442295</div><div class="line">2017-06-15 22:35:37,337 INFO  BlockStateChange (BlockManager.java:computeReplicationWorkForBlocks(1531)) - BLOCK* neededReplications </div><div class="line">= 0, pendingReplications = 0.</div><div class="line">2017-06-15 22:35:37,342 INFO  util.ExitUtil (ExitUtil.java:terminate(124)) - Exiting with status 1</div><div class="line">2017-06-15 22:35:37,396 INFO  namenode.NameNode (LogAdapter.java:info(47)) - SHUTDOWN_MSG: </div><div class="line">/************************************************************</div><div class="line">SHUTDOWN_MSG: Shutting down NameNode at namenode01.will.com/10.2.19.72</div></pre></td></tr></table></figure></p>
<p>DN17的log<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">2017-06-19 16:34:39,682 WARN  client.QuorumJournalManager (QuorumCall.java:waitFor(134)) - Waited 27324 ms (timeout=20000 ms) for a r</div><div class="line">esponse for selectInputStreams. No responses yet.</div><div class="line"></div><div class="line">.........</div><div class="line">2017-06-19 16:34:46,859 INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(196)) - Detected pause in JVM or host machine (eg GC): p</div><div class="line">ause of approximately 6029ms</div><div class="line">No GCs detected</div><div class="line">2017-06-19 16:34:49,739 INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(196)) - Detected pause in JVM or host machine (eg GC): p</div><div class="line">ause of approximately 2380ms</div><div class="line">No GCs detected</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">2017-06-26 13:39:04,029 INFO  ipc.Server (Server.java:doRead(891)) - Socket Reader #1 for port 8020: readAndProcess from client 10.2.</div><div class="line">19.83 threw exception [java.io.IOException: Connection reset by peer]</div><div class="line">java.io.IOException: Connection reset by peer</div><div class="line">        at sun.nio.ch.FileDispatcherImpl.read0(Native Method)</div><div class="line">        at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)</div><div class="line">        at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)</div><div class="line">        at sun.nio.ch.IOUtil.read(IOUtil.java:197)</div><div class="line">        at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)</div><div class="line">        at org.apache.hadoop.ipc.Server.channelRead(Server.java:2773)</div><div class="line">        at org.apache.hadoop.ipc.Server.access$2800(Server.java:136)</div><div class="line">        at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:1606)</div><div class="line">        at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:880)</div><div class="line">        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:746)</div><div class="line">        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:717)</div><div class="line">2017-06-26 13:39:04,066 INFO  ipc.Server (Server.java:doRead(891)) - Socket Reader #1 for port 8020: readAndProcess from client 10.2.</div><div class="line">19.110 threw exception [java.io.IOException: Connection reset by peer]</div><div class="line">java.io.IOException: Connection reset by peer</div><div class="line">        at sun.nio.ch.FileDispatcherImpl.read0(Native Method)</div><div class="line">        at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)</div><div class="line">        at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)</div><div class="line">        at sun.nio.ch.IOUtil.read(IOUtil.java:197)</div><div class="line"></div><div class="line">.......</div><div class="line"></div><div class="line"></div><div class="line">2017-06-26 13:39:08,310 WARN  client.QuorumJournalManager (IPCLoggerChannel.java:call(406)) - Took 4136ms to send a batch of 3 edits (262 bytes) to remote journal 10.2.19.121:8485</div><div class="line">2017-06-26 13:39:08,310 WARN  client.QuorumJournalManager (IPCLoggerChannel.java:call(406)) - Took 4130ms to send a batch of 3 edits (262 bytes) to remote journal 10.2.19.123:8485</div><div class="line">2017-06-26 13:39:08,310 WARN  client.QuorumJournalManager (IPCLoggerChannel.java:call(388)) - Remote journal 10.2.19.127:8485 failed to write txns 134233020-134233022. Will try to write to this JN again after the next log roll.</div><div class="line">org.apache.hadoop.ipc.RemoteException(java.io.IOException): IPC&apos;s epoch 15 is less than the last promised epoch 16</div><div class="line">        at org.apache.hadoop.hdfs.qjournal.server.Journal.checkRequest(Journal.java:418)</div><div class="line">        at org.apache.hadoop.hdfs.qjournal.server.Journal.checkWriteRequest(Journal.java:446)</div><div class="line">        at org.apache.hadoop.hdfs.qjournal.server.Journal.journal(Journal.java:341)</div><div class="line">        at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.journal(JournalNodeRpcServer.java:148)</div><div class="line">        at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.journal(QJournalProtocolServerSideTranslatorPB.java:158)</div><div class="line">        at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProto</div><div class="line">colProtos.java:25421)</div><div class="line">        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)</div><div class="line">        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)</div><div class="line">        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2206)</div><div class="line">        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2202)</div><div class="line">        at java.security.AccessController.doPrivileged(Native Method)</div><div class="line">        at javax.security.auth.Subject.doAs(Subject.java:422)</div><div class="line">        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1709)</div><div class="line">        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2200)</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">..........</div><div class="line"></div><div class="line">org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:</div><div class="line">10.2.19.127:8485: IPC&apos;s epoch 15 is less than the last promised epoch 16</div></pre></td></tr></table></figure>
<p>又一次<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">2017-06-28 10:05:21,397 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state</div><div class="line">2017-06-28 10:05:21,398 WARN  ha.EditLogTailer (EditLogTailer.java:doWork(349)) - Edit log tailer interrupted</div><div class="line">java.lang.InterruptedException: sleep interrupted</div><div class="line">        at java.lang.Thread.sleep(Native Method)</div><div class="line">        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:347)</div><div class="line">        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:284)</div><div class="line">        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:301)</div><div class="line">        at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:449)</div><div class="line">        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:297)</div><div class="line">2017-06-28 10:05:21,403 INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1098)) - Starting services required for active state</div></pre></td></tr></table></figure></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/06/13/RunningDataV2版本迁移计划/" title="runningdatav2版本迁移计划" itemprop="url">runningdatav2版本迁移计划</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-06-13T08:45:17.000Z" itemprop="datePublished"> 发表于 2017-06-13</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h4 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h4><ul>
<li>编辑、更新<ul>
<li>各类ETL自动创建与之对应的ExecObj对象【重载save方法实现】</li>
<li>个别自动分析依赖的ETL同时新建或更新相关ExecBlood【H2H, H2M】</li>
<li>个别需要输入产出的ETL类型需要添加outputs字段，并在save的时候自创创建对应的NullETL对象【JAR】</li>
<li>根据自身特性创建自身的rel_name 【save的时候分析并添加上】</li>
</ul>
</li>
<li>调度相关<ul>
<li>(日月周)日常调度【完成依赖解析与任务文件生成，测试通过】</li>
<li>定时调度【执行部分使用既有方案】</li>
<li>临时调度【使用既有方案】</li>
<li>新建调度时，针对的对象应该是修改为ExecObj</li>
</ul>
</li>
</ul>
<h4 id="影响范围"><a href="#影响范围" class="headerlink" title="影响范围"></a>影响范围</h4><ul>
<li>整体过程中xstorm新建、编辑不可用</li>
<li>任务调度中间可能出现失败</li>
</ul>
<h4 id="实施步骤"><a href="#实施步骤" class="headerlink" title="实施步骤"></a>实施步骤</h4><ol>
<li>向各事业部发送不可用通知</li>
<li>数据库备份</li>
<li>确保新的save方法都已经注释掉,否则会影响清洗过程。</li>
<li>将数据库对应model字段全部添加上<blockquote>
<p>./manage.py migrate metamap 0052 –settings=metamap.config</p>
</blockquote>
</li>
</ol>
<p>可能需要手动添加exec_obj_id字段…【历史原因】<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="comment">--</span></div><div class="line"><span class="comment">-- Add field exec_obj to anaetl</span></div><div class="line"><span class="comment">--</span></div><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`metamap_anaetl`</span> <span class="keyword">ADD</span> <span class="keyword">COLUMN</span> <span class="string">`exec_obj_id`</span> <span class="built_in">integer</span> <span class="literal">NULL</span>;</div><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`metamap_anaetl`</span> <span class="keyword">ALTER</span> <span class="keyword">COLUMN</span> <span class="string">`exec_obj_id`</span> <span class="keyword">DROP</span> <span class="keyword">DEFAULT</span>;</div><div class="line"><span class="comment">--</span></div><div class="line"><span class="comment">-- Add field exec_obj to etl</span></div><div class="line"><span class="comment">--</span></div><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`metamap_etl`</span> <span class="keyword">ADD</span> <span class="keyword">COLUMN</span> <span class="string">`exec_obj_id`</span> <span class="built_in">integer</span> <span class="literal">NULL</span>;</div><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`metamap_etl`</span> <span class="keyword">ALTER</span> <span class="keyword">COLUMN</span> <span class="string">`exec_obj_id`</span> <span class="keyword">DROP</span> <span class="keyword">DEFAULT</span>;</div><div class="line"><span class="comment">--</span></div><div class="line"><span class="comment">-- Add field exec_obj to jarapp</span></div><div class="line"><span class="comment">--</span></div><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`metamap_jarapp`</span> <span class="keyword">ADD</span> <span class="keyword">COLUMN</span> <span class="string">`exec_obj_id`</span> <span class="built_in">integer</span> <span class="literal">NULL</span>;</div><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`metamap_jarapp`</span> <span class="keyword">ALTER</span> <span class="keyword">COLUMN</span> <span class="string">`exec_obj_id`</span> <span class="keyword">DROP</span> <span class="keyword">DEFAULT</span>;</div><div class="line"><span class="comment">--</span></div><div class="line"><span class="comment">-- Add field exec_obj to sqoophive2mysql</span></div><div class="line"><span class="comment">--</span></div><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`metamap_sqoophive2mysql`</span> <span class="keyword">ADD</span> <span class="keyword">COLUMN</span> <span class="string">`exec_obj_id`</span> <span class="built_in">integer</span> <span class="literal">NULL</span>;</div><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`metamap_sqoophive2mysql`</span> <span class="keyword">ALTER</span> <span class="keyword">COLUMN</span> <span class="string">`exec_obj_id`</span> <span class="keyword">DROP</span> <span class="keyword">DEFAULT</span>;</div><div class="line"><span class="comment">--</span></div><div class="line"><span class="comment">-- Add field exec_obj to sqoopmysql2hive</span></div><div class="line"><span class="comment">--</span></div><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`metamap_sqoopmysql2hive`</span> <span class="keyword">ADD</span> <span class="keyword">COLUMN</span> <span class="string">`exec_obj_id`</span> <span class="built_in">integer</span> <span class="literal">NULL</span>;</div><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`metamap_sqoopmysql2hive`</span> <span class="keyword">ALTER</span> <span class="keyword">COLUMN</span> <span class="string">`exec_obj_id`</span> <span class="keyword">DROP</span> <span class="keyword">DEFAULT</span>;</div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">INDEX</span> <span class="string">`metamap_anaetl_30a76f4d`</span> <span class="keyword">ON</span> <span class="string">`metamap_anaetl`</span> (<span class="string">`exec_obj_id`</span>);</div><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`metamap_anaetl`</span> <span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span> <span class="string">`metamap_anaetl_exec_obj_id_1bac03db_fk_metamap_execobj_id`</span> FOREIGN <span class="keyword">KEY</span> (<span class="string">`exec_obj_id`</span>) <span class="keyword">REFERENCES</span> <span class="string">`metamap_execobj`</span> (<span class="string">`id`</span>);</div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">INDEX</span> <span class="string">`metamap_etl_30a76f4d`</span> <span class="keyword">ON</span> <span class="string">`metamap_etl`</span> (<span class="string">`exec_obj_id`</span>);</div><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`metamap_etl`</span> <span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span> <span class="string">`metamap_etl_exec_obj_id_8c6a086a_fk_metamap_execobj_id`</span> FOREIGN <span class="keyword">KEY</span> (<span class="string">`exec_obj_id`</span>) <span class="keyword">REFERENCES</span> <span class="string">`metamap_execobj`</span> (<span class="string">`id`</span>);</div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">INDEX</span> <span class="string">`metamap_jarapp_30a76f4d`</span> <span class="keyword">ON</span> <span class="string">`metamap_jarapp`</span> (<span class="string">`exec_obj_id`</span>);</div><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`metamap_jarapp`</span> <span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span> <span class="string">`metamap_jarapp_exec_obj_id_6340f92e_fk_metamap_execobj_id`</span> FOREIGN <span class="keyword">KEY</span> (<span class="string">`exec_obj_id`</span>) <span class="keyword">REFERENCES</span> <span class="string">`metamap_execobj`</span> (<span class="string">`id`</span>);</div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">INDEX</span> <span class="string">`metamap_sqoophive2mysql_30a76f4d`</span> <span class="keyword">ON</span> <span class="string">`metamap_sqoophive2mysql`</span> (<span class="string">`exec_obj_id`</span>);</div><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`metamap_sqoophive2mysql`</span> <span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span> <span class="string">`metamap_sqoophive2mys_exec_obj_id_ee2cb5c2_fk_metamap_execobj_id`</span> FOREIGN <span class="keyword">KEY</span> (<span class="string">`exec_obj_id`</span>) <span class="keyword">REFERENCES</span> <span class="string">`metamap_execobj`</span> (<span class="string">`id`</span>);</div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">INDEX</span> <span class="string">`metamap_sqoopmysql2hive_30a76f4d`</span> <span class="keyword">ON</span> <span class="string">`metamap_sqoopmysql2hive`</span> (<span class="string">`exec_obj_id`</span>);</div><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`metamap_sqoopmysql2hive`</span> <span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span> <span class="string">`metamap_sqoopmysql2hi_exec_obj_id_9d61c4ff_fk_metamap_execobj_id`</span> FOREIGN <span class="keyword">KEY</span> (<span class="string">`exec_obj_id`</span>) <span class="keyword">REFERENCES</span> <span class="string">`metamap_execobj`</span> (<span class="string">`id`</span>);</div></pre></td></tr></table></figure></p>
<ol>
<li>按照以下顺序开始清洗</li>
</ol>
<ul>
<li><p>clean_etl </p>
<p>  生成对应ETL的ExecObj</p>
</li>
<li><p>clean_rel </p>
<p>  清洗H2M,M2H中不规范的name，规范化hive表名到rel_name字段中</p>
</li>
<li><p>clean_m2h </p>
<p>  清洗M2H任务，生成对应的ExecObj。另外找到所有TBLBlood中父表是此表rel_name的记录，新建与之对应的ExecBlood记录</p>
</li>
<li><p>before_clean_blood</p>
<p>  过滤一下TblBlood中的parent，对于不存在于H2H和M2好的父表，临时创建为之创建NULLETL，并创建对应ExecObj，然后再创建ExecBlood。 </p>
<p>  <strong>==注意==</strong>：由于NULLETL的特殊性，需要在此创建ExecObj的deptask的日月周调度【在save方法中已实现】</p>
</li>
<li><p>clean_blood</p>
<p>  清洗TblBlood到对应ExecBlood，因为前面已经处理了所有情况，不该出现任务child或者parent不存在的问题。</p>
<p>  自检sql</p>
  <figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> <span class="keyword">name</span> <span class="keyword">from</span> metamap_execobj <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">name</span> <span class="keyword">HAVING</span> <span class="keyword">count</span>(<span class="number">1</span>) &gt; <span class="number">1</span>;</div><div class="line"></div><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">from</span> metamap_execobj <span class="keyword">where</span> <span class="keyword">name</span> = <span class="string">'w_data_platform@drop_d_regula_stock'</span>;</div><div class="line"></div><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">from</span> metamap_execobj <span class="keyword">where</span> <span class="keyword">name</span> = <span class="string">'app_jlc@jlc_life_accumulative'</span>;</div></pre></td></tr></table></figure>
</li>
<li><p>clean_h2m</p>
<p>  清洗H2M到ExecObj对象，获取依赖ETL的H2H ExecObj对象，添加对应ExecBlood。<br>  如果是JAR产生的表，暂不支持，需要额外处理【JAR添加自身的output】。</p>
<p>  <strong>==注意==</strong>：<br>  H2M中的个别现象，多个周期的数据存放在同一个表中：<br>  SELECT * from metamap_sqoophive2mysql where id in (71,72,73,74,75,76)<br>  需要额外手动维护execblood</p>
</li>
<li><p>clean_jar</p>
<p>  清洗JAR到ExecObj对象</p>
</li>
<li><p>clean_email</p>
<p>  清洗ANAETL到ExecObj对象</p>
</li>
<li><p>clean_task</p>
<p>  分别执行clean， type=4, type=1等(1,2,3,4,6)</p>
  <figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">--- 这些都是ana_etl本身的valid是0</span></div><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">from</span> metamap_willdependencytask <span class="keyword">where</span> <span class="keyword">id</span> <span class="keyword">in</span> (<span class="number">864</span>, <span class="number">870</span>, <span class="number">759</span>, <span class="number">643</span>, <span class="number">164</span>, <span class="number">143</span>, <span class="number">85</span>)</div></pre></td></tr></table></figure>
</li>
<li><p>clean_ptask</p>
<p>  更新定时任务的task参数，由原来的will_deptask的id，更新为type为100的最新清洗完的task id.</p>
</li>
<li><p>clean_null</p>
<p>  为所有的NULLETL对象创建日月周的task调度</p>
</li>
</ul>
<ol>
<li>测试各种任务调度【日常调度、定时调度、即时调度】</li>
<li><p>clean_exec_id</p>
<p> 清洗原有的ETL对象的exec_obj_id字段</p>
</li>
<li><p>放开ETL对象的save方法注释</p>
</li>
<li>恢复线上使用，开启beta测试，随时解决未发现的新生bug</li>
<li>修改日调度脚本中的url到新版本</li>
<li>添加调度的页面覆盖回来[sche/edit_new.html， /views/sche_etl_v2.py]</li>
</ol>
<p>稳定运行一周，将dep task中旧的task全部删除</p>
<p>TODO</p>
<ol>
<li>H2M的依赖手动添加以下。SELECT * from metamap_sqoophive2mysql where id in (71,72,73,74,75,76)</li>
<li>测试各种ETL的save方法</li>
</ol>
<p>新增逻辑：</p>
<ol>
<li></li>
</ol>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/06/09/gobblin-architecture译文/" title="gobblin-architecture译文" itemprop="url">gobblin-architecture译文</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-06-09T06:44:08.000Z" itemprop="datePublished"> 发表于 2017-06-09</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>gobblin主要考虑的是扩展性，永固可以添加新的adapter或者集成已经存在的adapter来加入新的source，从新的source抽取数据。架构图：<br><img src="http://gobblin.readthedocs.io/en/latest/img/Gobblin-Architecture-Overview.png" alt="架构图"></p>
<p>一个gobblin job是一些列组件协同的结果。所有的组件都是可插拔可扩展的。(<a href="http://gobblin.readthedocs.io/en/latest/Gobblin-Architecture#gobblin-constructs" target="_blank" rel="external">http://gobblin.readthedocs.io/en/latest/Gobblin-Architecture#gobblin-constructs</a>)</p>
<p>一个gobblin job有一些列的task组成，每个task对应着一个工作单元，负责抽取一部分数据。这些task会根据配置选择(红色部分)通过gobblin runtime执行(上面橙色的部分)。</p>
<p><a href="http://gobblin.readthedocs.io/en/latest/Gobblin-Architecture/" target="_blank" rel="external">http://gobblin.readthedocs.io/en/latest/Gobblin-Architecture/</a></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/06/07/nginx代理HDP集群代码段/" title="nginx代理HDP集群代码段" itemprop="url">nginx代理HDP集群代码段</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-06-07T11:43:46.000Z" itemprop="datePublished"> 发表于 2017-06-07</time>
    
  </p>
</header>
    <div class="article-content">
        
        <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">#user  nobody;</div><div class="line">worker_processes  1;</div><div class="line"></div><div class="line"></div><div class="line">events &#123;</div><div class="line">    worker_connections  1024;</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">http &#123;</div><div class="line">    include       mime.types;</div><div class="line">    default_type  application/octet-stream;</div><div class="line"></div><div class="line"></div><div class="line">upstream jobhis &#123;</div><div class="line">        server servicenode03.will.com:19888 fail_timeout=30s;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    upstream azk &#123;</div><div class="line">        server schedule.will.com:8081 fail_timeout=30s;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    upstream yarn &#123;</div><div class="line">        server datanode02.will.com:8088 fail_timeout=30s;</div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line">    sendfile        on;</div><div class="line">    keepalive_timeout  65;</div><div class="line"></div><div class="line"></div><div class="line">    server &#123;</div><div class="line">        listen       81;</div><div class="line">        server_name  localhost;</div><div class="line"></div><div class="line">	subs_filter_types *;</div><div class="line">#        subs_filter overwrite willhistory i;</div><div class="line">        subs_filter datanode02.will.com:8088 $host:$server_port;</div><div class="line">	subs_filter 10.2.19.(\d*) unknown_ip ir;</div><div class="line">	subs_filter (data|name|service)node(\d*).will.com $1_$2.data.com ir;</div><div class="line">#        subs_filter will.com will.data.com ir;</div><div class="line"></div><div class="line"></div><div class="line">        #charset koi8-r;</div><div class="line"></div><div class="line">        #access_log  logs/host.access.log  main;</div><div class="line"></div><div class="line">	location /cluster/app &#123;</div><div class="line">                auth_request /auth;</div><div class="line">                try_files $uri @yarn;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        location /proxy &#123;</div><div class="line">                auth_request /auth;</div><div class="line">                try_files $uri @yarn;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        location /jobhistory &#123;</div><div class="line">               auth_request /auth;</div><div class="line">               try_files $uri @jobhis;</div><div class="line">		rewrite ^/jobhistory/logs/(data|service|name)_(\d*).data.com:(\d*)/(.*)$  /jobhistory/logs/$1node$2.will.com:$3/$4 break;</div><div class="line">        &#125;</div><div class="line"></div><div class="line"></div><div class="line">	location / &#123;</div><div class="line">                try_files $uri @azk;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">	location @jobhis&#123;</div><div class="line">            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</div><div class="line">            proxy_set_header Host $http_host;</div><div class="line">            proxy_redirect off;</div><div class="line">            proxy_pass http://jobhis;</div><div class="line">        &#125;</div><div class="line"></div><div class="line"></div><div class="line">        location = /auth &#123;</div><div class="line">           internal;</div><div class="line">           proxy_pass http://10.2.19.62:8088/metamap/nginx_auth_test;</div><div class="line">           proxy_set_header Content-Length &quot;&quot;;</div><div class="line">           proxy_set_header X-Original-URI $request_uri;</div><div class="line">           proxy_pass_request_body off;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        location /static &#123;</div><div class="line">                 try_files $uri @yarn;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">	location @yarn&#123;</div><div class="line">            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</div><div class="line">            proxy_set_header Host $http_host;</div><div class="line">            proxy_redirect off;</div><div class="line">            proxy_pass http://yarn;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        location @azk&#123;</div><div class="line">            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</div><div class="line">            proxy_set_header Host $http_host;</div><div class="line">            proxy_redirect off;</div><div class="line">            proxy_pass http://azk;</div><div class="line">	    subs_filter_types *;</div><div class="line">	    subs_filter datanode(\d\d).will.com will.will.com ir;</div><div class="line">	    subs_filter 10.2.19.(\d*) unknowip ir;</div><div class="line">        &#125;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">        error_page   500 502 503 504  /50x.html;</div><div class="line">        location = /50x.html &#123;</div><div class="line">            root   html;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">   </div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line">   </div><div class="line">&#125;</div></pre></td></tr></table></figure>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/05/26/fabric与anisible对比/" title="fabric与anisible对比" itemprop="url">fabric与anisible对比</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-05-26T03:18:37.000Z" itemprop="datePublished"> 发表于 2017-05-26</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>主要是跟anisible做对比，搞数据集群的环境越来越大，机器越来越多，不弄点儿自动化维护的工具，真心折腾不过来，而且容易出现失误。</p>
<p>这两天陪媳妇去图书馆自习，我就看书，看了一本不错的小说《兄弟》：余华写的，相当不错，笑中带泪，奔放中带着坚韧。因为近期工作中想要用一下docker来部署生产环境，为算法的同学提供动态可自定义的各种语言程序运行环境。前面听过几场关于docker环境部署的，听过几个人使用anisible进行docker部署，所以就在图书馆拿了本《奔跑吧：anisible》。</p>
<h2 id="吸引"><a href="#吸引" class="headerlink" title="吸引"></a>吸引</h2><p>里面提到anisible的我看中的功能性卖点：</p>
<ul>
<li>host分组</li>
<li>任务有顺序依赖的执行</li>
<li>获取上一个task的输出，比如docker容器mysql部署后，把这个容器的id保存给下一个容器web服务的配置文件使用。</li>
<li>配置文件模板化，接受外来变量赋值后，copy进入指定主机的指定目录。</li>
</ul>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><p>但是有一个比较恶心的问题，要记住一些概念</p>
<ul>
<li>inventory 主机</li>
<li>task<ul>
<li>module 具体执行的一些功能模块</li>
</ul>
</li>
<li>handler 等待被task触发</li>
<li>fact 主机相关的一些信息，比如CPU、内存、ip啥的</li>
</ul>
<h4 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h4><ul>
<li>module之类的都是别人封装好的，自己要完全按照人家的规则走，不舒服</li>
<li>有些需要额外处理的东西还是要自己写python代码处理，因为有些自定义的处理逻辑，是不会存在于既有的module中的</li>
</ul>
<p>那么恶心的事情就出现了：既要去使用module中别人给自己制定的规则， 又他么要自己写代码完成自己的逻辑。还不如fabric，完全按照自己的代码去执行逻辑。</p>
<h2 id="fabric"><a href="#fabric" class="headerlink" title="fabric"></a>fabric</h2><p>今儿早上看了一下fabric</p>
<ul>
<li>主机分组 【Y：有role进行分组】</li>
<li>任务 【Y】</li>
<li>任务依赖 【Y：通过定义额外的任务组合惹怒我】</li>
<li>主机信息【并没有感觉有什么用】</li>
<li><strong>task间变量传递</strong>【上一个任务给环境中的变量赋值，下一个任务可以直接接收到，比如dict】 —— <strong>失败</strong></li>
</ul>
<p>直接上自己的脚本文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">from fabric.api import *</div><div class="line"></div><div class="line"># 不指定用户的话，就是当前用户，跟ssh一样</div><div class="line">env.hosts = [</div><div class="line">    &apos;user@192.168.1.1&apos;,</div><div class="line">    &apos;user@192.168.1.2&apos;,</div><div class="line">]</div><div class="line"></div><div class="line"># 必须全面指定 ： user@ip:port</div><div class="line">env.passwords = &#123;</div><div class="line">    &apos;user@192.168.1.1:22&apos;: &apos;password1&apos;,</div><div class="line">    &apos;user@192.168.1.2:22&apos;: &apos;password2&apos;,</div><div class="line">&#125;</div><div class="line"></div><div class="line"># 这个标识有么有都可以 1.6.3版本</div><div class="line">@task</div><div class="line">def echo():</div><div class="line">    run(&apos;echo &quot;hello,world&quot;&apos;)</div></pre></td></tr></table></figure></p>
<p>动态为自己的机器分组, 那么就在fabric.py里执行以下逻辑：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">services = []</div><div class="line">datanodes = []</div><div class="line">hosts = list()</div><div class="line"></div><div class="line">def get_host():</div><div class="line">    with open(&apos;/etc/hosts&apos;, &apos;r&apos;) as hf:</div><div class="line">        for line in hf.readlines():</div><div class="line">            ss = line.split()</div><div class="line">            if &apos;node&apos; in ss[1]:</div><div class="line">                hosts.append(ss[0])</div><div class="line">            if &apos;servicenode&apos; in ss[1]:</div><div class="line">                services.append(ss[0])</div><div class="line">            if &apos;datanode&apos; in ss[1]:</div><div class="line">                datanodes.append(ss[0])</div><div class="line">    hosts.remove(&apos;10.2.19.104&apos;)</div><div class="line"></div><div class="line">env.hosts=hosts</div><div class="line"></div><div class="line">env.roledefs = &#123;</div><div class="line">    &apos;services&apos;: services,</div><div class="line">    &apos;datanodes&apos;: datanodes</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>其实这里的/etc/hosts就相当于anisible的inventory文件了。</p>
<p>调用的时候指定host组：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">fab cmd:roles=services,cmd=&apos;df -h&apos;</div></pre></td></tr></table></figure></p>
<p>至此：放弃fabric……不能支持依赖部署，或者容器编排。离开……【尝试在任务重使用变量赋值失败，因为每个remote机器赋值都是对于自己的，并不能对全局变量赋值。但是其实通过获取任务的output，所以不放弃了】</p>
<p>稻草一枚：</p>
<ul>
<li><a href="http://fabric-chs.readthedocs.io/zh_CN/chs/api/core/tasks.html" target="_blank" rel="external">http://fabric-chs.readthedocs.io/zh_CN/chs/api/core/tasks.html</a></li>
<li><a href="https://stackoverflow.com/questions/42946197/return-value-from-fabric-task" target="_blank" rel="external">https://stackoverflow.com/questions/42946197/return-value-from-fabric-task</a></li>
<li></li>
</ul>
<h2 id="并行任务"><a href="#并行任务" class="headerlink" title="并行任务"></a>并行任务</h2><p>fabric现在也支持并行执行task，并且提供一次并行多少的粒度<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">from fabric.api import *</div><div class="line"></div><div class="line">@parallel(pool_size=5)</div><div class="line">def heavy_task():</div><div class="line">    # lots of heavy local lifting or lots of IO here</div></pre></td></tr></table></figure></p>
<p>指定一次并行5个远程机器<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">fab -P -z 5 heavy_task</div></pre></td></tr></table></figure></p>
<p><a href="http://docs.fabfile.org/en/1.13/usage/parallel.html" target="_blank" rel="external">http://docs.fabfile.org/en/1.13/usage/parallel.html</a></p>
<h2 id="获取任务结果"><a href="#获取任务结果" class="headerlink" title="获取任务结果"></a>获取任务结果</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">from fabric.api import task, execute, run, runs_once</div><div class="line"></div><div class="line">@task</div><div class="line">def workhorse():</div><div class="line">    return run(&quot;get my infos&quot;)</div><div class="line"></div><div class="line">@task</div><div class="line">@runs_once</div><div class="line">def go():</div><div class="line">    results = execute(workhorse)</div><div class="line">    print results</div></pre></td></tr></table></figure>
<p>注意：execute是在任务在每个remote host上执行完之后获取结果，而run的stdout则是在单个任务内返回。</p>
<p><a href="http://docs.fabfile.org/en/1.13/usage/execution.html#intelligently-executing-tasks-with-execute" target="_blank" rel="external">http://docs.fabfile.org/en/1.13/usage/execution.html#intelligently-executing-tasks-with-execute</a></p>
<h2 id="文件传递"><a href="#文件传递" class="headerlink" title="文件传递"></a>文件传递</h2><p>使用put放到远程机器<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">with cd(&apos;/tmp&apos;):</div><div class="line">    put(&apos;/path/to/local/test.txt&apos;, &apos;files&apos;)</div><div class="line">    </div><div class="line">put(&apos;bin/project.zip&apos;, &apos;/tmp/project.zip&apos;)</div><div class="line">put(&apos;*.py&apos;, &apos;cgi-bin/&apos;)</div><div class="line">put(&apos;index.html&apos;, &apos;index.html&apos;, mode=0755)</div></pre></td></tr></table></figure></p>
<p>使用get获取远程机器文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">get(&apos;/path/to/remote_file.txt&apos;, &apos;local_directory&apos;)</div></pre></td></tr></table></figure></p>
<p>上面的put对比anisible来说，只有一方面不足，就是对于类似nginx配置文件中的一些变量信息，我们需要额外自己引入模板，渲染之后再put出去。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/05/25/linux中的hang进程/" title="linux中的hang进程" itemprop="url">linux中的hang进程</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-05-25T03:10:38.000Z" itemprop="datePublished"> 发表于 2017-05-25</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>5月24号晚上发现62上有两个hang的进程，占满了内存与cpu</p>
<p>第一个是M2H任务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">root     10082     1 97 May21 ?        3-20:08:33 /server/java/jdk1.8.0_60/bin/java -Xmx4096m -Dhdp.version=2.4.2.0-258 -Djava.net.preferIPv4Stack=true -Dhdp.version=2.4.2.0-258 -Dhadoop.log.dir=/var/log/hadoop/root -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/hdp/2.4.2.0-258/hadoop -Dhadoop.id.str=root -Dhadoop.root.logger=INFO,console -Djava.library.path=:/usr/hdp/2.4.2.0-258/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.4.2.0-258/hadoop/lib/native -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx4096m -Dhadoop.security.logger=INFO,NullAppender org.apache.sqoop.Sqoop import -Dmapreduce.job.queuename=xstorm --connect jdbc:mysql://10.0.100.73:3306/xiaodai?useCursorFetch=true&amp;dontTrackOpenResources=true&amp;defaultFetchSize=2000 --driver com.mysql.jdbc.Driver --username weixddata_read --password G7iu1BMo9LWs2e --hive-database ods_tinyv --columns ID,USER_ID,WB_USERNAME,MOBILE,BIZ_ID,MSG_TYPE,SMS_TYPE,DATA_SOURCE,SMS_ID,TASK_ID,SEND_STATUS,RES_CODE,REPORT_STATUS,SEND_TIME,REPORT_TIME,SEND_EXCEPTION --where DATE_FORMAT(SEND_TIME, &apos;%Y-%m-%d&apos;)=&apos;2017-05-20&apos; --table SMS_INFO --hive-import --hive-overwrite --target-dir ods_tinyv_SMS_INFO --outdir /server/app/sqoop/vo --bindir /server/app/sqoop/vo --verbose -m 1 --delete-target-dir --hive-import --hive-table o_wb_xiaodai_sms_info_i --hive-partition-key dt --hive-partition-value 2017-05-20 --null-string \\N --null-non-string \\N</div></pre></td></tr></table></figure></p>
<p>还有一个HIVE任务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">root      3483     1 96 May23 ?        1-11:12:07 /server/java/jdk1.8.0_60/bin/java -Xmx4096m -Dhdp.version=2.4.2.0-258 -Djava.net.preferIPv4Stack=true -Dhdp.version=2.4.2.0-258 -Djava.net.preferIPv4Stack=true -XX:NewRatio=12 -XX:MaxHeapFreeRatio=40 -XX:MinHeapFreeRatio=15 -XX:+UseNUMA -XX:+UseParallelGC -XX:-UseGCOverheadLimit -Dhdp.version=2.4.2.0-258 -Dhadoop.log.dir=/var/log/hadoop/root -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/hdp/2.4.2.0-258/hadoop -Dhadoop.id.str=root -Dhadoop.root.logger=INFO,console -Djava.library.path=:/usr/hdp/2.4.2.0-258/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.4.2.0-258/hadoop/lib/native -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx4096m -Xmx1024m -Dhadoop.security.logger=INFO,NullAppender -Dhdp.version=2.4.2.0-258 -Dhadoop.log.dir=/var/log/hadoop/root -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/hdp/2.4.2.0-258/hadoop -Dhadoop.id.str=root -Dhadoop.root.logger=INFO,console -Djava.library.path=:/usr/hdp/2.4.2.0-258/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.4.2.0-258/hadoop/lib/native:/usr/hdp/2.4.2.0-258/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.4.2.0-258/hadoop/lib/native -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx4096m -Xmx4096m -Xmx1024m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar /usr/hdp/2.4.2.0-258/hive/lib/hive-exec-1.2.1000.2.4.2.0-258.jar org.apache.hadoop.hive.ql.exec.mr.ExecDriver -localtask -plan file:/tmp/root/228f95e6-26ee-4466-bd3d-a91195c86bf4/hive_2017-05-23_10-38-11_000_7465740175512782543-1/-local-10004/plan.xml -jobconffile file:/tmp/root/228f95e6-26ee-4466-bd3d-a91195c86bf4/hive_2017-05-23_10-38-11_000_7465740175512782543-1/-local-10005/jobconf.xml</div></pre></td></tr></table></figure></p>
<p>手贱，先kill掉了，不然还能看到上面的plan文件，和job配置文件什么的。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/05/18/runningdata改版记录/" title="runningdata改版记录" itemprop="url">runningdata改版记录</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-05-18T02:54:54.000Z" itemprop="datePublished"> 发表于 2017-05-18</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>抽象ETLObjRelated，其他对象继承之</p>
<ul>
<li>ETL的字段名tbl_name需要在数据库里修改为name<ul>
<li>tasks里的exec_etl_sche任务会调用etl.name【老表的tbl_name会报错找不到】</li>
</ul>
</li>
<li>执行metamap 0045的migrations，这个只是添加字段，不会造成额外影响</li>
<li></li>
</ul>
<p>sdf </p>
<ol>
<li><p>确保新的save方法都已经注释掉</p>
</li>
<li><p>./manage.py migrate metamap 0050 –settings=metamap.config</p>
</li>
<li><p>开始清洗</p>
</li>
</ol>
<ul>
<li>clean_etl</li>
<li>clean_rel</li>
<li>clean_m2h</li>
<li>before_clean_blood</li>
<li>clean_blood</li>
<li>clean_h2m</li>
<li>clean_jar</li>
<li>clean_email</li>
<li>clean_task[分别执行clean， type=4, type=1等等]</li>
<li>clean_period</li>
</ul>
<h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><ol>
<li>H2M中的个别现象，多个周期的数据存放在同一个表中：<br>SELECT * from metamap_sqoophive2mysql where id in (71,72,73,74,75,76)<br>需要额外手动维护execblood</li>
<li>放开那些注释</li>
</ol>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






  <nav id="page-nav" class="clearfix">
    <a class="extend prev" rel="prev" href="/page/9/"><span></span>Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="page-number" href="/page/9/">9</a><span class="page-number current">10</span><a class="page-number" href="/page/11/">11</a><a class="page-number" href="/page/12/">12</a><span class="space">&hellip;</span><a class="page-number" href="/page/24/">24</a><a class="extend next" rel="next" href="/page/11/">Next<span></span></a>
  </nav>

</div>
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  


  

  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/youdaonote/" title="youdaonote">youdaonote<sup>187</sup></a></li>
			
		
			
				<li><a href="/tags/源码/" title="源码">源码<sup>10</sup></a></li>
			
		
			
				<li><a href="/tags/akka/" title="akka">akka<sup>9</sup></a></li>
			
		
			
				<li><a href="/tags/flume/" title="flume">flume<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/ETL/" title="ETL">ETL<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/solr/" title="solr">solr<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/spring/" title="spring">spring<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/调度平台/" title="调度平台">调度平台<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/azkaban/" title="azkaban">azkaban<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/mysql/" title="mysql">mysql<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/scala/" title="scala">scala<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/ambari/" title="ambari">ambari<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/quartz/" title="quartz">quartz<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/nodejs/" title="nodejs">nodejs<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Solr/" title="Solr">Solr<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/guava/" title="guava">guava<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/heroku/" title="heroku">heroku<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/hdfs/" title="hdfs">hdfs<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/hue/" title="hue">hue<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/ElasticSearch/" title="ElasticSearch">ElasticSearch<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="https://github.com/willcup" target="_blank" title=" 我自己的github">github</a>
            
          </li>
        
          <li>
            
            	<a href="http://thisding.com" target="_blank" title="朋友的主页">Steven&#39;s Blog</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

  <div class="weiboshow">
  <p class="asidetitle">新浪微博</p>
    <iframe width="100%" height="119" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=null&verifier=&dpc=1"></iframe>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m Will Chen in MeiTuan. <br/>
			元 亨 利 贞.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
		<a href="mailto:chenxin15@meituan.com" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2017 
		
		<a href="/about" target="_blank" title="Will Chen">Will Chen</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>










<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3Fe6d1f421bbc9962127a50488f9ed37d1' type='text/javascript'%3E%3C/script%3E"));
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
 </html>
