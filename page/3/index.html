
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <script type="text/javascript">
    (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
    })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');
    
    _st('install','yNiKTKaAnwd1uuxVMfiE','2.0.0');
  </script>
  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?5b99dfd487346155d274c0c49c3fb869";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
  </script>

  
    <title>Will&#39;s Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Will Chen">
    

    
    <meta name="description" content="左右水色 右手天光">
<meta property="og:type" content="website">
<meta property="og:title" content="Will's Blog">
<meta property="og:url" content="https://runningdata.github.io/page/3/index.html">
<meta property="og:site_name" content="Will's Blog">
<meta property="og:description" content="左右水色 右手天光">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Will's Blog">
<meta name="twitter:description" content="左右水色 右手天光">

    
    <link rel="alternative" href="/atom.xml" title="Will&#39;s Blog" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="Will&#39;s Blog" title="Will&#39;s Blog"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Will&#39;s Blog">Will&#39;s Blog</a></h1>
				<h2 class="blog-motto">简易 变易 不易</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">首页</a></li>
					
						<li><a href="/archives">归档</a></li>
					
						<li><a href="/about">关于</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:runningdata.github.io">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main">

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/12/05/slider上手/" title="slider上手" itemprop="url">slider上手</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-12-05T09:42:44.000Z" itemprop="datePublished"> 发表于 2017-12-05</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h4 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h4><ul>
<li>hadoop2.6+</li>
<li>HDFS,YARN,ZKK</li>
<li>JDK1.7</li>
<li>python 2.6</li>
<li>openssl</li>
</ul>
<h4 id="配置集群"><a href="#配置集群" class="headerlink" title="配置集群"></a>配置集群</h4><p>配置hadoop集群。</p>
<p>注意：debug设置为非0的能进行debug。如果使用一个vm或者一个sandbox，那么可以修改yarn配置，允许多个container在同一个host上。在yarn-site.xml中修改下面的配置</p>
<p>例子<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;</div><div class="line">  &lt;value&gt;256&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;yarn.nodemanager.delete.debug-delay-sec&lt;/name&gt;</div><div class="line">  &lt;value&gt;3600&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure></p>
<h4 id="下载slider"><a href="#下载slider" class="headerlink" title="下载slider"></a>下载slider</h4><h4 id="配置slider"><a href="#配置slider" class="headerlink" title="配置slider"></a>配置slider</h4><p>进入目录<code>slider-0.80.0-incubating/conf</code>后，编辑<code>slider-env.sh</code>文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">export JAVA_HOME=/usr/jdk64/jdk1.7.0_67</div><div class="line">export HADOOP_CONF_DIR=/etc/hadoop/conf</div></pre></td></tr></table></figure></p>
<p>如果运行在一个没有安装hadoop的节点上，只需要把相关配置放到相应目录就可以了。也可以通过<code>slider-clietn.xml</code>配置hadoop配置路径：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;HADOOP_CONF_DIR&lt;/name&gt;</div><div class="line">  &lt;value&gt;/etc/hadoop/conf&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure></p>
<p>或者<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;HADOOP_CONF_DIR&lt;/name&gt;</div><div class="line">  &lt;value&gt;$&#123;SLIDER_CONF_DIR&#125;/../hadoop-conf&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure></p>
<p>对于一个没有nn HA和 RM HA的集群，修改slider-client.xml配置如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hadoop.registry.zk.quorum&lt;/name&gt;</div><div class="line">    &lt;value&gt;yourZooKeeperHost:port&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">    &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;</div><div class="line">    &lt;value&gt;yourResourceManagerHost:8050&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">    &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;</div><div class="line">    &lt;value&gt;yourResourceManagerHost:8030&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">    &lt;name&gt;fs.defaultFS&lt;/name&gt;</div><div class="line">    &lt;value&gt;hdfs://yourNameNodeHost:8020&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div></pre></td></tr></table></figure></p>
<p>执行命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$&#123;slider-install-dir&#125;/slider-0.80.0-incubating/bin/slider version</div><div class="line"></div><div class="line">python %slider-install-dir%/slider-0.80.0-incubating/bin/slider.py version</div></pre></td></tr></table></figure></p>
<p>保证没有错误输出，那么slider就已经正确安装了。</p>
<h4 id="发布slider-resource"><a href="#发布slider-resource" class="headerlink" title="发布slider resource"></a>发布slider resource</h4><p>确保所有的文件目录都可以被app实例的创建者使用，我们这里使用yarn作为app创建者。</p>
<h5 id="确保HDFS-home存在"><a href="#确保HDFS-home存在" class="headerlink" title="确保HDFS home存在"></a>确保HDFS home存在</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">su hdfs</div><div class="line"></div><div class="line">hdfs dfs -mkdir /user/yarn</div><div class="line"></div><div class="line">hdfs dfs -chown yarn:hdfs /user/yarn</div></pre></td></tr></table></figure>
<h5 id="创建app包"><a href="#创建app包" class="headerlink" title="创建app包"></a>创建app包</h5><p>有几个简单的例子：</p>
<ul>
<li>app-packages/memcached-win</li>
<li>app-packages/hbase</li>
<li>app-packages/accumulo</li>
<li>app-packages/storm</li>
</ul>
<p>根据各个里面的README，创建一个或多个slider app。</p>
<h5 id="安装，配置，启动，验证"><a href="#安装，配置，启动，验证" class="headerlink" title="安装，配置，启动，验证"></a>安装，配置，启动，验证</h5><ul>
<li>安装<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">slider install-package --name *package name* --package *sample-application-package*</div></pre></td></tr></table></figure>
</li>
</ul>
<p>安装包会被发布到HDFS的<user home="" dir="">/.slider/package/<name provided="" in="" the="" command="">。</name></user></p>
<ul>
<li>创建。分两部分，一个是resource specification，另一个是app configuration<ul>
<li>resource specification。slider需要知道要部署多少component，需要多少CPU，内存。这些信息放在resources.json中。</li>
<li>application configuration。应用的配置信息，例如jvm堆大小等</li>
</ul>
</li>
<li><p>启动。通过cli启动的话</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd $&#123;slider-install-dir&#125;/slider-0.80.0-incubating/bin</div><div class="line">./slider create cl1 --template appConfig.json --resources resources.json</div></pre></td></tr></table></figure>
</li>
<li><p>验证。到yarn里，打开appmaster，看到slider app master</p>
</li>
</ul>
<h5 id="获取client配置"><a href="#获取client配置" class="headerlink" title="获取client配置"></a>获取client配置</h5><p>一个app发布几个用户的细节信息，用来管理app实例。</p>
<p>可以使用registry命令获取这些数据。</p>
<ul>
<li>发布的数据。在app master的/ws/v1/slider/publisher可以看到，通过slider-client status app1</li>
<li>client配置。/ws/v1/slider/publisher/slider/<config name=""></config></li>
<li>log位置。ws/v1/slider/publisher/slider/logfolders</li>
<li>一些监控UI, jmx终端等。/ws/v1/slider/publisher/slider/quicklinks</li>
</ul>
<h4 id="app生命周期管理"><a href="#app生命周期管理" class="headerlink" title="app生命周期管理"></a>app生命周期管理</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">./slider start/stop cl1</div><div class="line">./slider destroy</div><div class="line">./slider flex cl1 --component worker 5</div></pre></td></tr></table></figure>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/12/05/slider架构概览/" title="slider架构概览" itemprop="url">slider架构概览</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-12-05T08:03:33.000Z" itemprop="datePublished"> 发表于 2017-12-05</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>slider是一个YARN application，用来部署非YARN的app到YARN集群中。</p>
<p>slider包含一个YARN application master，Slider AM，然后client application需要通过RPC或者HTTP与YARN和Slider AM进行通信。client application提供了命令行与low-level API，以供测试。</p>
<p>被部署的app应该是可以运行在YARN管理的server池中的程序，还要能动态定位到它自己的peer。slider并不负责配置这些peer server，只负责一些app指定的实例的配置初始化工作。</p>
<p>每个app实例都是一个或多个component，每个component可以有不同的程序或命令，不同的配置项或参数。</p>
<p>AM负责启动哪些具体的role，为每个component请求一个YARN container。然后监控app实例的状态，当一个远程执行的进程完成之后，YARN会通知到AM。然后AM就去部署这个component的下一个实例去了。</p>
<h4 id="slider打包"><a href="#slider打包" class="headerlink" title="slider打包"></a>slider打包</h4><p>slider一个重要的目标就是支持已经存在的APP部署到yarn上去</p>
<h4 id="AM架构"><a href="#AM架构" class="headerlink" title="AM架构"></a>AM架构</h4><p>AM包含：</p>
<ul>
<li>AM engine，负责处理所有的外部服务的整合，尤其是YARN和其他的slider client</li>
<li>provider，指定部署app的class</li>
<li>app的状态</li>
</ul>
<p>app状态是app实例的模型，包含：</p>
<ul>
<li>app实例一些期望的状态，比如每种component的实例数量，他们的YARN container内存等</li>
<li>当前实例在yarn集群中每种component的数据，包括每个node上的可用资源</li>
<li>role history。记录每个node都被部署过哪种component，后面可以还这样部署。这是为了在需要读写本地磁盘的时候不出问题。</li>
<li>追踪消息队列：请求、发布、启动节点</li>
</ul>
<p>app engine整合了所有外部的东西：YARN RM， 指定node的NM，接受来自RM的service，request，释放container的event，在分配的container上启动app。</p>
<p>集群中发生任何变化，都会发送通知，然后app engine把通知传递给App的Status类，Status类更新它的状态，返回一系列集群操作(请求不同类型的container， 可能会指定节点，或者请求释放container)，供提交。</p>
<p>有了这些之后，再加上分配消息，app engine就可以把app State分配给指定的组件了，然后出发provider构建app的启动context。</p>
<p>provider有带有用于启动provider支持的程序的文件关联、环境变量、命令，用以发布container。</p>
<p>core provider在目标container上部署一个minimal 的agent，然后这个agent会计入agent provider的REST API， 执行它的命令。</p>
<p>这个agnet要执行的命令主要是从HDFS下载归档文件，解压开，运行python脚本来执行真正的配置，最后就是目标的执行了。这里面会用到很多模板。</p>
<p>总结一下：slider不是一个典型的YARN analysis app，YARN analysis app是指在短期、中期生命的container中分配和调度工作，带有一个query或者analysis session的一个生命周期，slider的生命周期是长达几天或者几个月的。slider要是app集群保持某个状态，app也应该能在node失败后进行恢复，还有就是定位到自己的peer node，再有就是与HDFS文件系统的数据进行交互。</p>
<p>Samza是第一个被设计运行在yarn上的app，它作为一个平台或者long-live 服务存在。这些app对yarn的需求是不一样的，他们的application master的设计主要集中在维护分布式app在一个稳定的状态，而不是提交什么作业。</p>
<p>MVC的切分实现了mode与aid mock测试的隔离性，增强了slider能够在YARN上部署更大规模的信息。</p>
<h4 id="失败模型"><a href="#失败模型" class="headerlink" title="失败模型"></a>失败模型</h4><p>app master被设计为一个<a href="https://www.usenix.org/legacy/events/hotos03/tech/full_papers/candea/candea.pdf" target="_blank" rel="external"> crash-only application</a>, client是随时可以直接请求YARN来终止app实例的。</p>
<p>有一个RPC方法可以停掉app实例。这个是挺好的，会记录一条message在日志里，以后可能还会给provider警告一下这个app实例要被关掉了。这也有一定潜在的危险，以你为provider实现里可能开始期望这个方法被可靠调用。slider的设计是失败不会告警，而是基于配置进行重新构建，可以被人工停止。</p>
<h4 id="RPC-接口"><a href="#RPC-接口" class="headerlink" title="RPC 接口"></a>RPC 接口</h4><p>RPC接口允许client查询当前app的状态，也能通过json请求进行更新。</p>
<p>主要操作有：</p>
<ul>
<li>getJSONClusterStatus(): 获取app实例的json状态输出</li>
<li>flexCluster(): 更新调整不同component的数量</li>
<li>stopCluster </li>
</ul>
<p>还有一些其他更low-level的操作供我们进行诊断、测试，但是比较有限。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/12/04/在yarn上安装presto/" title="在yarn上安装presto" itemprop="url">在yarn上安装presto</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-12-04T10:18:20.000Z" itemprop="datePublished"> 发表于 2017-12-04</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h4 id="前置条件"><a href="#前置条件" class="headerlink" title="前置条件"></a>前置条件</h4><ul>
<li>hdp 2.2+ 或者CDH5.4+</li>
<li>slider 0.80.0+</li>
<li>jdk 1.8</li>
<li>zookeeper</li>
<li>openssl &gt;= 1.0.1e-16</li>
<li>ambari 2.1</li>
</ul>
<h4 id="presto安装目录结构"><a href="#presto安装目录结构" class="headerlink" title="presto安装目录结构"></a>presto安装目录结构</h4><p>使用ambari slider view安装基于yarn的presto集群的时候，安装目录与标准的是不一样的。</p>
<p>如果使用slider脚本或者ambari slider view来部署presto到yarn上的话，presto是会使用presto server的tar包的形式进行安装的(不是通过rpm)。当yarn app启动后，可发现presto server安装在yarn上的nodemanager的<code>yarn.nodemanager.local-dirs</code>。例如，配置<code>yarn.nodemanager.local-dirs</code>为<code>/mnt/hadoop/nm-local-dirs</code>，且<code>app_user</code>配置为<code>yarn</code>，那么就安装在<code>/mnt/hadoop-hdfs/nm-local-dir/usercache/yarn/appcache/application_&lt;id&gt;/container_&lt;id&gt;/app/install/presto-server-&lt;version&gt;</code>。container_id之前的部分在slider中叫做AGENT_WORK_ROOT，也就是说<code>AGENT_WORK_ROOT/app/install/presto-server-&lt;version&gt;</code>。</p>
<p>通常，使用tar安装的presto，catalog、plugin、lib目录等都在presto-server主目录下。catalog目录在<code>AGENT_WORK_ROOT/app/install/presto-server-&lt;version&gt;/etc/catalog</code>, plugin和lib目录在<code>AGENT_WORK_ROOT/app/install/presto-server-&lt;version&gt;/plugin</code>和<code>AGENT_WORK_ROOT/app/install/presto-server-&lt;version&gt;/lib</code>.启动脚本在<code>AGENT_WORK_ROOT/app/install/presto-server-&lt;version&gt;/bin</code>.</p>
<p>presto日志是基于数据目录的配置的。</p>
<p>参考：<a href="https://prestodb.io/presto-yarn/installation-yarn-directory-structure.html" target="_blank" rel="external">https://prestodb.io/presto-yarn/installation-yarn-directory-structure.html</a></p>
<h4 id="presto配置"><a href="#presto配置" class="headerlink" title="presto配置"></a>presto配置</h4><p>安装过程中，ambari slider view允许你进行配置。</p>
<p>如果使用mabri进行安装，可以通过UI配置，如果是手动安装的话，就自己编辑配置文件。</p>
<p>主要配置文件为appConfig.json和resources-[singlenode|multinode].json，需要在运行presto之前配置好。在下面提出的位置有样例配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">presto-yarn-package/src/main/resources</div></pre></td></tr></table></figure></p>
<p><code>presto-yarn-package/src/main/resources/appConfig.json</code>和<code>presto-yarn-package/src/main/resources/resources-multinode.json</code>是对应的默认配置。</p>
<h5 id="appConfig-json"><a href="#appConfig-json" class="headerlink" title="appConfig.json"></a>appConfig.json</h5><ul>
<li>site.global.app_user。 默认是yarn，启动presto的用户。确认app_user要有一个HDFS home目录。如果要访问hive的话，也要确认这个app_user有相应的权限</li>
<li>site.global.user_group。默认是hadoop</li>
<li><p>site.global.data_dir。默认是<code>/var/lib/presto/data</code>，presto的数据目录，应该在启动之前就存在，并且是属于app_user，否则slider就会因权限问题不能启动了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mkdir -p /var/lib/presto/data</div><div class="line">chown -R yarn:hadoop /var/lib/presto/data</div></pre></td></tr></table></figure>
</li>
<li><p>site.global.config_dir,默认是/var/lib/presto/etc。presto配置文件所在的目录，包含node.properties, jvm.config, config.properties以及connector配置文件等。这些文件会从模板<code>presto-yarn-package/package/templates/*.j2</code>和相关appConfig.json的参数生成。</p>
</li>
<li>site.global.singlenode。默认true，当前node既做为coordinator也作为worker。</li>
<li>site.global.presto_query_max_memory。在config.properties文件中是query.max_memroy，默认50G.</li>
<li>site.global.presto_query_max_memory_per_node，默认1G</li>
<li>site.global.presto_server_port，默认8080</li>
<li>site.global.catalog.默认是tpch connector。这个是用来配置presto的connector的。应该对应于非基于yarn的presto集群的connector.properites。格式一般为：<code>{‘connector1’ : [‘key1=value1’, ‘key2=value2’..], ‘connector2’ : [‘key1=value1’, ‘key2=value2’..]..}.</code>。这个会创建connector1.properties, connector2.properties两个配置文件，带有不同的entry。看一个hive.properties的例子<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&quot;site.global.catalog&quot;: &quot;&#123;&apos;hive&apos;: [&apos;connector.name=hive-cdh5&apos;, &apos;hive.metastore.uri=thrift://$&#123;NN_HOST&#125;:9083&apos;], &apos;tpch&apos;: [&apos;connector.name=tpch&apos;]&#125;&quot;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>这里的NN_HOST运行时会被替换成NN的地址，如果hive metastore跟NN没在一起，需要自己修改一下。</p>
<ul>
<li><p>site.global.jvm_args。这个是生成presto的jvm.properties文件的，默认是heapsize是1G.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&quot;site.global.jvm_args&quot;: &quot;[&apos;-server&apos;, &apos;-Xmx1024M&apos;, &apos;-XX:+UseG1GC&apos;, &apos;-XX:G1HeapRegionSize=32M&apos;, &apos;-XX:+UseGCOverheadLimit&apos;, &apos;-XX:+ExplicitGCInvokesConcurrent&apos;, &apos;-XX:+HeapDumpOnOutOfMemoryError&apos;, &apos;-XX:OnOutOfMemoryError=kill -9 %p&apos;]&quot;,</div></pre></td></tr></table></figure>
</li>
<li><p>site.global.log_properties. 配置presto的日志级别默认是<code>[‘com.facebook.presto=INFO’]</code>。应该是一行一个表达式。例子</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&quot;site.global.log_properties&quot;: &quot;[&apos;com.facebook.presto.hive=WARN&apos;, &apos;com.facebook.presto.server=INFO&apos;]&quot;</div></pre></td></tr></table></figure>
</li>
<li><p>site.global.additional_node_properties和site.global.additional_config_properties。</p>
</li>
<li><p>site.global.plugin</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&quot;site.global.plugin&quot;: &quot;&#123;&apos;ml&apos;: [&apos;presto-ml-$&#123;presto.version&#125;.jar&apos;]&#125;&quot;,</div></pre></td></tr></table></figure>
</li>
<li><p>site.global.app_name</p>
</li>
<li>application.def. 对于slider用户，安装presto的命令运行的时候，日志会打印出这个参数。如果不是自定义的presto包，不必理会这个参数。</li>
<li>java_home ， 默认是/usr/lib/jvm/java</li>
<li>appConfig.json里的类似${COORDINATOR_HOST}, ${AGENT_WORK_ROOT}的变量是在运行时确认的。</li>
</ul>
<h5 id="resources-json"><a href="#resources-json" class="headerlink" title="resources.json"></a>resources.json</h5><p>这个配置可以对应于全局，也可以针对每个组件</p>
<ul>
<li>yarn.vcores: 默认是全局的，-1</li>
<li>yarn.component.instances，默认coordinator是-1，worker是3.多节点模式下的例子配置中<code>presto-yarn-package/src/main/resources/resources-multinode.json</code>是1个coordinator，3个worker。他们的分布有着较严格的策略，每个node上只会运行一个实例。当节点数不够申请的worker时，这个app就会失败。如果都用作presot节点的话，那么worker的数量应该是集群中的nodemanager数量 -1 ，留一个作为coordinator。</li>
<li>yarn.memory。默认1500M，是site.global.jvm_args的-Xmx参数，被presto的jvm所使用的。slider推荐要比这个大一些。yarn.memory应该比任何jvm申请的堆都要大一丢丢，推荐最少大50%。</li>
<li>yarn.label.expression. coordinator或者worker。</li>
</ul>
<p>参考：<a href="https://prestodb.io/presto-yarn/installation-yarn-configuration-options.html" target="_blank" rel="external">https://prestodb.io/presto-yarn/installation-yarn-configuration-options.html</a></p>
<h4 id="使用ambari-slider-view-安装基于yarn的presto集群"><a href="#使用ambari-slider-view-安装基于yarn的presto集群" class="headerlink" title="使用ambari slider view 安装基于yarn的presto集群"></a>使用ambari slider view 安装基于yarn的presto集群</h4><ol>
<li>安装ambari server</li>
<li>下载slider包</li>
<li>把presto包copy到ambari server的<code>/var/lib/ambari-server/resources/apps/</code>路径下</li>
<li>重启ambari-server</li>
<li>登陆ambari</li>
<li>安装基础组件：HDFS, YARN, Zk， Slider等</li>
<li>保证slider-env.sh里已经指定了JAVA_HOME和HADOOP_CONF_DIR。</li>
<li>对于zk，如果不是安装在/usr/lib/zookeeper:<ul>
<li>在slider配置里添加zk.home配置变量</li>
<li>如果不是2181端口，添加slider.zookeeper.quorum配置</li>
</ul>
</li>
<li>启动服务，到ambari创建slider view，然后创建app</li>
<li>提供presto服务的相关配置细节，UI会提供一些默认参数。</li>
<li>app名字应该是小写的：presto1</li>
<li>配置</li>
<li>准备slider的HDFS目录，这个根据global.app_user来的。</li>
<li>修改global.presto_server_port为8080之外的其他端口，以免跟ambari srever冲突</li>
<li>预创建所有节点上的数据目录<code>var/lib/presto</code>，可以自己修改</li>
<li>其他自定义配置</li>
<li>完成。这个动作相当于在bin/slider脚本执行package –install和create，然后就可以看到presto已经在yarn上运行起来了。<ul>
<li>从slider view监控运行状态</li>
<li>Quick Links，观察yarn UI</li>
</ul>
</li>
<li>如果job失败，可以到对应节点上找日志看</li>
<li>可以在View界面管理app的生命周期(start, stop, fliex, destory)。</li>
</ol>
<h4 id="手动使用slider安装presto集群"><a href="#手动使用slider安装presto集群" class="headerlink" title="手动使用slider安装presto集群"></a>手动使用slider安装presto集群</h4>
        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/27/tez笔记/" title="tez笔记" itemprop="url">tez笔记</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-27T10:47:27.000Z" itemprop="datePublished"> 发表于 2017-11-27</time>
    
  </p>
</header>
    <div class="article-content">
        
        <ol>
<li>部署hadoop2.7以上版本</li>
<li>构建tez<code>mvn clean package -DskipTests=true -Dmaven.javadoc.skip=true</code><ul>
<li>JDK8, MAVEN 3</li>
<li>protocol buffer 2.5.0</li>
<li>如果使用单元测试，把skipTests去掉就行</li>
<li>如果使用eclipse，可以使用import maven project引入。</li>
</ul>
</li>
<li>把对应的tez包copy到HDFS，配置tez-site.xml</li>
</ol>
<ul>
<li>tez包包含tez和hadoop的类库，tez-dist/tez-x.y.z-SNAPSHOT.tar.gz</li>
<li><p>假设tez放在了HDFS的/apps下，命令如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop fs -mkdir /apps/tez-x.y.z-SNAPSHOT</div><div class="line">hadoop fs -copyFromLocal tez-dist/target/tez-x.y.z-SNAPSHOT.tar.gz /apps/tez-x.y.z-SNAPSHOT</div></pre></td></tr></table></figure>
</li>
<li><p>tez-site.xml配置</p>
<ul>
<li>设置<code>tez.lib.uris</code>指定HDFS上的tar.gz的位置。假设是上面的话，就设置成<code>${fs.defaultFS}/apps/tez-x.y.z-SNAPSHOT/tez-x.y.z-SNAPSHOT.tar.gz</code></li>
<li>确认<code>tez.cluster.hadoop-libs</code>没有在tez-site.xml中设置，这个值应该是false</li>
</ul>
</li>
<li>注意tar包版本应该与用来提交tez job的客户端版本一致。</li>
</ul>
<ol>
<li>可选的：如果在tez上运行已经存在的MR任务，修改mapred-site.xml，修改mapreduce.framework.name, 从yarn修改为yarn-tez.</li>
<li>配置client节点，把tez类库加入到hadoop类库中。</li>
</ol>
<ul>
<li>抽取tez最小的tar包到本地目录</li>
<li>设置TEZ_CONF_DIR为tez-site.xml的位置</li>
<li><p>添加$TEZ_CONF_DIR，${TEZ_JARS}/<em>和${TEZ_JARS}/lib/</em>到app的classpath。例如通过标准hadoop工具链设置的话：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">export HADOOP_CLASSPATH=$&#123;TEZ_CONF_DIR&#125;:$&#123;TEZ_JARS&#125;/*:$&#123;TEZ_JARS&#125;/lib/*</div></pre></td></tr></table></figure>
</li>
<li><p>注意 <code>*</code>是必须的</p>
</li>
</ul>
<ol>
<li>下面是一个提交MR任务的例子：<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$HADOOP_PREFIX/bin/hadoop jar tez-examples.jar orderedwordcount &lt;input&gt; &lt;output&gt;</div></pre></td></tr></table></figure>
</li>
</ol>
<p>这个会使用tez dag ApplicationMaster来运行wordcount job。这个wordcount相比简单的，多了个按照词频顺序输出。</p>
<p>Tez DAG可以分别运行在不同的app上，使用同一个TEZ session就可以了。tez-tests中有一个odrderedwordcount是支持session的使用的，同时处理多个input-output pairs。可以在不同的input/output上连续运行多个DAG。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$HADOOP_PREFIX/bin/hadoop jar tez-tests.jar testorderedwordcount &lt;input1&gt; &lt;output1&gt; &lt;input2&gt; &lt;output2&gt; &lt;input3&gt; &lt;output3&gt; ...</div></pre></td></tr></table></figure>
<p>上面的例子就会为每个input-output pair运行多个DAG了。</p>
<p>要使用tez session的话，设置 -DUSE_TEZ_SESSION=true<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$HADOOP_PREFIX/bin/hadoop jar tez-tests.jar testorderedwordcount -DUSE_TEZ_SESSION=true &lt;input1&gt; &lt;output1&gt; &lt;input2&gt; &lt;output2&gt;</div></pre></td></tr></table></figure></p>
<ol>
<li>像平时一样提交一个MR任务<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$HADOOP_PREFIX/bin/hadoop jar hadoop-mapreduce-client-jobclient-3.0.0-SNAPSHOT-tests.jar sleep -mt 1 -rt 1 -m 1 -r 1</div></pre></td></tr></table></figure>
</li>
</ol>
<p>这会使用TEZ DAG ApplicationMaster来运行MR job。可以通过查看YARN UI上的AM的log来验证一下。记住，mapred-site.xml里的mapreduce.framework.name需要设置成yarn-tez。</p>
<h4 id="指定tez-lib-uris的几种方式"><a href="#指定tez-lib-uris的几种方式" class="headerlink" title="指定tez.lib.uris的几种方式"></a>指定tez.lib.uris的几种方式</h4><p>tez.lib.uris属性支持逗号分隔的多个值，可以是单个文件，一个目录，压缩包(tar,zip等)。</p>
<p>对于文件和目录，tez会把第一层的文件放到tez运行时的工作目录中，然后放入classpath。对于压缩文件，会被解压到工作目录中。</p>
<h4 id="hadoop依赖安装"><a href="#hadoop依赖安装" class="headerlink" title="hadoop依赖安装"></a>hadoop依赖安装</h4><p>上面的使用tez的方式，也就是预装在hadoop类库中是我们推荐的方式。带有所有依赖的完整的tar包是一个更好的方式，可以保证已经存在的job在集群回滚或者升级的时候继续正常运行。</p>
<p>尽管<code>tez.lib.uris</code>配置项有很广泛的使用模型，但是还有两个主要的可选模式:</p>
<ul>
<li>A： 在hadoop类库可用的集群上使用tez tar包</li>
<li><p>B： 与hadoop tar包一起使用tez tar包</p>
<p>这两个模式需要一个没有hadoop依赖而编译地的tez，可以是tez-dist/target/tez-x.y.z-minimal.tar.gz。</p>
<h4 id="对于模式A：通过yarn-application-classpath使用集群已有的hadoop类库"><a href="#对于模式A：通过yarn-application-classpath使用集群已有的hadoop类库" class="headerlink" title="对于模式A：通过yarn.application.classpath使用集群已有的hadoop类库"></a>对于模式A：通过yarn.application.classpath使用集群已有的hadoop类库</h4><p>对于使用rolling  upgrade的集群不推荐这种方式。另外，用户需要负责保证tez版本与正在运行集群的hadoop的兼容性。对于上面的第三个步骤，也需要修改。后续的步骤应该使用tez-dist/target/tez-x.y.z-minimal.tar.gz而不是tez-dist/target/tez-x.y.z.tar.gz。</p>
<ul>
<li><p>如果tez jar已经放在了HDFS的/apps里，那么minimal的tez就可以运行了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"> &quot;hadoop fs -mkdir /apps/tez-x.y.z&quot;</div><div class="line">&quot;hadoop fs -copyFromLocal tez-dist/target/tez-x.y.z-minimal.tar.gz /apps/tez-x.y.z&quot;</div></pre></td></tr></table></figure>
</li>
<li><p>tez-site.xml配置</p>
<ul>
<li>设置tez.lib.uris为hdfs包含tez jar的位置。</li>
<li>设置tez.use.cluster.hadoop-libs为true</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="对于模式B：带有hadoo-tar包的tez-tar包"><a href="#对于模式B：带有hadoo-tar包的tez-tar包" class="headerlink" title="对于模式B：带有hadoo tar包的tez  tar包"></a>对于模式B：带有hadoo tar包的tez  tar包</h4><p>这个模式是支持rolling upgrade的。但是用户需要确认自己选择的tez和hadoop版本兼容。也需要修改第三步：</p>
<ul>
<li><p>假设tez的压缩包在HDFS的/apps下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop fs -mkdir /apps/tez-x.y.z </div><div class="line">hadoop fs -copyFromLocal tez-dist/target/tez-x.y.z-minimal.tar.gz /apps/tez-x.y.z</div></pre></td></tr></table></figure>
</li>
<li><p>或者，可以把minimal目录直接放到HDFS，然后再把每个jar包放进去。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoop fs -copyFromLocal tez-dist/target/tez-x.y.z-minimal/* /apps/tez-x.y.z</div></pre></td></tr></table></figure>
</li>
<li><p>构建完hadoop之后，hadoop tar包在hadoop/hadoop-dist/target/hadoop-x.y.z-SNAPSHOT.tar.gz</p>
</li>
<li><p>假设hadoop jar包放在了HDFS上的/apps里</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop fs -mkdir /apps/hadoop-x.y.z</div><div class="line">hadoop fs -copyFromLocal hadoop-dist/target/hadoop-x.y.z-SNAPSHOT.tar.gz /apps/hadoop-x.y.z</div></pre></td></tr></table></figure>
</li>
<li><p>tez-site.xml的配置</p>
<ul>
<li>tez.lib.uris只想tez/hadoop需要的jar或者归档文件所在位置</li>
<li>例子：当时用tez和hadoop归档文件时，设置tez.lib.uris为<code>${fs.defaultFS}/apps/tez-x.y.z/tez-x.y.z-minimal.tar.gz#tez,${fs.defaultFS}/apps/hadoop-x.y.z/hadoop-x.y.z-SNAPSHOT.tar.gz#hadoop-mapreduce</code></li>
<li>例子：当时用带有hadoop归档文件的tezjar的时候，设置tez.lib.uris为<code>${fs.defaultFS}/apps/tez-x.y.z,${fs.defaultFS}/apps/tez-x.y.z/lib,${fs.defaultFS}/apps/hadoop-x.y.z/hadoop-x.y.z-SNAPSHOT.tar.gz#hadoop-mapreduce</code></li>
<li>在tez.lib.uris中，跟在<code>#</code>后面的文档会自动创建对应的fragment 链接。如果没有给出fragment，那么链接就被设置为归档的名字。fragment不应该是目录或者jar</li>
<li>如果在tez.lib.uris中指定了任何归档，就也要设置tez.lib.uris.classpath，定义好这些归档文件的classpath，因为归档文件结构是未知的。</li>
<li><p>例子：当使用tez和hadoop归档时，设置tez.lib.uris.classpath：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./tez/*:./tez/lib/*:./hadoop-mapreduce/hadoop-x.y.z-SNAPSHOT/share/hadoop/common/*:./hadoop-mapreduce/hadoop-x.y.z-SNAPSHOT/share/hadoop/common/lib/*:./hadoop-mapreduce/hadoop-x.y.z-SNAPSHOT/share/hadoop/hdfs/*:./hadoop-mapreduce/hadoop-x.y.z-SNAPSHOT/share/hadoop/hdfs/lib/*:./hadoop-mapreduce/hadoop-x.y.z-SNAPSHOT/share/hadoop/yarn/*:./hadoop-mapreduce/hadoop-x.y.z-SNAPSHOT/share/hadoop/yarn/lib/*:./hadoop-mapreduce/hadoop-x.y.z-SNAPSHOT/share/hadoop/mapreduce/*:./hadoop-mapreduce/hadoop-x.y.z-SNAPSHOT/share/hadoop/mapreduce/lib/*</div></pre></td></tr></table></figure>
</li>
<li><p>例子：当使用tez jar和hadoop归档文件时，设置tez.lib.uris.classpath为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./hadoop-mapreduce/hadoop-x.y.z-SNAPSHOT/share/hadoop/common/*:./hadoop-mapreduce/hadoop-x.y.z-SNAPSHOT/share/hadoop/common/lib/*:./hadoop-mapreduce/hadoop-x.y.z-SNAPSHOT/share/hadoop/hdfs/*:./hadoop-mapreduce/hadoop-x.y.z-SNAPSHOT/share/hadoop/hdfs/lib/*:./hadoop-mapreduce/hadoop-x.y.z-SNAPSHOT/share/hadoop/yarn/*:./hadoop-mapreduce/hadoop-x.y.z-SNAPSHOT/share/hadoop/yarn/lib/*:./hadoop-mapreduce/hadoop-x.y.z-SNAPSHOT/share/hadoop/mapreduce/*:./hadoop-mapreduce/hadoop-x.y.z-SNAPSHOT/share/hadoop/mapreduce/lib/*</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/27/hive2-LLAP/" title="hive2-LLAP" itemprop="url">hive2-LLAP</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-27T06:59:23.000Z" itemprop="datePublished"> 发表于 2017-11-27</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>Live Long And Process。</p>
<h4 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h4><p>最近几年，有了tez和CBO等机制，hive的运行速度与特性已经有了很大提升。这次2.0又把hive带入了一个新的level</p>
<ul>
<li>异步spindle-aware的IO</li>
<li>预抽取column chunk，缓存column chunk</li>
<li>多线程JIT友好的operator pipeline</li>
</ul>
<p>上面的特性就是LLAP提供的了，LLAP提供了一个混合引擎模型。它包含了一个长期存在的daemon，替代直接与HDFS的Datanode交互。还有一个与DAG紧密结合的framework。对于缓存、字段pre-fetching、query的执行与ACL都被移动到了daemon中。small/short的query大部分都会被送到这个daemon直接处理，其他稍微重一些的操作都会被YARN的container运行。</p>
<p>跟DataNode类似，LLAP deamon也可以被其他的app使用，尤其是基于文件处理的关系型数据view。这个daemon也提供了可选的API(例如InputFormat)，供其它数据处理框架作为一个构建的block。</p>
<p>最后，细粒度的字段级别的acl在这个model中也得到了完美的呈现。</p>
<p>下图显示了LLAP的一个执行样例。Tez AM负责整体的编排工作。query的初始化stage被push给了LLAP。reduce stage，大的shuffle操作是在几个container中执行的。多个查询和app可以并发访问LLAP。</p>
<p><img src="https://cwiki.apache.org/confluence/download/attachments/62689557/LLAP_diagram.png?version=1&amp;modificationDate=1474327021000&amp;api=v2" alt=""></p>
<h4 id="持久化daemon"><a href="#持久化daemon" class="headerlink" title="持久化daemon"></a>持久化daemon</h4><p>为了进一步优化缓存和JIT，还有能够更好的估算startup耗时等，集群中的worker节点上都会有一个daemon。这个daemon处理IO,缓存，query分片的执行。</p>
<ul>
<li>所有的node都是无状态的。任何发送给LLAP节点的request都包含数据的位置和元信息。可以是本地的位置，也可以是远程的，数据本地化是调用者需要考虑的事情(YARN)</li>
<li>recovery/resilency。失败和恢复都很简单，因为任何数据家电都可以用来处理输入数据的任何分片。Tez AM只需要简单的重新运行失败的分片即可。</li>
<li>节点间沟通。LLAP节点之间可以共享数据(例如抽取partition数据，广播数据分片等)。实现方式与Tez中一样的。</li>
</ul>
<h5 id="执行引擎"><a href="#执行引擎" class="headerlink" title="执行引擎"></a>执行引擎</h5><p>LLAP和已经存在的，基于过程的hive引擎是可以兼容的，保留了hive的可扩展性和广泛性。它并没有取代已经存在的执行模型，而是对其进行增强。</p>
<ul>
<li>daemon是可选的。在没有这些daemon的时候，hive仍然是可运行的。</li>
<li>外部编排和执行引擎。LLAP并不是一个像Tez或者MR的执行引擎。所有的执行都是被已经存在的hive执行引擎（比如tez）在LLAP节点上进行调度与监控的，跟普通的container一样。显然，LLAP级别的支持是基于每个执行引擎(目前是tez)的。MR的支持并没有计划，但是其他的引擎有可能会在后面也加入进来。其他的框架，例如pig，也可以选择使用LLAP daemon。</li>
<li>部分执行。LLAP daemon的执行结果可以说某个hive query的结果的一部分，也可以传递给外部的hive task，这个取决于具体的query</li>
<li>资源管理。YARN仍然负责资源的管理与分发。yarn container delegation被用来允许分配资源给LLAP。为了避免jvm内存设置的初始化，缓存的数据是放在off-heap的，大的buffer也是(比如groupby，join等操作)。通过这种方案，daemon可以只是用很小的内存，其他资源(CPU,内存等)会根据负载进行分发。</li>
</ul>
<h4 id="query-fragment执行"><a href="#query-fragment执行" class="headerlink" title="query fragment执行"></a>query fragment执行</h4><p>LLAP节点会执行一些query分片，比如filter，projection，数据转化，部分聚合，排序，分桶，hash join/semi-join等。在LLAP中只接受hive代码和udf。没有任何代码是可以在运行时生成和执行的。这是出于稳定性和安全性的考虑。</p>
<ul>
<li>并发执行。一个LLAP节点允许不同query和session 的多个查询分片的并发执行。</li>
<li>interface。用户可以通过client API直接访问LLAP节点。他们可以指定关系转化，然后通过面向record的stream进行数据读取。</li>
</ul>
<h4 id="IO"><a href="#IO" class="headerlink" title="IO"></a>IO</h4><p>daemon摆脱了压缩格式处理的IO，这些工作交给其他独立的线程。数据在就绪的时候会被传递给execution，就是说前一批数据正在被处理的同时，就可以准备下一批了。数据是以简单的RLE编码的列式格式传递给execution的，主要是为了后面方便进行vectorized processiong【向量化处理？】。这也是缓存的格式，可以减小IO，缓存，execution之间的copy流量。</p>
<ul>
<li>多种文件格式。IO和缓存依赖于已经存在的文件格式(越高效越好)。因此，和vectorization工作类似，不同的文件格式都会通过插件形式被支持(目前是ORC)。另外，一个通用的，不那么搞笑的插件也可以加进来支持任意的hive输入格式。这些插件必须负责持有元信息，并且把原始数据转化到column chunk。</li>
<li>预测和bloom filter。SARGs和bloom filter是会被push down到存储层的。</li>
</ul>
<h4 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h4><p>daemon会缓存输入文件和数据的元数据。即便数据还没有缓存，元数据和索引信息也是可以先缓存起来的。元数据是以java object的形式存在进程的，缓存的数据是根据<a href="https://cwiki.apache.org/confluence/display/Hive/LLAP#LLAP-I/O" target="_blank" rel="external">IO部分</a>的指定形式，保存在off-heap的。</p>
<ul>
<li>驱逐策略【eviction policy】。取出策略是为了调优负载，应对频繁的表扫面的。初始阶段，是使用了LRFU的简单策略。这个策略是可插拔的。</li>
<li>缓存粒度。column-chunk是缓存数据的基本单位。这是在低开销的处理与高效存储之间的一个权衡。chunk的粒度取决于文件格式和执行引擎了。(Vectorized Row Batch Size, ORC stripe等)</li>
</ul>
<p>bloomfilter会自动创建，以提供动态运行时过滤。</p>
<h4 id="workload管理"><a href="#workload管理" class="headerlink" title="workload管理"></a>workload管理</h4><p>YARN用来获取不同workload的资源。某个workload一旦获取到yarn分配的资源之后，这个执行引擎就可以选择把资源代理给LLAP，或者在单独的进程里启动hive executor。通过YARN的资源管理保证了节点不会过载运行，不管是因为LLAP或者其他container。daemon本身也是在YARN的控制之下的。</p>
<h4 id="ACID支持"><a href="#ACID支持" class="headerlink" title="ACID支持"></a>ACID支持</h4><p>LLAP是事务感知的。在数据放入缓存之前，将delta文件合并，可以生成一个table的特定的state。如果有多版本，可以在请求中指定使用哪个版本。这样的好处是可以异步merge，而且只用cache一次数据，从而避免了operator pipeline的攻击。</p>
<h4 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h4><p>LLAP server是一个很自然的就可以进行acl的地方，比per-file的控制粒度还要细。因为LLAP的daemon知道当前要处理的column和record，所有针对这俩东西的策略都可以在这里实施。这并不会替代已有的安全机制，但是会有所增强，也可以提供给其他框架使用。</p>
<h4 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h4><p>LLAP监控的配置是存储在resources.json， appConfig.json， metainfo.xml，都会存在于slider的templates.py中。</p>
<p>LLAP monitor daemon也运行在YARN container中，跟LLAP Daemon一样，而且默认监听同样的端口。</p>
<p>LLAP Metric Collection Server从所有的LLAP Daemon周期性地收集JMX metric</p>
<p>LLAP daemon列表是在启动集群的zookeeper中抽取的。</p>
<h4 id="web-service"><a href="#web-service" class="headerlink" title="web service"></a>web service</h4><ul>
<li>json jmx数据 - /jmx</li>
<li>jvm stack trace - /stacks</li>
<li>LLAP daemon的xml配置 - /conf</li>
<li>LLAP status - /status</li>
<li>LLAP Peers - /peers</li>
</ul>
<h4 id="在slider上部署"><a href="#在slider上部署" class="headerlink" title="在slider上部署"></a>在slider上部署</h4><p>LLAP可以通过slider进行部署，绕过了节点安装与相关复杂处理</p>
<h4 id="LLAP-status"><a href="#LLAP-status" class="headerlink" title="LLAP status"></a>LLAP status</h4><p><a href="https://issues.apache.org/jira/browse/AMBARI-16149" target="_blank" rel="external">ambari相关</a>介绍了LLAP ap的状态，在hiveserver2中可用了。</p>
<p>例子<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">/current/hive-server2-hive2/bin/hive --service llapstatus --name &#123;llap_app_name&#125; [-f] [-w] [-i] [-t]</div><div class="line">-f,--findAppTimeout &lt;findAppTimeout&gt;                 Amount of time(s) that the tool will sleep to wait for the YARN application to start. negative values=wait</div><div class="line">                                                     forever, 0=Do not wait. default=20s</div><div class="line">-H,--help                                            Print help information</div><div class="line">   --hiveconf &lt;property=value&gt;                       Use value for given property. Overridden by explicit parameters</div><div class="line">-i,--refreshInterval &lt;refreshInterval&gt;               Amount of time in seconds to wait until subsequent status checks in watch mode. Valid only for watch mode.</div><div class="line">                                                     (Default 1s)</div><div class="line">-n,--name &lt;name&gt;                                     LLAP cluster name</div><div class="line">-o,--outputFile &lt;outputFile&gt;                         File to which output should be written (Default stdout)</div><div class="line">-r,--runningNodesThreshold &lt;runningNodesThreshold&gt;   When watch mode is enabled (-w), wait until the specified threshold of nodes are running (Default 1.0</div><div class="line">                                                     which means 100% nodes are running)</div><div class="line">-t,--watchTimeout &lt;watchTimeout&gt;                     Exit watch mode if the desired state is not attained until the specified timeout. (Default 300s)</div><div class="line">-w,--watch                                           Watch mode waits until all LLAP daemons are running or subset of the nodes are running (threshold can be</div><div class="line">                                                     specified via -r option) (Default wait until all nodes are running)</div></pre></td></tr></table></figure></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/22/hive2---轻松更新hive表2/" title="hive2---轻松更新hive表2" itemprop="url">hive2---轻松更新hive表2</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-22T09:58:13.000Z" itemprop="datePublished"> 发表于 2017-11-22</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>前面讲了使用MERGE,UPDATE,DELETE更新hive数据。现在我们进一步谈一下hive管理slowly-changing dimensions(SCDs，就是缓慢更新的维度表)的策略。在数据仓库中，SCDs更新数据是无规律的。对应于不同的业务需求，有不同的策略。假如你要一个用户维度表的所有历史，以跟踪某个用户随时间的变化情况。还有些情况，我们只关心最新的维度状态 。</p>
<p>下面是三种SCD更新策略：</p>
<ul>
<li>使用新数据覆盖旧数据。很简单，如果只是要同步最新状态的话，就用这个，但是会丢失历史维度值。</li>
<li>添加带有version的新数据行。可以追踪到所有历史。但是随着时间的退役，可能会特别大，还有就是查询的时候需要只看最新版本的维度值。</li>
<li>添加新数据行，管理有限版本的历史。有一些历史数据，然是控制在一定范围内。</li>
<li></li>
</ul>
<p>这个blog是讲一下怎样使用hive的MERGE来管理SCD。所有的例子都可以在<a href="https://github.com/cartershanklin/hive-scd-examples" target="_blank" rel="external">这里</a>找到。管理SCD是很麻烦的事情，所以最好能够用一些工作，比如<a href="https://www.amazon.com/Data-Warehouse-Toolkit-Complete-Dimensional/dp/0471200247" target="_blank" rel="external">数仓工具</a></p>
<h4 id="SCD管理策略一览"><a href="#SCD管理策略一览" class="headerlink" title="SCD管理策略一览"></a>SCD管理策略一览</h4><p><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/1Slowly-changing-dimensions-1024x695.png" alt=""></p>
<h4 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h4><p>所有的是例子都是从一个外部表，copy到hive的managed table，这个managed table就是merge target。第二个外部表，代表第二次从某个系统全量dump出来的数据。这两个外部表是一样的csv文件，包含字段:ID,Name, Email,State。初始化的数据有1000条，第二次数据有1100条，其中包含100个新纪录和93个需要更新项。</p>
<h4 id="第一种策略"><a href="#第一种策略" class="headerlink" title="第一种策略"></a>第一种策略</h4><p>有就直接替换，没有就添加。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">merge into</div><div class="line"> contacts_target</div><div class="line">using</div><div class="line"> contacts_update_stage as stage</div><div class="line">on</div><div class="line"> stage.id = contacts_target.id</div><div class="line">when matched then</div><div class="line"> update set name = stage.name, email = stage.email, state = stage.state</div><div class="line">when not matched then</div><div class="line"> insert values (stage.id, stage.name, stage.email, stage.state);</div></pre></td></tr></table></figure>
<p>值得注意的是，上面的操作也是单独一个，是原子且独立的，如果出现错误会正确rollback。在SQL-on-Hasdoop方式里提供这些特性是很困难的，但是hive的MERGE操作就实现了。</p>
<h4 id="第二种策略"><a href="#第二种策略" class="headerlink" title="第二种策略"></a>第二种策略</h4><p>保留所有的历史版本，提供单独的版本相关字段:ValidFrom, ValidTo。</p>
<p><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/2Hive-Type-2_1-1024x319.png" alt=""></p>
<p>我们可以使用这个策略来满足并发用户对于正在更新的数据的数据读取。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">merge into contacts_target</div><div class="line">using (</div><div class="line"> — The base staging data.</div><div class="line"> select</div><div class="line">contacts_update_stage.id as join_key,</div><div class="line">contacts_update_stage.* from contacts_update_stage</div><div class="line"> union all</div><div class="line">— Generate an extra row for changed records.</div><div class="line"> — The null join_key forces records down the insert path.</div><div class="line"> select</div><div class="line">   null, contacts_update_stage.*</div><div class="line"> from</div><div class="line">   contacts_update_stage join contacts_target</div><div class="line">   on contacts_update_stage.id = contacts_target.id</div><div class="line"> where</div><div class="line">   ( contacts_update_stage.email &lt;&gt; contacts_target.email</div><div class="line">     or contacts_update_stage.state &lt;&gt; contacts_target.state )</div><div class="line">   and contacts_target.valid_to is null</div><div class="line">) sub</div><div class="line">on sub.join_key = contacts_target.id</div><div class="line">when matched</div><div class="line"> and sub.email &lt;&gt; contacts_target.email or sub.state &lt;&gt; contacts_target.state</div><div class="line"> then update set valid_to = current_date()</div><div class="line">when not matched</div><div class="line"> then insert</div><div class="line"> values (sub.id, sub.name, sub.email, sub.state, current_date(), null);</div></pre></td></tr></table></figure>
<p>需要注意的是，using语句中对于每个更新的row会输出2个record。这些record会有一个null join key(就会成为一个insert了), 还会有一个valid jonk key(这是一个update)。如果都过去i安眠文章的话，其实有类似于在分区之间移动数据，只不过是使用update而不是delete。</p>
<p>看下93条记录的情况。<br><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/2Hive-Type-2_2-1024x304.png" alt=""></p>
<h4 id="第三种类型"><a href="#第三种类型" class="headerlink" title="第三种类型"></a>第三种类型</h4><p>第二种类型其实挺强大的了，不过比较复杂，而且维度表会无限增长下去。第三种策略中维度表基本跟数据源大小差不多，但是只提供部分历史。</p>
<p>下面我们就只保存上一个版本的纬度值</p>
<p><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/3Hive-Type-3_1.png" alt=""></p>
<p>当update的时候，我们任务就是把当前的版本放到last的值里。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">merge</span> <span class="keyword">into</span></div><div class="line"> contacts_target</div><div class="line"><span class="keyword">using</span></div><div class="line"> contacts_update_stage <span class="keyword">as</span> stage</div><div class="line"><span class="keyword">on</span> stage.id = contacts_target.id</div><div class="line"><span class="keyword">when</span> <span class="keyword">matched</span> <span class="keyword">and</span></div><div class="line"> contacts_target.email &lt;&gt; stage.email</div><div class="line"> <span class="keyword">or</span> contacts_target.state &lt;&gt; stage.state — <span class="keyword">change</span> detection</div><div class="line"> <span class="keyword">then</span> <span class="keyword">update</span> <span class="keyword">set</span></div><div class="line"> last_email = contacts_target.email, email = stage.email, — email history</div><div class="line"> last_state = contacts_target.state, state = stage.state  — state history</div><div class="line"><span class="keyword">when</span> <span class="keyword">not</span> <span class="keyword">matched</span> <span class="keyword">then</span> <span class="keyword">insert</span></div><div class="line"> <span class="keyword">values</span> (stage.id, stage.name, stage.email, stage.email,</div><div class="line"> stage.state, stage.state);</div></pre></td></tr></table></figure>
<p>我们看到相比第二种策略，这种就简单多了。</p>
<p><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/3Hive-Type-3_2.png" alt=""></p>
<h4 id="一个更简单的变化追踪方法"><a href="#一个更简单的变化追踪方法" class="headerlink" title="一个更简单的变化追踪方法"></a>一个更简单的变化追踪方法</h4><p>如果有很多字段需要比较，那么对于变化的探测逻辑会比较笨重。幸运的是，hive引入了一个hash UDF让这个变得简单，可以接收任意数量的参数，然会一个checksum。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">merge into</div><div class="line"> contacts_target</div><div class="line">using</div><div class="line"> contacts_update_stage as stage</div><div class="line">on stage.id = contacts_target.id</div><div class="line">when matched and</div><div class="line"> hash(contacts_target.email, contacts_target.state) &lt;&gt;</div><div class="line">   hash(stage.email, stage.state)</div><div class="line"> then update set</div><div class="line"> last_email = contacts_target.email, email = stage.email, — email history</div><div class="line"> last_state = contacts_target.state, state = stage.state  — state history</div><div class="line">when not matched then insert</div><div class="line"> values (stage.id, stage.name, stage.email, stage.email,</div><div class="line"> stage.state, stage.state);</div></pre></td></tr></table></figure>
<p>好处就是，不管有多少个字段要比较，我们对于代码的修改可以几乎没有。</p>
<h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>SCD管理是数据仓库机器重要的概念，是一个有很多策略和方法实现的子模块。有了ACID MERGE，hive让我们在hadoop上管理SCD变的简单。</p>
<p>参考：<a href="https://zh.hortonworks.com/blog/update-hive-tables-easy-way-2/" target="_blank" rel="external">https://zh.hortonworks.com/blog/update-hive-tables-easy-way-2/</a></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/22/hive2---轻松更新hive表1/" title="hive2---轻松更新hive表1" itemprop="url">hive2---轻松更新hive表1</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-22T09:07:16.000Z" itemprop="datePublished"> 发表于 2017-11-22</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>首先是merge、insert、update、delete。</p>
<p>以前，让hive里的数据持续更新是需要很复杂的成本的，很难去维护与执行。HDP2.6借助hive里的merge语法彻底地简化了数据维护成本，完成了INSERT, UPDATE, DELETE能力。</p>
<p>这个blog会说明怎样解释以下三种问题：</p>
<ul>
<li>hive update，从RDBMS同步数据到hive</li>
<li>更新hive里数据的分区</li>
<li>选择性地mask或者purge数据</li>
</ul>
<h4 id="基础操作：SQL-MERGE-UPDATE-AND-DELETE"><a href="#基础操作：SQL-MERGE-UPDATE-AND-DELETE" class="headerlink" title="基础操作：SQL MERGE, UPDATE AND DELETE"></a>基础操作：SQL MERGE, UPDATE AND DELETE</h4><p>MERGE是SQL 2008标准里的，是一个强大的SQL语句，它可以在同一个statement中inert，update，delete数据。MERGE让两个系统一致性工作变得简单。咱们看一下MERGE的语法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">MERGE INTO &lt;target table&gt;</div><div class="line"> USING &lt;table reference&gt;</div><div class="line">ON &lt;search condition&gt;</div><div class="line"> &lt;merge when clause&gt;...</div><div class="line">WHEN MATCHED [ AND &lt;search condition&gt; ]</div><div class="line">THEN &lt;merge update or delete specification&gt;</div><div class="line">WHEN NOT MATCHED [ AND &lt;search condition&gt; ]</div><div class="line">THEN &lt;merge insert specification&gt;</div></pre></td></tr></table></figure></p>
<p>WHEN MATCHED/WHEN NOT MATCHED语句可以无限量的。</p>
<p>我们也会使用到比较熟悉的UPDATE，语法<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">UPDATE &lt;target table&gt;</div><div class="line">SET &lt;set clause list&gt;</div><div class="line">[ WHERE &lt;search condition&gt; ]</div></pre></td></tr></table></figure></p>
<p>当没必要把insert 和update的数据在一个sql statement里进行合并的时候，就可以使用update了。</p>
<h4 id="保持数据fresh"><a href="#保持数据fresh" class="headerlink" title="保持数据fresh"></a>保持数据fresh</h4><p>在HDP2.6中，需要先做两个工作：</p>
<ul>
<li>开启Hive transaction。</li>
<li>我们table必须是一个transactional table。就是说这个table必须是clustered的，必须是ORCFile存储格式，而且有一个table属性：transactional=true。下面是一个例子：<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">create table customer_partitioned</div><div class="line"> (id int, name string, email string, state string)</div><div class="line"> partitioned by (signup date)</div><div class="line"> clustered by (id) into 2 buckets stored as orc</div><div class="line"> tblproperties(&quot;transactional&quot;=&quot;true&quot;);</div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="例1：HIVE-UPSERT"><a href="#例1：HIVE-UPSERT" class="headerlink" title="例1：HIVE UPSERT"></a>例1：HIVE UPSERT</h4><p>假设我们有一个源数据库，想要load进hadoop来运行ing大批量的分析。这个RDBMS中的数据不断的被添加和修改，而且并没有log告诉你哪些数据有变化【就是说没有binlog】。最简单的处理就是每24小时完整的copy一下这个RDBMS的数据镜像。</p>
<p><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/RDBMS-Source.png" alt=""></p>
<p>下面我们创建table：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">create table customer_partitioned</div><div class="line">(id int, name string, email string, state string)</div><div class="line"> partitioned by (signup date)</div><div class="line"> clustered by (id) into 2 buckets stored as orc</div><div class="line"> tblproperties(&quot;transactional&quot;=&quot;true&quot;);</div></pre></td></tr></table></figure></p>
<p>假设我们的数据在Time = 1的时候是这样的：<br><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/Time-equals-1.png" alt=""></p>
<p>在Time = 2的时候是这样的<br><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/Time-equals-2.png" alt=""></p>
<p>Upsert操作是吧update和insert放在一个操作里，这样我们就不用关心这些数据是不是原来就已经存在于目标table中。MERGE就是用来做这个事情的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">merge into customer_partitioned</div><div class="line"> using all_updates on customer_partitioned.id = all_updates.id</div><div class="line"> when matched then update set</div><div class="line">   email=all_updates.email,</div><div class="line">   state=all_updates.state</div><div class="line"> when not matched then insert</div><div class="line">   values(all_updates.id, all_updates.name, all_updates.email,</div><div class="line">   all_updates.state, all_updates.signup);</div></pre></td></tr></table></figure></p>
<p>注意我们的两个when条件语句是用来管理update或者insert的。在merge过后，这个managed table就与Time=2的staged Table完全一样了，而且所有数据也都在其对应的分区中。</p>
<h4 id="例2：更新hive-partition"><a href="#例2：更新hive-partition" class="headerlink" title="例2：更新hive partition"></a>例2：更新hive partition</h4><p>hive中很多会用日期作为partition策略。这样可以简化数据加载，提升性能。只是有时我们偶尔会出现数据进入错误的分区的情形。例如，假设用户数据是由一个第三方提供的，里面包含一个用户的singup日期。如果这个第三方数据提供者提供的数据开始有问题，后面又修正了，那么前面的在错误分区里的数据就应该被清除了。</p>
<p><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/update-hive-partitions.png" alt="初始数据"></p>
<p><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/second-load.png" alt="修复后的数据"></p>
<p>注意到ID为2的数据第一次跟第二次的signup日期是不一样的，这就需要更新2017-01-08分区，从里面把它删除，然后把它加入到2017-01-10里面去。</p>
<p>在MERGE出现之前，基本不可能管理这些分区裱花的。Hive的MERGE statement不是原生支持更新partition key，但是有一个小的技巧。 We introduce a delete marker which we set any time the partition keys and UNION this with a second query that produces an extra row on-the-fly for each of these non-matching records.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">merge into customer_partitioned</div><div class="line"> using (</div><div class="line">-- Updates with matching partitions or net new records.</div><div class="line">-- 更新符合分区的或者</div><div class="line">select</div><div class="line">  case</div><div class="line">       when all_updates.signup &lt;&gt; customer_partitioned.signup then 1</div><div class="line">       else 0</div><div class="line">     end as delete_flag,</div><div class="line">     all_updates.id as match_key,</div><div class="line">     all_updates.* from</div><div class="line">    all_updates left join customer_partitioned</div><div class="line">   on all_updates.id = customer_partitioned.id</div><div class="line">      union all</div><div class="line"></div><div class="line"> -- Produce new records when partitions don’t match.</div><div class="line"> -- 分区不匹配的时候，生成新的record</div><div class="line">     select 0, null, all_updates.*</div><div class="line">     from all_updates, customer_partitioned where</div><div class="line">     all_updates.id = customer_partitioned.id</div><div class="line">     and all_updates.signup &lt;&gt; customer_partitioned.signup</div><div class="line"> ) sub</div><div class="line">on customer_partitioned.id = sub.match_key</div><div class="line"> when matched and delete_flag=1 then delete</div><div class="line"> when matched and delete_flag=0 then</div><div class="line">   update set email=sub.email, state=sub.state</div><div class="line"> when not matched then</div><div class="line">   insert values(sub.id, sub.name, sub.email, sub.state, sub.signup);</div></pre></td></tr></table></figure></p>
<p>在MERGE处理过这个managed table之后，它就跟源数据表完全一致了。虽然过程中有分区的修改，但是这是一个操作，是原子、且独立的操作。</p>
<h4 id="例3：mask或者purge-hive的数据"><a href="#例3：mask或者purge-hive的数据" class="headerlink" title="例3：mask或者purge hive的数据"></a>例3：mask或者purge hive的数据</h4><p>假设有一天你们公司的安全部门过来，让我们把某个用户的所有数据进行mask或者purge操作。那么我们就需要花费很长的时间对很多收到影响的分区进行数据重写。</p>
<p>假设有一个contact table<br><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/contracts-table.png" alt=""></p>
<p>我们对应的hive表是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">create table contacts</div><div class="line"> (id int, name string, customer string, phone string)</div><div class="line"> clustered by (id) into 2 buckets stored as orc </div><div class="line">tblproperties(&quot;transactional&quot;=&quot;true&quot;);</div></pre></td></tr></table></figure></p>
<p>安全部门提出以下要求：</p>
<h5 id="把MaxLeads的所有的电话号码mask掉"><a href="#把MaxLeads的所有的电话号码mask掉" class="headerlink" title="把MaxLeads的所有的电话号码mask掉"></a>把MaxLeads的所有的电话号码mask掉</h5><p>我们可以使用hive内置的mask方法<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">update contacts set phone = mask(phone) where customer = &apos;MaxLeads&apos;;</div></pre></td></tr></table></figure></p>
<h5 id="把所有LeadMax的记录都purge掉"><a href="#把所有LeadMax的记录都purge掉" class="headerlink" title="把所有LeadMax的记录都purge掉"></a>把所有LeadMax的记录都purge掉</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">delete from contacts where customer = &apos;LeadMax&apos;;</div></pre></td></tr></table></figure>
<h5 id="把给定id列表的所有记录都删掉"><a href="#把给定id列表的所有记录都删掉" class="headerlink" title="把给定id列表的所有记录都删掉"></a>把给定id列表的所有记录都删掉</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">delete from contacts where id in ( select id from purge_list );</div></pre></td></tr></table></figure>
<h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>hive的MERGE和ACID事务让hive里的数据管理工作变得简单、强大、而且兼容于现有的EDW平台。</p>
<p>参考：<a href="https://zh.hortonworks.com/blog/update-hive-tables-easy-way/" target="_blank" rel="external">https://zh.hortonworks.com/blog/update-hive-tables-easy-way/</a></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/22/实时系统的特性/" title="实时系统的特性" itemprop="url">实时系统的特性</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-22T06:20:41.000Z" itemprop="datePublished"> 发表于 2017-11-22</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h4 id="关键特性"><a href="#关键特性" class="headerlink" title="关键特性"></a>关键特性</h4><p>首先，各个微服务之间应该是解耦的，最好通过stream进行结构。</p>
<ul>
<li>持久化，把数据流暂存起来，供消费。具体持久化的时间，可以根据自己的业务处理</li>
<li>高性能，最快的处理每个环节，最大化单个处理单元的吞吐量</li>
<li>易扩展性，主要是易于应对数据量的海量增加</li>
</ul>
<p>参考：<a href="https://www.youtube.com/watch?v=4lUxf5pzAHs" target="_blank" rel="external">https://www.youtube.com/watch?v=4lUxf5pzAHs</a></p>
<h4 id="Move-from-State-to-Flow"><a href="#Move-from-State-to-Flow" class="headerlink" title="Move from State to Flow"></a>Move from State to Flow</h4><p>把微服务中的state转移到flow中去。</p>
<p>如果多个微服务都更新自己的state到同一个本地存储【比如mysql】，那么这个mysql就会变成一个比较危险的地方。如果我们单个微服务要修改mysql的配置，其他几个服务也要受到影响。</p>
<p>但是我们期望，每个微服务自己有修改的时候，相互之间没有影响，每个微服务的变化都是独立的。假设有A,B,C三个微服务，如果给C单独的mysql，那么c对于A,B就是完全独立的。然后针对A,B,C的更新操作全部看作business event放入一个queue，然后再由consumer从queue里消费event，针对不同的event进行处理。</p>
<p>参考：<a href="https://www.youtube.com/watch?v=_xqK0Es9zP4" target="_blank" rel="external">https://www.youtube.com/watch?v=_xqK0Es9zP4</a></p>
<h4 id="财政部门的flow数据架构"><a href="#财政部门的flow数据架构" class="headerlink" title="财政部门的flow数据架构"></a>财政部门的flow数据架构</h4><table>
<thead>
<tr>
<th>state</th>
<th>flow</th>
</tr>
</thead>
<tbody>
<tr>
<td>共享的DB</td>
<td>不共享任何，只共享flow</td>
</tr>
<tr>
<td>复杂的语义，需要小心的使用事务</td>
<td>好的沟通规范</td>
</tr>
<tr>
<td>人们较熟悉</td>
<td>生活中的真实流程</td>
</tr>
<tr>
<td>控制流 + state更新</td>
<td>控制流 + offset/message</td>
</tr>
</tbody>
</table>
<p>bank1和bank2都监听同一个message queue，处理过后持久化到自己的私有db。</p>
<p>参考：<a href="https://www.youtube.com/watch?v=vG2qxjkqOgA" target="_blank" rel="external">https://www.youtube.com/watch?v=vG2qxjkqOgA</a></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/22/Flink特性/" title="Flink特性" itemprop="url">Flink特性</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-22T06:13:34.000Z" itemprop="datePublished"> 发表于 2017-11-22</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>stateful operator可以追溯到前面的状态，例如count操作</p>
<p>stateful</p>
<ul>
<li>聚合操作</li>
<li>complex event processing</li>
<li>ML pattern</li>
</ul>
<p>stateless</p>
<ul>
<li>数据抽取</li>
<li>数据清洗</li>
<li>stateless的转化</li>
</ul>
<h4 id="queryable-state"><a href="#queryable-state" class="headerlink" title="queryable state"></a>queryable state</h4><p>如果设定了一个小时的窗口，在到达一小时之前这个数据一般是不可查询的。但是有了 queryable 是state，我们可以在未到时间窗口的时候，就进行查询计算。</p>
<h4 id="不想中断数据处理，但又想"><a href="#不想中断数据处理，但又想" class="headerlink" title="不想中断数据处理，但又想"></a>不想中断数据处理，但又想</h4><ul>
<li>修改worker的数量</li>
<li>迁移到另一个集群</li>
<li>修复代码bug</li>
<li>升级flink</li>
<li>测试不同的算法</li>
<li>……</li>
</ul>
<p>以上这些对于stateless任务其实是很简单的，直接操作就可以。停掉，重启。对于statefule的任务，就比较棘手。对于添加worker的需求，state需要reload或者redistribute。</p>
<p>Flink方案：savepoint。</p>
<ul>
<li>创建savepoint</li>
<li>修改</li>
<li>从savepoint重启</li>
</ul>
<p>对于session window的state也是很棘手的，Flink1.1会支持这个场景。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/21/flink的容错机制/" title="flink的容错机制" itemprop="url">flink的容错机制</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-21T08:44:02.000Z" itemprop="datePublished"> 发表于 2017-11-21</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Flink容错机制保证了，即便出现失败，程序的state也最终reflect每条记录exactly once，也可以降级到at least once。</p>
<p>这个容错机制持续的描绘出分布式数据流的snapshot。对于少有state的流式应用来说，这些snapshot是非常轻量的，可以在不影响到性能的前提下快速完成。流式应用的state会被存储在配置好的地方(比如master节点、hdfs等)。</p>
<p>如果程序失败了(机器原因、网络原因、软件问题等)，Flink会踢掉分布式数据流。然后系统会重启所有的operator，然后把他们重置到最近的成功的checkpoint。输入流也被重置到这个state snapshot的点。作为重新启动的并行dataflow的一部分，已经处理过的所有的记录都保证不属于前一个checkpoint state里的一部分。</p>
<p>注意：默认checkpoint是未启用的。</p>
<p>注意：要完全保证这个机制，需要数据流的source(一般是消息队列或者broker)能够支持重置位移。例如kafka就可以重置位移。</p>
<p>注意：以你为Flink的checkpoints是通过分布式snapshot实现的，我们可以交换使用snapshot和checkpoint这两个词语。</p>
<h2 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h2><p>Flinke容错机制的核心就是为分布式的数据流和操作状态进行snapshot。这些snapshot作为一致性的checkpoint供错误恢复使用。Flink执行snapshot的机制在<a href="http://arxiv.org/abs/1506.08603" target="_blank" rel="external"> “Lightweight Asynchronous Snapshots for Distributed Dataflows”.</a>有介绍。是由<a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/chandy.pdf" target="_blank" rel="external">Chandy-Lamport algorithm</a>实现的，这是一种分布式snapshot方法，而且兼容Flink的执行模型。</p>
<h4 id="Barrier栅栏"><a href="#Barrier栅栏" class="headerlink" title="Barrier栅栏"></a>Barrier栅栏</h4><p>Flink分布式snapshot的核心元素是stream barrier。这些栅栏被注入到data stream和flow当中作为data stream的一部分存在。barrier永远不会超过记录，flow是严格线性的。barrier负责把data stream中的数据进行切分，切分为两部分，一部分到当前的snapshot中，然后另外一部分是下一个snapshot里的。Each barrier carries the ID of the snapshot whose records it pushed in front of it. barrier并不会中断数据流处理，十分轻量。不同snampshot的多个barrier可能同时存在于stream中，这就是说可能会多个snapshot并发执行。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.3/fig/stream_barriers.svg" alt=""></p>
<p>Stream barrier在stream source被注入到并发的data flow中。snapshot n的barrier的点Sn被注入的位置是source stream知道覆盖到数据的snapshot【The point where the barriers for snapshot n are injected (let’s call it Sn) is the position in the source stream up to which the snapshot covers the data】。例如在kafka中，这个位置就是当前分区上一次访问的记录的offset。这个位置Sn就被汇报给checkpoint coordinator(Flink里就是JobManager)。</p>
<p>然后barrier继续向下执行。当一个中间oerator抽取到snapshot n的barrier时，它发射一个snapshot n的barrier给它所有的outgoing stream。一旦一个sink operator(DAG的最后)收到barrier n的时候，它就向checkpoint coordinator确认ack snapshot n。所有的sink都ack了这个snapshot的时候，它就被认为已经成功了。</p>
<p>snapshot n完成之后，job再也不会请求Sn之前的数据记录了，因为这些数据记录已经通过了整个数据流处理拓扑。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.3/fig/stream_aligning.svg" alt=""></p>
<p>接收多个input stream的operator必须排列多个input stream的snapshot barriers。上图内容</p>
<ul>
<li>operator接到单个input stream的snapshot barrier n的时候，不能立即处理这个stream的数据，需要等着其他input stream的barrier n也到达的时候才行。否则，它会把snapshot n的数据记录和snapshot n+1的数据记录弄混了。</li>
<li>已经汇报barrier n的input stream暂时被搁置。收到的数据记录暂时不处理，而是放进一个input buffer</li>
<li>最后一个stream也收到barrier n的时候，这个operator就发射所有pending的outing 记录，然后自己也发射snapshot n的barrier。</li>
<li>最后，它恢复处理所有input stream的数据记录，处理在此之前的input buffer里的数据记录，然后处理stream的记录。</li>
</ul>
<h4 id="state"><a href="#state" class="headerlink" title="state"></a>state</h4><p>如果operator包含任意形式的state，这个state就必须成为snapshot的一部分。operator statue可能是下面的几种：</p>
<ul>
<li>user-defined state。通过转化方法(例如map、filter)直接创建与修改的state。</li>
<li>system state。例如operator计算的一部分，数据缓存等。典型的例子是window buffer，在window buffer中通常收集聚合数据记录，直到window的计算或者被清空。</li>
</ul>
<p>operator在收到了它所有input stream的barrier n，并且没有发送barrier n给它的所有output stream之前，snapshot它的state。在这个时间点，barrier之前的所有的数据记录导致的state更新已经完成，并且没有根据已经执行的的barrier之后的数据记录进行任何更新。因为snapshot 的state可能会很大，它可以被存储在一个可配置的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/ops/state_backends.html" target="_blank" rel="external">后端</a>。默认情况下，是放在JobManager的内存里，对于生产环境，最好放在可靠的存储介质上，例如HDFS。在state被存储之后，operator ack这个checkpoint，发送这个snapshot barrier到output stream中。</p>
<p>现在snapshot包含了：</p>
<ul>
<li>对于每个并行的stream data source，snapshot开始的时候stream中的位置信息或者offset</li>
<li>对于每个operator，一个指向snapshot state仓库的pointer</li>
</ul>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.3/fig/checkpointing.svg" alt="checkpoint流程图"></p>
<h2 id="Exactly-Once还是At-least-once"><a href="#Exactly-Once还是At-least-once" class="headerlink" title="Exactly Once还是At least once"></a>Exactly Once还是At least once</h2><p>对于streaming program来说alignment操作可能会造成一些延迟。通差，这部分延迟是早毫秒级的，但是我们见过一些非常突出的延迟。对于那些坚持要求低延迟的应用，Flink有一个开关可以关闭checkpoint过程中的alignment操作。checkpoint snapshot仍然很快。</p>
<p>当alignment被跳过后，即便一些checkpoint barrier n已经到了，operator也要继续处理所有的输入。这样的话，在snapshot n完结之前，operator也会处理属于 snapshot n+1的数据。再回复的时候，这些记录就会被重复处理，因为他们都被记录在了snapshot n的state snapshot里，所以也会作为checkpoint n之后的数据被replay。</p>
<p>注意：alignment只会发生在具有多个前辈(join)，或者多个sender(在一个stream被repartition/shuffle)的operator。因此，对于只包含并行处理操作(map, flatmap, filter等)的dataflow来说，at least once模式下其实也是exactly once的。</p>
<h2 id="异步state-snapshot"><a href="#异步state-snapshot" class="headerlink" title="异步state snapshot"></a>异步state snapshot</h2><p>注意上面描述的机制意味着operator在奥村他们的snapshot state到state backend的时候，需要停止处理输入的记录。这个同步的state snapshot操作会造成一个小的时间延迟。</p>
<p>如果让这个存储操作异步执行的话，就能让operator继续执行下面的步骤了。要这样的话，operator必循能够生成一个state对象，这个state 对象能够被存储，而且后面operator state的更新不会影响到它。例如，copy-on-write数据结构，rocksdb里有这种操作。</p>
<p>接收到所有input stream的checkpoint barrier后，operator开始异步snapshot，copy他的state。它会马上发送barrier到它的output，然后继续下面的数据流处理。一旦后台的copy进程完成后，它就会向checkpoint coordinator(JobManager) ack这个checkpoint。 这个checkpoint现在只在所有的sink都收到barrier后，所有的statefule operator都ack他们完成了backup后(这个可能比barrier到达sink还要慢)才算完成。</p>
<h2 id="recovery"><a href="#recovery" class="headerlink" title="recovery"></a>recovery</h2><p>在这个机制下的recovery很直接：一旦发生失败，Flink选择最新的完成的checkpoint k。然后这个system重新部署整个的分布式数据流，然后给每个operator这个snapshot k对应的state，因为这也是checkpoint k的一部分。而且需要从数据源的Sk的位置开始读取数据流。如果是kafka的话，就是从offset为Sk的地方开始抽取数据。</p>
<p>如果state是增量snapshot的，那么operator要使用最新full snapshot的state，然后把后续的更新操作应用到这个state上。</p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/dev/restart_strategies.html" target="_blank" rel="external">更多</a></p>
<h2 id="operator-snapshot的实现"><a href="#operator-snapshot的实现" class="headerlink" title="operator snapshot的实现"></a>operator snapshot的实现</h2><p>当operator执行snapshot的时候，有两个部分：同步的和异步的。</p>
<p>operator和state backend是以java FutureTask的形式提供他们的snapshot的。这个task包含了同步部分已完成的state，但是异步部分可能还在pending状态。异步部分后面会被这个checkpoint的一个后台线程执行。</p>
<p>使用纯同步方式的operator checkpint会返回一个已经完成了的FutrueTask。如果异步操作需要被执行，就执行FutrueTask的run方法。</p>
<p>这些task是可以被cancel的，这样stream和其他的资源消费句柄就可以被release了。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






  <nav id="page-nav" class="clearfix">
    <a class="extend prev" rel="prev" href="/page/2/"><span></span>Prev</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/24/">24</a><a class="extend next" rel="next" href="/page/4/">Next<span></span></a>
  </nav>

</div>
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  


  

  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/youdaonote/" title="youdaonote">youdaonote<sup>187</sup></a></li>
			
		
			
				<li><a href="/tags/源码/" title="源码">源码<sup>10</sup></a></li>
			
		
			
				<li><a href="/tags/akka/" title="akka">akka<sup>9</sup></a></li>
			
		
			
				<li><a href="/tags/flume/" title="flume">flume<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/ETL/" title="ETL">ETL<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/solr/" title="solr">solr<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/spring/" title="spring">spring<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/调度平台/" title="调度平台">调度平台<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/azkaban/" title="azkaban">azkaban<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/mysql/" title="mysql">mysql<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/scala/" title="scala">scala<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/ambari/" title="ambari">ambari<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/quartz/" title="quartz">quartz<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/nodejs/" title="nodejs">nodejs<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Solr/" title="Solr">Solr<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/guava/" title="guava">guava<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/heroku/" title="heroku">heroku<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/hdfs/" title="hdfs">hdfs<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/hue/" title="hue">hue<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/ElasticSearch/" title="ElasticSearch">ElasticSearch<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="https://github.com/willcup" target="_blank" title=" 我自己的github">github</a>
            
          </li>
        
          <li>
            
            	<a href="http://thisding.com" target="_blank" title="朋友的主页">Steven&#39;s Blog</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

  <div class="weiboshow">
  <p class="asidetitle">新浪微博</p>
    <iframe width="100%" height="119" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=null&verifier=&dpc=1"></iframe>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m Will Chen in MeiTuan. <br/>
			元 亨 利 贞.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
		<a href="mailto:chenxin15@meituan.com" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2017 
		
		<a href="/about" target="_blank" title="Will Chen">Will Chen</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>










<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3Fe6d1f421bbc9962127a50488f9ed37d1' type='text/javascript'%3E%3C/script%3E"));
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
 </html>
