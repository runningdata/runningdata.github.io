
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <script type="text/javascript">
    (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
    })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');
    
    _st('install','yNiKTKaAnwd1uuxVMfiE','2.0.0');
  </script>
  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?5b99dfd487346155d274c0c49c3fb869";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
  </script>

  
    <title>Will&#39;s Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Will Chen">
    

    
    <meta name="description" content="左右水色 右手天光">
<meta property="og:type" content="website">
<meta property="og:title" content="Will's Blog">
<meta property="og:url" content="https://runningdata.github.io/page/11/index.html">
<meta property="og:site_name" content="Will's Blog">
<meta property="og:description" content="左右水色 右手天光">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Will's Blog">
<meta name="twitter:description" content="左右水色 右手天光">

    
    <link rel="alternative" href="/atom.xml" title="Will&#39;s Blog" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="Will&#39;s Blog" title="Will&#39;s Blog"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Will&#39;s Blog">Will&#39;s Blog</a></h1>
				<h2 class="blog-motto">简易 变易 不易</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">首页</a></li>
					
						<li><a href="/archives">归档</a></li>
					
						<li><a href="/about">关于</a></li>
					
					<li>
 					
                                                <form class="search" action="/search/index.html" method="get" accept-charset="utf-8" target="_blank">
                                                        <label>搜索</label>
                                                <input name="s" type="hidden" value= null ><input type="text" name="q" size="30" placeholder="搜索"><br>
                                                </form>
					
					</li>
				</ul>
			</nav>			
</div>

    </header>
    <div id="container">
      <div id="main">

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/05/10/django用户组的思考/" title="django用户组的思考" itemprop="url">django用户组的思考</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-05-10T09:24:10.000Z" itemprop="datePublished"> 发表于 2017-05-10</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>我们有两个不同的事业部A, B， 目前是用django的group来做的。。。都在我的平台上编辑自己的内容OBJ，我给OBJ指定了唯一一个group_id外键来保证AB事业部内容的隔离。。。。现在遇到问题，因为要控制一些权限，当加group的时候…..自己就懵逼了</p>
<p>不该这样处理AB，对吧。。。应该额外建立一个oaganization来作为AB隔离的。django的group用来做操作权限控制更好，而不是对象隔离。</p>
<p>所以现在的代码结构是：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">OrgGroup</span><span class="params">(models.Model)</span>:</span></div><div class="line">    name = models.CharField(max_length=<span class="number">200</span>, verbose_name=<span class="string">u"组织名称"</span>)</div><div class="line">    owners = models.CharField(max_length=<span class="number">100</span>, verbose_name=<span class="string">u"负责人"</span>, blank=<span class="keyword">True</span>, default=<span class="string">''</span>)</div><div class="line">    hdfs_path = models.CharField(max_length=<span class="number">100</span>, verbose_name=<span class="string">u"HDFS临时路径"</span>, blank=<span class="keyword">True</span>, default=<span class="string">''</span>)</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> self.name</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">UserProfile</span><span class="params">(models.Model)</span>:</span></div><div class="line">    user = models.OneToOneField(User)</div><div class="line">    phone = models.BigIntegerField(default=<span class="number">110</span>)</div><div class="line">    org_group = models.ForeignKey(OrgGroup, on_delete=models.DO_NOTHING, related_name=<span class="string">'user_cgroup'</span>, null=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> self.user.username</div></pre></td></tr></table></figure></p>
<p>重新定义了一个组织的model，然后每个人都有属于某个特定的组织。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">JarApp</span><span class="params">(models.Model)</span>:</span></div><div class="line">    .....</div><div class="line">    cgroup = models.ForeignKey(OrgGroup, on_delete=models.DO_NOTHING, </div><div class="line">    .....</div></pre></td></tr></table></figure>
<p>上面的cgroup原来是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cgroup = models.ForeignKey(auth.Group, on_delete=models.DO_NOTHING, related_name=&apos;jar_cgroup&apos;, null=True)</div></pre></td></tr></table></figure></p>
<p>然后还要重构JarApp的新建与查询的一些代码。</p>
<p>这样，使用自定义的组织来划分人员与面向的内容。使用django的group来控制是否组织内特定人员组具有的权限【ETL开发人员、与报表开发人员】。</p>
<p>自定义的组织用来限定报表和ETL所属的组织。而django的auth.group可以管理一组权限【对ETL、报表的访问权限、操作权限等】。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/05/09/ambari个别component扩张/" title="ambari个别component扩张" itemprop="url">ambari个别component扩张</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-05-09T03:08:30.000Z" itemprop="datePublished"> 发表于 2017-05-09</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>需要扩展20个NodeManager，ambari只能手动到每个datanode界面上去安装NodeManager，并启动。啰嗦，麻烦。</p>
<p>看了一下ajax请求，整理了一个脚本。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">#!/bin/bash</div><div class="line"></div><div class="line">for i in `seq 26 33`;</div><div class="line">do</div><div class="line"></div><div class="line">echo handing $i</div><div class="line"></div><div class="line"># 安装service</div><div class="line">curl -u admin:will@bj15. -H &quot;X-Requested-By: ambari&quot; -X POST -d &apos;</div><div class="line">&#123;&quot;RequestInfo&quot;:&#123;&quot;context&quot;:&quot;Install NodeManager&quot;&#125;,&quot;Body&quot;:&#123;&quot;host_components&quot;:[&#123;&quot;HostRoles&quot;:&#123;&quot;component_name&quot;:&quot;NODEMANAGER&quot;&#125;&#125;]&#125;&#125;&apos; http://namenode01.will.com:8080/api/v1/clusters/datacenter/hosts?Hosts/host_name=datanode$&#123;i&#125;.will.com</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"># 安装component</div><div class="line">curl -u admin:will@bj15. -H &quot;X-Requested-By: ambari&quot; -X PUT -d &apos;</div><div class="line">&#123;&quot;RequestInfo&quot;:&#123;&quot;context&quot;:&quot;Install NodeManager&quot;,&quot;operation_level&quot;:&#123;&quot;level&quot;:&quot;HOST_COMPONENT&quot;,&quot;cluster_name&quot;:&quot;datacenter&quot;,&quot;host_name&quot;:&quot;datanode$&#123;i&#125;.will.com&quot;,&quot;service_name&quot;:&quot;YARN&quot;&#125;&#125;,&quot;Body&quot;:&#123;&quot;HostRoles&quot;:&#123;&quot;state&quot;:&quot;INSTALLED&quot;&#125;&#125;&#125;&apos; http://namenode01.will.com:8080/api/v1/clusters/datacenter/hosts/datanode$&#123;i&#125;.will.com/host_components/NODEMANAGER?HostRoles/state=INIT</div><div class="line"></div><div class="line"></div><div class="line"># 启动</div><div class="line">curl -u admin:will@bj15. -H &quot;X-Requested-By: ambari&quot; -X PUT -d &apos;&#123;&quot;RequestInfo&quot;:&#123;&quot;context&quot;:&quot;Start NodeManager&quot;,&quot;operation_level&quot;:&#123;&quot;level&quot;:&quot;HOST_COMPONENT&quot;,&quot;cluster_name&quot;:&quot;datacenter&quot;,&quot;host_name&quot;:&quot;datanode$&#123;i&#125;.will.com&quot;,&quot;service_name&quot;:&quot;YARN&quot;&#125;&#125;,&quot;Body&quot;:&#123;&quot;HostRoles&quot;:&#123;&quot;state&quot;:&quot;STARTED&quot;&#125;&#125;&#125;&apos; http://namenode01.will.com:8080/api/v1/clusters/datacenter/hosts/datanode$&#123;i&#125;.will.com/host_components/NODEMANAGER</div><div class="line">done</div></pre></td></tr></table></figure></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/04/27/自制RPM包并发布到自己的yum源/" title="自制RPM包并发布到自己的yum源" itemprop="url">自制RPM包并发布到自己的yum源</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-04-27T03:29:46.000Z" itemprop="datePublished"> 发表于 2017-04-27</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>使用一个普通用户执行，以免对系统造成重伤。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install -y rpmdevtools rpm-build</div></pre></td></tr></table></figure>
<h2 id="自定义工作空间"><a href="#自定义工作空间" class="headerlink" title="自定义工作空间"></a>自定义工作空间</h2><p>方案1：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rpmdev-setuptree</div></pre></td></tr></table></figure>
<p>方案2</p>
<p>创建文件~/.rpmmacros<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">%_topdir        /home/will/rpmbuild</div></pre></td></tr></table></figure></p>
<p>配置了空间之后，还得手动创建一下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mkdir /home/will/rpmbuild</div></pre></td></tr></table></figure></p>
<p>创建需要的目录<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd ~/rpmbuild  </div><div class="line">mkdir -pv &#123;BUILD,BUILDROOT,RPMS,SOURCES,SPECS,SRPMS&#125;</div></pre></td></tr></table></figure></p>
<ul>
<li>BUILD #编译之前，如解压包后存放的路径</li>
<li>BUILDROOT #编译后存放的路径</li>
<li>RPMS #打包完成后rpm包存放的路径</li>
<li>SOURCES #源包所放置的路径</li>
<li>SPECS #spec文档放置的路径</li>
<li>SPRMS #源码rpm包放置的路径</li>
</ul>
<p>注：一般我们都把源码打包成tar.gz格式然后存放于SOURCES路径下，而在SPECS路径下编写spec文档，通过命令打包后，默认会把打包后的rpm包放在RPMS下，而源码包会被放置在SRPMS下</p>
<h2 id="源码放到SOURCES目录"><a href="#源码放到SOURCES目录" class="headerlink" title="源码放到SOURCES目录"></a>源码放到SOURCES目录</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cp /tmp/redis-3.2.8.tar.gz SOURCES</div></pre></td></tr></table></figure>
<h2 id="SPECS下创建配置"><a href="#SPECS下创建配置" class="headerlink" title="SPECS下创建配置"></a>SPECS下创建配置</h2><p>到SPECS下创建指定配置，编辑的时候会自动生成模板。编辑<code>SPECS/redis.spec</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div></pre></td><td class="code"><pre><div class="line">Name:		redis</div><div class="line">Version:	3.2.8	</div><div class="line">Release:	3%&#123;dist&#125;</div><div class="line">Summary:	redis from will	</div><div class="line"></div><div class="line">Group:		System Environment/Daemons</div><div class="line">License:	GPLv2</div><div class="line">URL:		https://github.com/willcup</div><div class="line">Source0:	redis-3.2.8.tar.gz</div><div class="line"></div><div class="line">Packager:       WillCup &lt;willcup@163.com&gt; </div><div class="line">BuildRequires:	gcc,make</div><div class="line">Requires:	openssl,chkconfig</div><div class="line">BuildRoot:      %_topdir/BUILDROOT</div><div class="line"></div><div class="line"></div><div class="line">%define PortFindDir /usr/local/will_redis</div><div class="line"></div><div class="line">%description</div><div class="line">this is build from will, just for ambari service.</div><div class="line"></div><div class="line">%prep</div><div class="line">%setup -q</div><div class="line"></div><div class="line">%build</div><div class="line">make %&#123;?_smp_mflags&#125;</div><div class="line"></div><div class="line"></div><div class="line">%install</div><div class="line">[ ! -e $RPM_BUILD_ROOT%&#123;PortFindDir&#125; ] &amp;&amp; mkdir -p $RPM_BUILD_ROOT%&#123;PortFindDir&#125;</div><div class="line">cp -rfv * $RPM_BUILD_ROOT%&#123;PortFindDir&#125;</div><div class="line">[ ! -e $RPM_BUILD_ROOT/etc/init.d ] &amp;&amp; mkdir -p $RPM_BUILD_ROOT/etc/init.d</div><div class="line">[ ! -e $RPM_BUILD_ROOT/usr/local/bin ] &amp;&amp; mkdir -p $RPM_BUILD_ROOT/usr/local/bin</div><div class="line">cp -vf $RPM_BUILD_ROOT%&#123;PortFindDir&#125;/utils/redis_init_script $RPM_BUILD_ROOT/etc/init.d/redis</div><div class="line">cp -vf $RPM_BUILD_ROOT%&#123;PortFindDir&#125;/src/redis-server $RPM_BUILD_ROOT/usr/local/bin</div><div class="line">cp -vf $RPM_BUILD_ROOT%&#123;PortFindDir&#125;/src/redis-cli $RPM_BUILD_ROOT/usr/local/bin</div><div class="line">#mkdir -p &quot;$RPM_BUILD_ROOT&quot;</div><div class="line">#cp -rvf * &quot;$RPM_BUILD_ROOT&quot;</div><div class="line">#ls -l &quot;$RPM_BUILD_ROOT&quot;</div><div class="line">echo &quot;no reason to install redis, just move it&quot;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">%files</div><div class="line">%defattr (-,root,root,0755)</div><div class="line">%dir %&#123;PortFindDir&#125;</div><div class="line">%attr(0755, root, root) %&#123;PortFindDir&#125;/*</div><div class="line">%attr(0755, root, root)	/etc/init.d/redis</div><div class="line">%attr(0755, root, root) /usr/local/bin</div><div class="line">%doc</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">%postun	</div><div class="line">rm -fr %(PortFindDir&#125;</div><div class="line">rm -vf /usr/local/bin/redis-*</div><div class="line">rm -vf /etc/init.d/redis</div><div class="line"></div><div class="line">%changelog</div><div class="line">* Fri Dec 29 2016 willcup &lt;willcup@163.com&gt; - 3.2.8-1 </div><div class="line">- Initial version just changelog</div></pre></td></tr></table></figure></p>
<p>其实上面的buildroot就相当于是后面rpm安装时候的系统根目录。所以一般都需要指定一个子目录。不然是行不通的，会发现弄完以后RPM包里没有任何文件。</p>
<h2 id="开始构建"><a href="#开始构建" class="headerlink" title="开始构建"></a>开始构建</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rpmbuild -ba redis.spec</div></pre></td></tr></table></figure>
<p>可以看到已经有了结果</p>
<p>这个是构建过程中的源码目录：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">[will@datanode08 rpmbuild]$ ll BUILD/redis-3.2.8/</div><div class="line">total 204</div><div class="line">-rw-r--r--.  1 will will 85775 Feb 12 23:14 00-RELEASENOTES</div><div class="line">-rw-r--r--.  1 will will    53 Feb 12 23:14 BUGS</div><div class="line">-rw-r--r--.  1 will will  1805 Feb 12 23:14 CONTRIBUTING</div><div class="line">-rw-r--r--.  1 will will  1487 Feb 12 23:14 COPYING</div><div class="line">-rw-r--r--.  1 will will     0 Apr 27 12:25 debugfiles.list</div><div class="line">-rw-r--r--.  1 will will     0 Apr 27 12:25 debuglinks.list</div><div class="line">-rw-r--r--.  1 will will     0 Apr 27 12:25 debugsources.list</div><div class="line">drwxr-xr-x.  7 will will  4096 Apr 27 12:25 deps</div><div class="line">-rw-r--r--.  1 will will    11 Feb 12 23:14 INSTALL</div><div class="line">-rw-r--r--.  1 will will   151 Feb 12 23:14 Makefile</div><div class="line">-rw-r--r--.  1 will will  4223 Feb 12 23:14 MANIFESTO</div><div class="line">-rw-r--r--.  1 will will  6834 Feb 12 23:14 README.md</div><div class="line">-rw-r--r--.  1 will will 46695 Feb 12 23:14 redis.conf</div><div class="line">-rwxr-xr-x.  1 will will   271 Feb 12 23:14 runtest</div><div class="line">-rwxr-xr-x.  1 will will   280 Feb 12 23:14 runtest-cluster</div><div class="line">-rwxr-xr-x.  1 will will   281 Feb 12 23:14 runtest-sentinel</div><div class="line">-rw-r--r--.  1 will will  7606 Feb 12 23:14 sentinel.conf</div><div class="line">drwxr-xr-x.  2 will will  4096 Apr 27 12:25 src</div><div class="line">drwxr-xr-x. 10 will will  4096 Feb 12 23:14 tests</div><div class="line">drwxr-xr-x.  7 will will  4096 Feb 12 23:14 utils</div></pre></td></tr></table></figure></p>
<p>打包完成后rpm包存放的路径：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[will@datanode08 rpmbuild]$ ll RPMS/x86_64/</div><div class="line">total 8</div><div class="line">-rw-rw-r--. 1 will will 1752 Apr 27 12:25 redis-3.2.8-1.el6.x86_64.rpm</div><div class="line">-rw-rw-r--. 1 will will 1880 Apr 27 12:25 redis-debuginfo-3.2.8-1.el6.x86_64.rpm</div></pre></td></tr></table></figure></p>
<p>源码rpm包放置的路径<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[will@datanode08 rpmbuild]$ ll SRPMS/</div><div class="line">total 1516</div><div class="line">-rw-rw-r--. 1 will will 1549338 Apr 27 12:25 redis-3.2.8-1.el6.src.rpm</div></pre></td></tr></table></figure></p>
<p>然而查看rpm包的文件，竟然什么都没有。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[will@datanode08 rpmbuild]$ rpm -qlp RPMS/x86_64/redis-3.2.8-1.el6.x86_64.rpm </div><div class="line">(contains no files)</div></pre></td></tr></table></figure></p>
<p>修改之后，能够正常安装与使用了。</p>
<p>使用 rpm -ivh xx.rpm成功测试。</p>
<p>下一步，将RPM发布至我们自有的yum源上。</p>
<p>按照其他的类似hadoop之类，创建一个redis目录，然后把我们的rpm包放上去</p>
<p>目录样子<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">[root@datanode21 2.4.2.0]# ll</div><div class="line">total 2146284</div><div class="line">.....</div><div class="line">drwxr-xr-x  2 ambari-qa users       4096 Apr 25  2016 hadoop</div><div class="line">drwxr-xr-x  2 ambari-qa users       4096 Apr 25  2016 hadooplzo</div><div class="line">drwxr-xr-x  2 ambari-qa users       4096 Apr 25  2016 hbase</div><div class="line">.......</div><div class="line">drwxr-xr-x  2 ambari-qa users       4096 Apr 25  2016 oozie</div><div class="line">drwxr-xr-x  2 ambari-qa users       4096 Apr 25  2016 phoenix</div><div class="line">drwxr-xr-x  2 ambari-qa users       4096 Apr 25  2016 pig</div><div class="line">drwxr-xr-x  2 ambari-qa users       4096 Apr 25  2016 ranger</div><div class="line">drwxr-xr-x  2 root      root        4096 Apr 27 16:45 redis</div><div class="line">You have new mail in /var/spool/mail/root</div><div class="line">[root@datanode21 2.4.2.0]# pwd</div><div class="line">/server/www/html/hdp/HDP/centos6/2.x/updates/2.4.2.0</div></pre></td></tr></table></figure></p>
<p>先看下我们的HDP.repo<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[HDP-2.4]</div><div class="line">name=HDP-2.4</div><div class="line">baseurl=http://10.2.19.110/hdp/HDP/centos6/2.x/updates/2.4.2.0</div><div class="line"></div><div class="line">path=/</div><div class="line">enabled=1</div><div class="line">gpgcheck=0</div></pre></td></tr></table></figure></p>
<p>可以看到是同一个目录，我们需要在这个目录下重新执行<code>createrepo</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">[root@datanode21 2.4.2.0]# createrepo .</div><div class="line">Spawning worker 0 with 182 pkgs</div><div class="line">Workers Finished</div><div class="line">Gathering worker results</div><div class="line"></div><div class="line">Saving Primary metadata</div><div class="line">Saving file lists metadata</div><div class="line">Saving other metadata</div><div class="line">Generating sqlite DBs</div><div class="line">Sqlite DBs complete</div><div class="line">[root@datanode21 2.4.2.0]# ll repodata</div><div class="line">total 856</div><div class="line">-rw-r--r-- 1 root root 373992 Apr 27 17:59 458b198ae4b61c02b0f7bb03ae9421365dcb2076ffb6087e6808e7915ec31778-filelists.sqlite.bz2</div><div class="line">-rw-r--r-- 1 root root   9092 Apr 27 17:59 9a59871d45121b0be43f188ae7ffe788e2eceb07d03648717323dedd26faf567-other.xml.gz</div><div class="line">-rw-r--r-- 1 root root  12162 Apr 27 17:59 bb3c2dc4c1f7ae17b172f104e3df5171d0d09db797a5f5a9227ab4ae424a45b7-other.sqlite.bz2</div><div class="line">-rw-r--r-- 1 root root  37245 Apr 27 17:59 c23cec21ae4b3e9b89a029b593362ca1e2483316e1d07843a9035ad8e3c93053-primary.xml.gz</div><div class="line">-rw-r--r-- 1 root root 363468 Apr 27 17:59 c521ec682137ff19e61f7ec91e86c725d6d6fa7553be01c783a67ffb68b30afe-filelists.xml.gz</div><div class="line">-rw-r--r-- 1 root root  65483 Apr 27 17:59 eb98320b3ad040203135b91f26caee107900f2e9bdc86a4be6c5218fcc505036-primary.sqlite.bz2</div><div class="line">-rw-r--r-- 1 root root   2996 Apr 27 17:59 repomd.xml</div></pre></td></tr></table></figure></p>
<p>然后更新客户机上，也就是要安装redis 的机器上的repo信息。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">yum clean all</div><div class="line">yum update</div><div class="line">yum search redis</div></pre></td></tr></table></figure></p>
<p>能够搜到，至此结束。</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>我们要构建redis，主要是为了适应既有ambari的redis service，它执行安装的命令是<code>yum install redis.3.2.8</code>。当然我们是可以修改一下他的install代码的，但是考虑到以后其他组件很有可能还是通过yum安装，那还是现在就把自己动手构建yum的rpm包这个问题解决了吧，以绝后患。</p>
<p>问题来了，上面我们搜到的只是<code>redis.x86_64</code>,实际安装的时候请求的是3.2.8，需要版本号加进去才行。看到spec里有version关键字。。。折腾了好半天，都不是，构建出来search的时候都还是只有redis。</p>
<p>后来参考既有的hadoop、flume等yum源，成功搞定。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">flume_2_4_2_0_258-1.5.2.2.4.2.0-258.el6.noarch.rpm	25-Apr-2016 19:54	40M	 </div><div class="line">	</div><div class="line">flume_2_4_2_0_258-agent-1.5.2.2.4.2.0-258.el6.noarch.rpm	25-Apr-2016 19:54	6.4K</div></pre></td></tr></table></figure></p>
<p>发现这个版本号貌似是跟着文件夹的。</p>
<p>所以，修改如下:</p>
<ul>
<li>修改redis.spec为redis-3.2.8.spec</li>
<li>编辑spec文件<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Name:           redis-3.2.8</div><div class="line">Version:        1_0_0</div><div class="line"></div><div class="line">URL:            https://github.com/willcup</div><div class="line">Source0:        redis-3.2.8.tar.gz</div></pre></td></tr></table></figure>
</li>
</ul>
<p>关键在于Name，后面都是喽啰</p>
<ul>
<li>这样解压后会去redis-3.2.8-1_0_0，也就是根据name和version生成的规则，所以可能要调整一下tar.gz里的文件夹名称</li>
<li>重新构建预发布，即可<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">redis-3.2.8-1_0_0-4.el6.x86_64.rpm</div><div class="line"></div><div class="line">yum search redis</div><div class="line">redis.x86_64 : redis from will</div><div class="line">redis-3.2.8.x86_64 : redis 3 2 8 from will</div></pre></td></tr></table></figure>
</li>
</ul>
<p>参考：</p>
<ul>
<li><a href="https://docs.fedoraproject.org/en-US/Fedora_Draft_Documentation/0.1/html/Packagers_Guide/chap-Packagers_Guide-Spec_File_Reference-Preamble.html" target="_blank" rel="external">https://docs.fedoraproject.org/en-US/Fedora_Draft_Documentation/0.1/html/Packagers_Guide/chap-Packagers_Guide-Spec_File_Reference-Preamble.html</a></li>
<li><a href="https://fedoraproject.org/wiki/How_to_create_an_RPM_package/zh-cn#.E5.AE.9E.E4.BE.8B" target="_blank" rel="external">https://fedoraproject.org/wiki/How_to_create_an_RPM_package/zh-cn#.E5.AE.9E.E4.BE.8B</a></li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/04/26/TEZ-hadoop上数据处理的新篇章/" title="TEZ-hadoop上数据处理的新篇章" itemprop="url">TEZ-hadoop上数据处理的新篇章</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-04-26T12:15:47.000Z" itemprop="datePublished"> 发表于 2017-04-26</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="TEZ"><a href="#TEZ" class="headerlink" title="TEZ"></a>TEZ</h2><p>生成一个复杂的DAG task图</p>
<p>目前基本所有的hadoop任务都是MapReduce程序，面向批数据的特性使得它并不能够满足一些特定查询。TEZ是传统MR程序的另一个选择，可以更快地返回结果，而且减少过程中的吞吐。</p>
<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>分布式处理是hadoop的核心。存储与分析各种不同的大量的数据使得hadoop之上产生了很多工具。随着hadoop进入yarn时代，它把MR解耦了出来，这样可以使用其他的数据处理方式来迎接新的不同的挑战。</p>
<h2 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h2><p>hive,pig这些高层次的数据处理工具需要一个引擎来解析他们的语句，然后执行。TEZ就是这样一个引擎。</p>
<h4 id="解析，建模，执行"><a href="#解析，建模，执行" class="headerlink" title="解析，建模，执行"></a>解析，建模，执行</h4><p>TEZ把数据处理看作一个数据流图，节点代表数据处理逻辑，边代表着数据的流向。TEZ有一个很好的数据流相关API,能够让用户清晰表达出自己的复杂查询逻辑，也能够支持hive、pig等高级应用生成的查询计划。</p>
<p>如下图，使用range partitioning进行分布式sort的模型。Preprocessor stage中发送samples给Sampler，计算每个数据分区的range，以保证平均分配。然后这些range再被发送给Partition stage。然后partition stage和aggregate stage就读取分配的stage，执行数据的扫描与后续聚合工作。</p>
<p><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2013/09/tez1-450x257.png" alt=""></p>
<h4 id="灵活的input-processor-output任务模型"><a href="#灵活的input-processor-output任务模型" class="headerlink" title="灵活的input-processor-output任务模型"></a>灵活的input-processor-output任务模型</h4><p>TEZ中对于数据流中每个处理逻辑都是由三部分组成：input, processor, output。input和output决定数据接口。processor则是数据处理逻辑。TEZ只要求在同一个vertex task中这三部分之间是相互兼容的即可。</p>
<p><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2013/09/tez2-450x154.png" alt=""></p>
<h4 id="动态图配置的性能"><a href="#动态图配置的性能" class="headerlink" title="动态图配置的性能"></a>动态图配置的性能</h4><p>分布式数据处理天生就是动态的，所以很难提前知道最优并发和数据走向。更多的信息只能在运行时才获知，比如数据的内容和大小，这其实是可以帮助我们优化执行计划的。我们还注意到TEZ自身并不能总是自己执行这些动态优化。</p>
<p><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2013/09/tez3-450x208.png" alt=""></p>
<ul>
<li><a href="https://hortonworks.com/blog/apache-tez-a-new-chapter-in-hadoop-data-processing/" target="_blank" rel="external">https://hortonworks.com/blog/apache-tez-a-new-chapter-in-hadoop-data-processing/</a></li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/04/26/hiveserver2负载均衡/" title="hiveserver2负载均衡" itemprop="url">hiveserver2负载均衡</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-04-26T08:47:44.000Z" itemprop="datePublished"> 发表于 2017-04-26</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>hiveserver2是通过在zookeeper注册一个namespace，然后管理所有的hiveserver实例，实现动态服务发现的。</p>
<p>znode样式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/&lt;hiveserver2_namespace&gt;/serverUri=&lt;host:port&gt;;version=&lt;versionInfo&gt;; sequence=&lt;sequence_number&gt;,</div></pre></td></tr></table></figure></p>
<p>hiveserver实例会在znode上设置一个watch。当znode被修改的时候，watch会发送给hiveserver相关信息。这个通知能够让所有的hiveserver实例知道它是不是对于client端可用。</p>
<p>当有hiveserver实例退出时，会从zk的对应node里移除，但是只对新的客户端连接生效。(已经连接的session不能生效了)。只有已经连接到这个hiveserver的最后一个client的session结束后，才会自动把这个hiveserver完全关闭，下面这个命令就是做这个工作的。</p>
<p>使用下面命令移除一个hiveserver<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hive --service hiveserver2 --deregister &lt;package ID&gt;</div></pre></td></tr></table></figure></p>
<h4 id="没有zk时的查询"><a href="#没有zk时的查询" class="headerlink" title="没有zk时的查询"></a>没有zk时的查询</h4><p>下面是一个传统的查询流程：</p>
<ul>
<li>通过JDBC/ODBC driver连接到HS2实例，建立一个session</li>
<li>然后每次查询的时候client都发送语句给HS2，转化成Hadoop上的执行任务</li>
<li>每个查询的结果都写道一个临时文件中</li>
<li>客户端driver从HS2抽取临时文件中的数据记录</li>
</ul>
<p><img src="https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.4.0/bk_hadoop-ha/content/figures/2/figures/Query_Ex_Path_No_ZK.png" alt="典型查询流程"></p>
<h4 id="带有zk的查询"><a href="#带有zk的查询" class="headerlink" title="带有zk的查询"></a>带有zk的查询</h4><p>因为可以使用动态服务发现，所以客户端driver必须知道怎样使用这个特性。对于HDP2.2或者JDBC driver2.0.0版本之后才能支持。</p>
<p>动态服务发现实现如下：</p>
<ul>
<li>多个HS2实例使用zk注册自己</li>
<li>客户端driver连接zk<blockquote>
<p> jdbc:hive2://<zookeeper_ensemble>;serviceDiscoveryMode=zooKeeper; zooKeeperNamespace=&lt;hiveserver2_namespace</zookeeper_ensemble></p>
</blockquote>
</li>
<li>zk随机返回一个host:port给客户端</li>
<li>客户端执行单个服务传统查询过程</li>
</ul>
<p><img src="https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.4.0/bk_hadoop-ha/content/figures/2/figures/Query_Ex_Path_With_ZK.png" alt="带有zk的查询过程"></p>
<h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><p>hive.zookeeper.quorum zk列表<br>hive.zookeeper.session.timeout 超时就关闭session<br>hive.server2.support.dynamic.service.discovery  设置为true<br>hive.server2.zookeeper.namespace    指定一个就行了，默认是hiveserver2</p>
<ul>
<li><a href="https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.4.0/bk_hadoop-ha/content/ha-hs2-requests.html" target="_blank" rel="external">https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.4.0/bk_hadoop-ha/content/ha-hs2-requests.html</a></li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/04/26/hue对于多个hiveserver2的支持/" title="hue对于多个hiveserver2的支持" itemprop="url">hue对于多个hiveserver2的支持</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-04-26T08:26:28.000Z" itemprop="datePublished"> 发表于 2017-04-26</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>相关连接代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">hiveserver2_jdbc_url</span><span class="params">()</span>:</span></div><div class="line">  urlbase = <span class="string">'jdbc:hive2://%s:%s/default'</span> % (beeswax.conf.HIVE_SERVER_HOST.get(),</div><div class="line">                                            beeswax.conf.HIVE_SERVER_PORT.get())</div><div class="line">  <span class="keyword">if</span> get_conf().get(_CNF_HIVESERVER2_USE_SSL, <span class="string">'FALSE'</span>).upper() == <span class="string">'TRUE'</span>:</div><div class="line">    <span class="keyword">return</span> <span class="string">'%s;ssl=true;sslTrustStore=%s;trustStorePassword=%s'</span> % (urlbase,</div><div class="line">            get_conf().get(_CNF_HIVESERVER2_TRUSTSTORE_PATH),</div><div class="line">            get_conf().get(_CNF_HIVESERVER2_TRUSTSTORE_PASSWORD))</div><div class="line">  <span class="keyword">else</span>:</div><div class="line">     <span class="keyword">return</span> urlbase</div></pre></td></tr></table></figure></p>
<p>可以看到，除非启用SSL，否则咋样都拼不进去下面这种串：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">jdbc:hive2://zkNode1:<span class="number">2181</span>,zkNode2:<span class="number">2181</span>,zkNode3:<span class="number">2181</span>/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2_zk</div></pre></td></tr></table></figure></p>
<p>Tip:</p>
<p>可以先用tengine配置TCP代理，然后在这里实现负载均衡，hue端只需要配置代理的地址就可以了。 —— 希望hive的driver可以支持，有待测试。</p>
<p>参考：</p>
<ul>
<li><a href="http://lxw1234.com/archives/2016/05/675.htm" target="_blank" rel="external">http://lxw1234.com/archives/2016/05/675.htm</a></li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/04/25/hive中使用向量化查询引擎Vectorized-Query-Execution/" title="hive中使用向量化查询引擎Vectorized-Query-Execution" itemprop="url">hive中使用向量化查询引擎Vectorized-Query-Execution</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-04-25T11:59:52.000Z" itemprop="datePublished"> 发表于 2017-04-25</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>向量化查询引擎可以在执行scan, filter, aggregate, join等操作的时候很大程度上降低CPU损耗。标准sql执行系统每次只处理一行数据，内部执行的时候会包括很长的代码路径和重要的metadata解析。向量化查询引擎简化了这个过程，一次读取1024行数据，在这个数据块中，每个字段都被存储成向量化的结构(一个原是数据类型的数组)。对于一些简单的算法可以通过快速迭代这个vector完成，只需要在循环过程中调用甚至不用调用几个函数。这些loop以一种流式方式编译，在固定时间内结束，为了提高效率，会使用processor pipline和内存缓存。<a href="https://issues.apache.org/jira/browse/HIVE-4160" target="_blank" rel="external">详细设计</a></p>
<p>个人理解：就是每行都执行很小的计算，但是要处理N多次。改成一次处理多行，同时针对多行做计算处理，节省CPU时间。</p>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><h4 id="启用"><a href="#启用" class="headerlink" title="启用"></a>启用</h4><p>要使用向量化查询引擎，必须先把hive表存储成ORC格式的。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">set hive.vectorized.execution.enabled = true;</div></pre></td></tr></table></figure></p>
<p>默认是没有开启向量化查询引擎的，需要手动开启。</p>
<h4 id="支持的数据类型与操作"><a href="#支持的数据类型与操作" class="headerlink" title="支持的数据类型与操作"></a>支持的数据类型与操作</h4><ul>
<li>tinyint</li>
<li>smallint</li>
<li>int</li>
<li>bigint</li>
<li>boolean</li>
<li>float</li>
<li>double</li>
<li>decimal</li>
<li>date</li>
<li>timestamp (see Limitations below)</li>
<li>string<br>其他的数据类型还是会按照传统方式一行行处理。</li>
</ul>
<p>支持的表达式：</p>
<ul>
<li>简单算法: +, -, *, /, %</li>
<li>AND, OR, NOT</li>
<li>比较 &lt;, &gt;, &lt;=, &gt;=, =, !=, BETWEEN, IN ( list-of-constants ) as filters</li>
<li>布尔表达式 (non-filters) using AND, OR, NOT, &lt;, &gt;, &lt;=, &gt;=, =, !=</li>
<li>IS [NOT] NULL</li>
<li>所有的匹配函数 (SIN, LOG, etc.)</li>
<li>string相关函数 SUBSTR, CONCAT, TRIM, LTRIM, RTRIM, LOWER, UPPER, LENGTH</li>
<li>类型转换</li>
<li>UDF</li>
<li>日期函数 (YEAR, MONTH, DAY, HOUR, MINUTE, SECOND, UNIX_TIMESTAMP)</li>
<li>IF 条件表达式</li>
</ul>
<p>UDF通过向后兼容的方式支持，不过执行的时候就是执行向量化查询引擎，但是没有内置的快。向量化的filter操作是从左到右执行，所以最好把UDF放在带有and的where语句的最后：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">where column1 = 10 and myUDF(column2) = "x"</div></pre></td></tr></table></figure></p>
<h2 id="限制"><a href="#限制" class="headerlink" title="限制"></a>限制</h2><p>Timestamps 只能是 1677-09-20 到2262-04-11. </p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/04/21/集群service配置相关/" title="集群service配置相关" itemprop="url">集群service配置相关</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-04-21T08:41:02.000Z" itemprop="datePublished"> 发表于 2017-04-21</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h2><table>
<thead>
<tr>
<th>服务名称</th>
<th>现有配置</th>
<th>TO </th>
</tr>
</thead>
<tbody>
<tr>
<td>resourcemanager</td>
<td>1G</td>
<td>4G</td>
</tr>
<tr>
<td>nodemanager</td>
<td>1G</td>
<td>2G</td>
</tr>
<tr>
<td>timeline server</td>
<td>1G</td>
<td>4G</td>
</tr>
</tbody>
</table>
<p>resource + timline server = 2G</p>
<h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS "></a>HDFS </h2><table>
<thead>
<tr>
<th>服务名称</th>
<th>现有配置</th>
<th>TO</th>
</tr>
</thead>
<tbody>
<tr>
<td>datanode</td>
<td>1G</td>
<td>2G</td>
</tr>
<tr>
<td>namenode</td>
<td>3G </td>
</tr>
</tbody>
</table>
<p>namenode * 2 =  6G</p>
<h2 id="MAPRED"><a href="#MAPRED" class="headerlink" title="MAPRED"></a>MAPRED</h2><table>
<thead>
<tr>
<th>服务名称</th>
<th>现有配置</th>
<th>TO</th>
</tr>
</thead>
<tbody>
<tr>
<td>history server</td>
<td>1G</td>
<td>2G</td>
</tr>
</tbody>
</table>
<h2 id="HIVE"><a href="#HIVE" class="headerlink" title="HIVE"></a>HIVE</h2><table>
<thead>
<tr>
<th>服务名称</th>
<th>配置</th>
</tr>
</thead>
<tbody>
<tr>
<td>hiveserver2</td>
<td>769M</td>
</tr>
<tr>
<td>metastore</td>
<td>1G</td>
</tr>
<tr>
<td>hcatserver</td>
<td>1G</td>
</tr>
</tbody>
</table>
<p>3G</p>
<h2 id="HBASE"><a href="#HBASE" class="headerlink" title="HBASE"></a>HBASE</h2><table>
<thead>
<tr>
<th>服务名称</th>
<th>配置</th>
</tr>
</thead>
<tbody>
<tr>
<td>regionserver</td>
<td>2G</td>
</tr>
<tr>
<td>master</td>
<td>1G</td>
</tr>
</tbody>
</table>
<p>regionserver <em> 8 + master </em> 2 = 18G</p>
<h2 id="ZK"><a href="#ZK" class="headerlink" title="ZK"></a>ZK</h2><table>
<thead>
<tr>
<th>服务名称</th>
<th>配置</th>
</tr>
</thead>
<tbody>
<tr>
<td>zk server</td>
<td>1G</td>
</tr>
</tbody>
</table>
<p>zk * 3 = 3G</p>
<h2 id="KAFKA"><a href="#KAFKA" class="headerlink" title="KAFKA"></a>KAFKA</h2><table>
<thead>
<tr>
<th>服务名称</th>
<th>配置</th>
</tr>
</thead>
<tbody>
<tr>
<td>broker</td>
<td>1G</td>
</tr>
</tbody>
</table>
<p>broker * 3 =3G</p>
<h2 id="SPAKR"><a href="#SPAKR" class="headerlink" title="SPAKR"></a>SPAKR</h2><table>
<thead>
<tr>
<th>服务名称</th>
<th>配置</th>
</tr>
</thead>
<tbody>
<tr>
<td>spark history server</td>
<td>1G</td>
</tr>
</tbody>
</table>
<h2 id="需要copy的机器"><a href="#需要copy的机器" class="headerlink" title="需要copy的机器"></a>需要copy的机器</h2><p>以下机器copy完成后，全部将内存提升至32G、CPU提升到8核</p>
<h5 id="迁出机器"><a href="#迁出机器" class="headerlink" title="迁出机器"></a>迁出机器</h5><ul>
<li>datanode15.will.com     -&gt; NM，DN</li>
<li>1.103-prd-datanode14.will.com   -&gt;kafka, DN,NM</li>
<li>1.108-prd-datanode19.will.com -&gt; regionserver, DN,NM</li>
<li>1.110-prd-datanode21.will.com -&gt; NM, DN</li>
<li>1.99-prd-datanode10.will.com -&gt; kafka, DB, NM</li>
<li>1.113-fengkong.data.com 风控 -&gt; NONE</li>
<li>1.87-prd-datanode05.data.com -&gt; DN, NM, regionserver</li>
<li>1.97-prd-datanode08.data.com -&gt; DN, NM, regionserver</li>
<li>1.95-prd-datanode06.data.com -&gt; kafka, DN, NM, SB HbaseMaster</li>
<li>1.96-prd-datanode07.data.com -&gt; DN, NM, regionserver</li>
</ul>
<p>原有机器迁出会占新资源的内存32G <em> 10 + CPU</em>80</p>
<h5 id="原有机器资源升级"><a href="#原有机器资源升级" class="headerlink" title="原有机器资源升级"></a>原有机器资源升级</h5><p>在原有资源基础上，添加16G内存，CPU核数翻倍【把迁移出去的机器空闲出来的资源充分利用】：</p>
<ul>
<li>1.107-prd-datanode18.will.com</li>
<li>1.109-prd-datanode20.will.com</li>
<li>1.102-prd-datanode13.will.com</li>
<li>1.106-prd-datanode17.will.com</li>
<li>1.100-prd-datanode11.will.com</li>
<li>1.98-prd-datanode09.will.com</li>
<li>1.110-prd-datanode21.will.com</li>
<li>1.86-prd-datanode04.data.com</li>
<li>1.82-prd-datanode01.data.com</li>
<li>1.83-prd-datanode02.data.com</li>
<li>1.84-prd-datanode03.data.com</li>
<li>1.105-prd-datanode16.will.com</li>
<li>1.101-prd-datanode12.will.com</li>
</ul>
<p>理论上，对原有机器不会有额外资源要求，对新机器资源也不会有影响。</p>
<h2 id="需要新建的机器"><a href="#需要新建的机器" class="headerlink" title="需要新建的机器"></a>需要新建的机器</h2><h4 id="新服务节点"><a href="#新服务节点" class="headerlink" title="新服务节点"></a>新服务节点</h4><p>可按照service01.will.com开始弄主机名。</p>
<p>单机配置： 32G内存 + 8核 + 50G硬【整机空间即可】 + CentOS release 6.8 (Final)</p>
<p>机器数量： 8台<br>共占：内存32G <em> 8 + CPU8 </em> 8 = 内存256G + CPU 64</p>
<h4 id="新数据节点"><a href="#新数据节点" class="headerlink" title="新数据节点"></a>新数据节点</h4><p>目前最新数据节点的主机名编号到了21，新机器可以datanode22.will.com开始。</p>
<p>单机配置：32G内存 + 8核CPU + 640G硬盘【/server/目录挂载空间】 + CentOS release 6.8 (Final)</p>
<p>机器数量： 12【如果物理机资源不够，可以暂时弄10台，以后酌情扩容】</p>
<p>共占：内存32G <em> 12 + CPU8 </em> 12 = 内存384G + CPU 96</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/04/20/ambari中启用hive-ACID事务/" title="ambari中启用hive-ACID事务" itemprop="url">ambari中启用hive-ACID事务</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-04-20T12:21:45.000Z" itemprop="datePublished"> 发表于 2017-04-20</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>场景</p>
<ul>
<li>数据重新执行</li>
<li>数据流重新执行</li>
<li>逐渐改变的维度</li>
<li>维度历史变更</li>
</ul>
<p>标准sql通过insert、update、delete、事务还有最近出现的merge方式来提供acid操作。这些已经被证明足够使用的了。</p>
<h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><ul>
<li>事务表。hive支持单表事务，但是目标表必须需要声明是支持事务的。</li>
<li>分区表。hive支持表分区，把数据分开以提供快速查询。分区与ACID是相互独立的概念。通常大表都是有分区的。</li>
<li>ACID操作（insert/update/delete）。</li>
<li>主键</li>
<li>流式数据。数据可以通过storm、flume等流式进入hive的事务表中</li>
<li>优化并发。</li>
<li>压缩。数据必须时段性的被压缩一下，节省空间，优化数据访问。最好让系统自动处理这件事情。，不过也可以设置外部的调度器。</li>
</ul>
<h4 id="启用ACID事务"><a href="#启用ACID事务" class="headerlink" title="启用ACID事务"></a>启用ACID事务</h4><h4 id="hello"><a href="#hello" class="headerlink" title="hello"></a>hello</h4><p>创建一个事务表，并插入一些数据<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> hello_acid;</div><div class="line"><span class="keyword">create</span> <span class="keyword">table</span> hello_acid (<span class="keyword">key</span> <span class="built_in">int</span>, <span class="keyword">value</span> <span class="built_in">int</span>)</div><div class="line">partitioned <span class="keyword">by</span> (load_date <span class="built_in">date</span>)</div><div class="line">clustered <span class="keyword">by</span>(<span class="keyword">key</span>) <span class="keyword">into</span> <span class="number">3</span> buckets</div><div class="line"><span class="keyword">stored</span> <span class="keyword">as</span> orc tblproperties (<span class="string">'transactional'</span>=<span class="string">'true'</span>);</div></pre></td></tr></table></figure></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">insert</span> <span class="keyword">into</span> hello_acid <span class="keyword">partition</span> (load_date=<span class="string">'2016-03-01'</span>) <span class="keyword">values</span> (<span class="number">1</span>, <span class="number">1</span>);</div><div class="line"><span class="keyword">insert</span> <span class="keyword">into</span> hello_acid <span class="keyword">partition</span> (load_date=<span class="string">'2016-03-02'</span>) <span class="keyword">values</span> (<span class="number">2</span>, <span class="number">2</span>);</div><div class="line"><span class="keyword">insert</span> <span class="keyword">into</span> hello_acid <span class="keyword">partition</span> (load_date=<span class="string">'2016-03-03'</span>) <span class="keyword">values</span> (<span class="number">3</span>, <span class="number">3</span>);</div><div class="line"><span class="keyword">select</span> * <span class="keyword">from</span> hello_acid;</div></pre></td></tr></table></figure>
<p>删除数据：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">delete</span> <span class="keyword">from</span> hello_acid <span class="keyword">where</span> <span class="keyword">key</span> = <span class="number">2</span>;</div><div class="line"><span class="keyword">select</span> * <span class="keyword">from</span> hello_acid;</div></pre></td></tr></table></figure></p>
<p>更新数据：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">update</span> hello_acid <span class="keyword">set</span> <span class="keyword">value</span> = <span class="number">10</span> <span class="keyword">where</span> <span class="keyword">key</span> = <span class="number">3</span>;</div><div class="line"><span class="keyword">select</span> * <span class="keyword">from</span> hello_acid;</div></pre></td></tr></table></figure></p>
<p>这些DML语句意在在大数据中执行少量修改，应该是记录级别的数据管理。如果你有小的多个批量修改，应该使用streaming data ingestion。</p>
<h4 id="Streaming-Data-Ingestion"><a href="#Streaming-Data-Ingestion" class="headerlink" title="Streaming Data Ingestion"></a>Streaming Data Ingestion</h4><p>许多时候我们需要处理连续的实时数据流，想要更方便的操作这些数据。hive可以自动把流式数据加入hive表中，也支持实时的数据抽取与查询。</p>
<p>现在hive提供两种：</p>
<ul>
<li>已经存在是<a href="https://github.com/apache/storm/tree/master/external/storm-hive" target="_blank" rel="external">storm hive bolt</a>方案，<a href="https://flume.apache.org/FlumeUserGuide.html#hive-sink" target="_blank" rel="external">flume hive sink</a>方案。这些工具对数据有较少的操作，重在转移数据</li>
<li>直接使用低级的<a href="https://cwiki.apache.org/confluence/display/Hive/Streaming+Data+Ingest" target="_blank" rel="external">Streaming Ingest API</a>.</li>
</ul>
<p>在使用streaming api之前，需要先创建好分区事务表。从查询角度来看，一切应该都是确定好的。</p>
<h4 id="4-实践"><a href="#4-实践" class="headerlink" title="4. 实践"></a>4. 实践</h4><p>插入几条数据对我们测试起来很简单，但是实际环境中，我们需要一次性处理几千或者几百万的数据。下面我们通过几个通用场景讨论一下怎样处理数据批次。</p>
<p>这些模型需要你建立一个主键。hive并不强制主键唯一，所以你必须在你app中控制一下。虽然hive2.1介绍了non-validating 外键，但是这东西目前还并没有被完整全面的验证过。</p>
<h5 id="4-1-searched-updates"><a href="#4-1-searched-updates" class="headerlink" title="4.1 searched updates"></a>4.1 searched updates</h5><p>hive  ACID支持searched updates，这是一种常见的更新方式。注意，基于hive ACID的架构，更新必须通过批处理的方式执行。一次更新一行这种事情在实际使用中是行不通的。如果想通过某种方式一次性更新大量数据，那么searched updates就可以帮你了。</p>
<p>假设有一个维度表，包含的一个flag，指示当前记录是不是最新的值。这样我们就可以沿时间追踪维度变更情况。当维度表发生更新的时候，我们就把已经存在记录的设置成old。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> mydim;</div><div class="line"><span class="keyword">create</span> <span class="keyword">table</span> mydim (<span class="keyword">key</span> <span class="built_in">int</span>, <span class="keyword">name</span> <span class="keyword">string</span>, zip <span class="keyword">string</span>, is_current <span class="built_in">boolean</span>)</div><div class="line">clustered <span class="keyword">by</span>(<span class="keyword">key</span>) <span class="keyword">into</span> <span class="number">3</span> buckets</div><div class="line"><span class="keyword">stored</span> <span class="keyword">as</span> orc tblproperties (<span class="string">'transactional'</span>=<span class="string">'true'</span>);</div></pre></td></tr></table></figure></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">insert</span> <span class="keyword">into</span> mydim <span class="keyword">values</span></div><div class="line">  (<span class="number">1</span>, <span class="string">'bob'</span>,   <span class="string">'95136'</span>, <span class="literal">true</span>),</div><div class="line">  (<span class="number">2</span>, <span class="string">'joe'</span>,   <span class="string">'70068'</span>, <span class="literal">true</span>),</div><div class="line">  (<span class="number">3</span>, <span class="string">'steve'</span>, <span class="string">'22150'</span>, <span class="literal">true</span>);</div></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> updates_staging_table;</div><div class="line"><span class="keyword">create</span> <span class="keyword">table</span> updates_staging_table (<span class="keyword">key</span> <span class="built_in">int</span>, newzip <span class="keyword">string</span>);</div><div class="line"><span class="keyword">insert</span> <span class="keyword">into</span> updates_staging_table <span class="keyword">values</span> (<span class="number">1</span>, <span class="number">87102</span>), (<span class="number">3</span>, <span class="number">45220</span>);</div></pre></td></tr></table></figure>
<p>执行更新,执行前后可以看一下维度表的数据变化，其实就是更新了flag而已。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">update</span> mydim <span class="keyword">set</span> is_current=<span class="literal">false</span></div><div class="line">  <span class="keyword">where</span> mydim.key <span class="keyword">in</span> (<span class="keyword">select</span> <span class="keyword">key</span> <span class="keyword">from</span> updates_staging_table);</div></pre></td></tr></table></figure></p>
<h5 id="4-2-searched-deletes"><a href="#4-2-searched-deletes" class="headerlink" title="4.2 searched deletes"></a>4.2 searched deletes</h5><p>批量删除也可以使用staging table轻松搞定。但是需要你在表之间放置一个公共key，有些类似RDBMS中的主键。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">delete</span> <span class="keyword">from</span> mydim</div><div class="line"><span class="keyword">where</span> mydim.key <span class="keyword">in</span> (<span class="keyword">select</span> <span class="keyword">key</span> <span class="keyword">from</span> updates_staging_table);</div><div class="line"><span class="keyword">select</span> * <span class="keyword">from</span> mydim;</div></pre></td></tr></table></figure></p>
<h4 id="5-批量覆盖更新"><a href="#5-批量覆盖更新" class="headerlink" title="5. 批量覆盖更新"></a>5. 批量覆盖更新</h4><p>有的时候我们需要批量更新一些数据。例如第一种SCD更新或者数据重导。hive目前还不支持merge操作，在支持之前，我们只能考虑使用先删除后插入的方式，但这样可能会造成查询客户端脏读。或者也可以在重新清洗的时候临时停掉查询。</p>
<h4 id="6-ACID工具"><a href="#6-ACID工具" class="headerlink" title="6. ACID工具"></a>6. ACID工具</h4><p>ACID事务执行过程中会创建一系列的锁。事务和他们的事务锁可以通过hive的一些工具来查看。</p>
<h5 id="6-1-查看事务"><a href="#6-1-查看事务" class="headerlink" title="6.1 查看事务"></a>6.1 查看事务</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">show transactions</div></pre></td></tr></table></figure>
<h5 id="6-1-查看锁"><a href="#6-1-查看锁" class="headerlink" title="6.1 查看锁"></a>6.1 查看锁</h5><p>有read, update，X lock。update锁与update操作互斥，但是与read兼容。X锁，与所有锁都互斥，属于独占。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">show locks</div></pre></td></tr></table></figure></p>
<h5 id="6-1-终止事务"><a href="#6-1-终止事务" class="headerlink" title="6.1 终止事务"></a>6.1 终止事务</h5><p>注意这并不会马上kill掉所有相关查询。ACID查询是周期性执行的，默认是2.5分钟，如果他们检测到自己的事务被kill，就会执行自动退出。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">abort transactions T1 T2 T3</div></pre></td></tr></table></figure></p>
<h4 id="7-性能考虑"><a href="#7-性能考虑" class="headerlink" title="7. 性能考虑"></a>7. 性能考虑</h4><ul>
<li>创建分区</li>
<li>insert快，update和delete都会比较慢一些，因为要扫描整个分区。</li>
<li>如果你们的工作里需要大量更新数据，那么请周期行执行compaction操作。不然数据大小会越来越大，查询也会越来越慢。</li>
</ul>
<h4 id="8-深入探究"><a href="#8-深入探究" class="headerlink" title="8. 深入探究"></a>8. 深入探究</h4><p>在使用之前一定要深入了解这套系统的工作原理，并且在你的可以容忍丢失的数据上执行测试。过程中也注意备份数据。</p>
<p>ACID表有一个隐藏字段<code>row__id</code>。这个系统内置的字段名称有可能会变。你应该构建一个基于这个字段的长远的方案。</p>
<p>这个字段记录的内容有：</p>
<ul>
<li>数据被insert或者update的active的事务id</li>
<li>数据所在bucket的bucketid</li>
<li>此次事务或者bucket中的rowid</li>
</ul>
<p>看一下<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">hive&gt; select row__id from hello_acid;</div><div class="line">OK</div><div class="line">&#123;"transactionid":12,"bucketid":0,"rowid":0&#125;</div><div class="line">&#123;"transactionid":10,"bucketid":1,"rowid":0&#125;</div></pre></td></tr></table></figure></p>
<p>常用场景就是确认所有的数据都load进来了。假设上游数据provider认为hive里的持久化数据丢失了，那么你的provider(storm Bolt比如)就会告诉你插入这些数据的事务ID。然后我们可以使用这个事务id计算一下实际的记录数。查询的时候使用X替换掉你的事务ID<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">set</span> hive.optimize.ppd=<span class="literal">false</span>;</div><div class="line"><span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> hello_acid <span class="keyword">where</span> row__id.transactionid = X;</div></pre></td></tr></table></figure></p>
<p>记牢，事务中插入的数据有可能会被后续的update或者delete语句影响到，所以如果count数并不符合，那就可能是这些因素造成的。</p>
<p>参考：</p>
<p><a href="https://hortonworks.com/hadoop-tutorial/using-hive-acid-transactions-insert-update-delete-data/" target="_blank" rel="external">https://hortonworks.com/hadoop-tutorial/using-hive-acid-transactions-insert-update-delete-data/</a></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/04/20/HIVE创建bucketed表/" title="HIVE创建bucketed表" itemprop="url">HIVE创建bucketed表</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-04-20T10:54:03.000Z" itemprop="datePublished"> 发表于 2017-04-20</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>建表语句<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">CREATE TABLE user_info_bucketed(user_id BIGINT, firstname STRING, lastname STRING)</div><div class="line">COMMENT &apos;A bucketed copy of user_info&apos;</div><div class="line">PARTITIONED BY(ds STRING)</div><div class="line">CLUSTERED BY(user_id) INTO 256 BUCKETS;</div></pre></td></tr></table></figure></p>
<p>基于字段user_id分桶的。</p>
<p>使用<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">set</span> hive.enforce.bucketing = <span class="literal">true</span>;  <span class="comment">-- (<span class="doctag">Note:</span> Not needed in Hive 2.x onward)</span></div><div class="line">FROM user_id</div><div class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> user_info_bucketed</div><div class="line"><span class="keyword">PARTITION</span> (ds=<span class="string">'2009-02-25'</span>)</div><div class="line"><span class="keyword">SELECT</span> userid, firstname, lastname <span class="keyword">WHERE</span> ds=<span class="string">'2009-02-25'</span>;</div></pre></td></tr></table></figure></p>
<p>hive怎样把row打散到不同的bucket中去的呢？一般是决定于hash函数，使用什么hash函数又取决于分桶字段的类型。比如整型字段就使用hash_int函数。</p>
<p>注意，如果分桶字段类型不同于insert进来的数据类型会出错的，或者手动使用不同类型的数据执行分桶操作也会出错。只要设置了<code>set hive.enforce.bucketing=true</code>，就能够正确的把数据发布到对应的地方。</p>
<p>再来一个例子<br>Bucketed Sorted Table<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> page_view(viewTime <span class="built_in">INT</span>, userid <span class="built_in">BIGINT</span>,</div><div class="line">     page_url <span class="keyword">STRING</span>, referrer_url <span class="keyword">STRING</span>,</div><div class="line">     ip <span class="keyword">STRING</span> <span class="keyword">COMMENT</span> <span class="string">'IP Address of the User'</span>)</div><div class="line"> <span class="keyword">COMMENT</span> <span class="string">'This is the page view table'</span></div><div class="line"> PARTITIONED <span class="keyword">BY</span>(dt <span class="keyword">STRING</span>, country <span class="keyword">STRING</span>)</div><div class="line"> CLUSTERED <span class="keyword">BY</span>(userid) SORTED <span class="keyword">BY</span>(viewTime) <span class="keyword">INTO</span> <span class="number">32</span> BUCKETS</div><div class="line"> <span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span></div><div class="line">   <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\001'</span></div><div class="line">   COLLECTION ITEMS <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\002'</span></div><div class="line">   <span class="keyword">MAP</span> <span class="keyword">KEYS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\003'</span></div><div class="line"> <span class="keyword">STORED</span> <span class="keyword">AS</span> SEQUENCEFILE;</div></pre></td></tr></table></figure></p>
<p>这个表根据userid分桶，每个bucket中按照viewTime升序排列。这种组织结果允许用户更高效的抽取clustered的字段，这里就是userid字段了。排序属性让内部操作能够快速处理估算查询的任务。MAP KEYS和COLLECTION ITEMS关键词可以用来处理字段是list或者map的情况。</p>
<p>CLUSTERED BY 和 SORTED BY并不影响insert数据。用户需要注意reducer数必须要跟bucket的数量一致，在query语句中还要使用CLUSTER BY 和SORT BY语句。</p>
<p>还有一种倾斜表。适用于某些表中确认包含倾斜数据的情况。通过指定倾斜key，hive会把他们打散到不同的文件中。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> list_bucket_single (<span class="keyword">key</span> <span class="keyword">STRING</span>, <span class="keyword">value</span> <span class="keyword">STRING</span>)</div><div class="line">  SKEWED <span class="keyword">BY</span> (<span class="keyword">key</span>) <span class="keyword">ON</span> (<span class="number">1</span>,<span class="number">5</span>,<span class="number">6</span>) [<span class="keyword">STORED</span> <span class="keyword">AS</span> DIRECTORIES];</div></pre></td></tr></table></figure>
<p>下面这个是有两个倾斜key<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">CREATE TABLE list_bucket_multiple (col1 STRING, col2 int, col3 STRING)</div><div class="line">  SKEWED BY (col1, col2) ON ((&apos;s1&apos;,1), (&apos;s3&apos;,3), (&apos;s13&apos;,13), (&apos;s78&apos;,78)) [STORED AS DIRECTORIES];</div></pre></td></tr></table></figure></p>
<p>参考：</p>
<ul>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL+BucketedTables" target="_blank" rel="external">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL+BucketedTables</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-BucketedSortedTables" target="_blank" rel="external">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-BucketedSortedTables</a></li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






  <nav id="page-nav" class="clearfix">
    <a class="extend prev" rel="prev" href="/page/10/"><span></span>Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><a class="page-number" href="/page/10/">10</a><span class="page-number current">11</span><a class="page-number" href="/page/12/">12</a><a class="page-number" href="/page/13/">13</a><span class="space">&hellip;</span><a class="page-number" href="/page/24/">24</a><a class="extend next" rel="next" href="/page/12/">Next<span></span></a>
  </nav>

</div>
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  


  

  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/youdaonote/" title="youdaonote">youdaonote<sup>187</sup></a></li>
			
		
			
				<li><a href="/tags/源码/" title="源码">源码<sup>10</sup></a></li>
			
		
			
				<li><a href="/tags/akka/" title="akka">akka<sup>9</sup></a></li>
			
		
			
				<li><a href="/tags/flume/" title="flume">flume<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/ETL/" title="ETL">ETL<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/solr/" title="solr">solr<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/spring/" title="spring">spring<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/调度平台/" title="调度平台">调度平台<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/azkaban/" title="azkaban">azkaban<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/mysql/" title="mysql">mysql<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/scala/" title="scala">scala<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/ambari/" title="ambari">ambari<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/quartz/" title="quartz">quartz<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/nodejs/" title="nodejs">nodejs<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Solr/" title="Solr">Solr<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/guava/" title="guava">guava<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/heroku/" title="heroku">heroku<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/hdfs/" title="hdfs">hdfs<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/hue/" title="hue">hue<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/ElasticSearch/" title="ElasticSearch">ElasticSearch<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="https://github.com/willcup" target="_blank" title=" 我自己的github">github</a>
            
          </li>
        
          <li>
            
            	<a href="http://thisding.com" target="_blank" title="朋友的主页">Steven&#39;s Blog</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

  <div class="weiboshow">
  <p class="asidetitle">新浪微博</p>
    <iframe width="100%" height="119" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=null&verifier=&dpc=1"></iframe>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m Will Chen in MeiTuan. <br/>
			元 亨 利 贞.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
		<a href="mailto:chenxin15@meituan.com" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2017 
		
		<a href="/about" target="_blank" title="Will Chen">Will Chen</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>










<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3Fe6d1f421bbc9962127a50488f9ed37d1' type='text/javascript'%3E%3C/script%3E"));
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
 </html>
