
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <script type="text/javascript">
    (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
    })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');
    
    _st('install','yNiKTKaAnwd1uuxVMfiE','2.0.0');
  </script>
  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?5b99dfd487346155d274c0c49c3fb869";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
  </script>

  
    <title>Will&#39;s Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Will Chen">
    

    
    <meta name="description" content="左右水色 右手天光">
<meta property="og:type" content="website">
<meta property="og:title" content="Will's Blog">
<meta property="og:url" content="https://runningdata.github.io/page/11/index.html">
<meta property="og:site_name" content="Will's Blog">
<meta property="og:description" content="左右水色 右手天光">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Will's Blog">
<meta name="twitter:description" content="左右水色 右手天光">

    
    <link rel="alternative" href="/atom.xml" title="Will&#39;s Blog" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="Will&#39;s Blog" title="Will&#39;s Blog"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Will&#39;s Blog">Will&#39;s Blog</a></h1>
				<h2 class="blog-motto">简易 变易 不易</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">首页</a></li>
					
						<li><a href="/archives">归档</a></li>
					
						<li><a href="/about">关于</a></li>
					
					<li>
 					
                                                <form class="search" action="/search/index.html" method="get" accept-charset="utf-8" target="_blank">
                                                        <label>搜索</label>
                                                <input name="s" type="hidden" value= null ><input type="text" class="st-default-search-input" name="q" size="30" placeholder="搜索"><br>
                                                </form>
					
					</li>
				</ul>
			</nav>			
</div>

    </header>
    <div id="container">
      <div id="main">

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/05/25/linux中的hang进程/" title="linux中的hang进程" itemprop="url">linux中的hang进程</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-05-25T03:10:38.000Z" itemprop="datePublished"> 发表于 2017-05-25</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>5月24号晚上发现62上有两个hang的进程，占满了内存与cpu</p>
<p>第一个是M2H任务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">root     10082     1 97 May21 ?        3-20:08:33 /server/java/jdk1.8.0_60/bin/java -Xmx4096m -Dhdp.version=2.4.2.0-258 -Djava.net.preferIPv4Stack=true -Dhdp.version=2.4.2.0-258 -Dhadoop.log.dir=/var/log/hadoop/root -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/hdp/2.4.2.0-258/hadoop -Dhadoop.id.str=root -Dhadoop.root.logger=INFO,console -Djava.library.path=:/usr/hdp/2.4.2.0-258/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.4.2.0-258/hadoop/lib/native -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx4096m -Dhadoop.security.logger=INFO,NullAppender org.apache.sqoop.Sqoop import -Dmapreduce.job.queuename=xstorm --connect jdbc:mysql://10.0.100.73:3306/xiaodai?useCursorFetch=true&amp;dontTrackOpenResources=true&amp;defaultFetchSize=2000 --driver com.mysql.jdbc.Driver --username weixddata_read --password G7iu1BMo9LWs2e --hive-database ods_tinyv --columns ID,USER_ID,WB_USERNAME,MOBILE,BIZ_ID,MSG_TYPE,SMS_TYPE,DATA_SOURCE,SMS_ID,TASK_ID,SEND_STATUS,RES_CODE,REPORT_STATUS,SEND_TIME,REPORT_TIME,SEND_EXCEPTION --where DATE_FORMAT(SEND_TIME, &apos;%Y-%m-%d&apos;)=&apos;2017-05-20&apos; --table SMS_INFO --hive-import --hive-overwrite --target-dir ods_tinyv_SMS_INFO --outdir /server/app/sqoop/vo --bindir /server/app/sqoop/vo --verbose -m 1 --delete-target-dir --hive-import --hive-table o_wb_xiaodai_sms_info_i --hive-partition-key dt --hive-partition-value 2017-05-20 --null-string \\N --null-non-string \\N</div></pre></td></tr></table></figure></p>
<p>还有一个HIVE任务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">root      3483     1 96 May23 ?        1-11:12:07 /server/java/jdk1.8.0_60/bin/java -Xmx4096m -Dhdp.version=2.4.2.0-258 -Djava.net.preferIPv4Stack=true -Dhdp.version=2.4.2.0-258 -Djava.net.preferIPv4Stack=true -XX:NewRatio=12 -XX:MaxHeapFreeRatio=40 -XX:MinHeapFreeRatio=15 -XX:+UseNUMA -XX:+UseParallelGC -XX:-UseGCOverheadLimit -Dhdp.version=2.4.2.0-258 -Dhadoop.log.dir=/var/log/hadoop/root -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/hdp/2.4.2.0-258/hadoop -Dhadoop.id.str=root -Dhadoop.root.logger=INFO,console -Djava.library.path=:/usr/hdp/2.4.2.0-258/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.4.2.0-258/hadoop/lib/native -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx4096m -Xmx1024m -Dhadoop.security.logger=INFO,NullAppender -Dhdp.version=2.4.2.0-258 -Dhadoop.log.dir=/var/log/hadoop/root -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/hdp/2.4.2.0-258/hadoop -Dhadoop.id.str=root -Dhadoop.root.logger=INFO,console -Djava.library.path=:/usr/hdp/2.4.2.0-258/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.4.2.0-258/hadoop/lib/native:/usr/hdp/2.4.2.0-258/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.4.2.0-258/hadoop/lib/native -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx4096m -Xmx4096m -Xmx1024m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar /usr/hdp/2.4.2.0-258/hive/lib/hive-exec-1.2.1000.2.4.2.0-258.jar org.apache.hadoop.hive.ql.exec.mr.ExecDriver -localtask -plan file:/tmp/root/228f95e6-26ee-4466-bd3d-a91195c86bf4/hive_2017-05-23_10-38-11_000_7465740175512782543-1/-local-10004/plan.xml -jobconffile file:/tmp/root/228f95e6-26ee-4466-bd3d-a91195c86bf4/hive_2017-05-23_10-38-11_000_7465740175512782543-1/-local-10005/jobconf.xml</div></pre></td></tr></table></figure></p>
<p>手贱，先kill掉了，不然还能看到上面的plan文件，和job配置文件什么的。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/05/18/runningdata改版记录/" title="runningdata改版记录" itemprop="url">runningdata改版记录</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-05-18T02:54:54.000Z" itemprop="datePublished"> 发表于 2017-05-18</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>抽象ETLObjRelated，其他对象继承之</p>
<ul>
<li>ETL的字段名tbl_name需要在数据库里修改为name<ul>
<li>tasks里的exec_etl_sche任务会调用etl.name【老表的tbl_name会报错找不到】</li>
</ul>
</li>
<li>执行metamap 0045的migrations，这个只是添加字段，不会造成额外影响</li>
<li></li>
</ul>
<p>sdf </p>
<ol>
<li><p>确保新的save方法都已经注释掉</p>
</li>
<li><p>./manage.py migrate metamap 0050 –settings=metamap.config</p>
</li>
<li><p>开始清洗</p>
</li>
</ol>
<ul>
<li>clean_etl</li>
<li>clean_rel</li>
<li>clean_m2h</li>
<li>before_clean_blood</li>
<li>clean_blood</li>
<li>clean_h2m</li>
<li>clean_jar</li>
<li>clean_email</li>
<li>clean_task[分别执行clean， type=4, type=1等等]</li>
<li>clean_period</li>
</ul>
<h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><ol>
<li>H2M中的个别现象，多个周期的数据存放在同一个表中：<br>SELECT * from metamap_sqoophive2mysql where id in (71,72,73,74,75,76)<br>需要额外手动维护execblood</li>
<li>放开那些注释</li>
</ol>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/05/10/django用户组的思考/" title="django用户组的思考" itemprop="url">django用户组的思考</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-05-10T09:24:10.000Z" itemprop="datePublished"> 发表于 2017-05-10</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>我们有两个不同的事业部A, B， 目前是用django的group来做的。。。都在我的平台上编辑自己的内容OBJ，我给OBJ指定了唯一一个group_id外键来保证AB事业部内容的隔离。。。。现在遇到问题，因为要控制一些权限，当加group的时候…..自己就懵逼了</p>
<p>不该这样处理AB，对吧。。。应该额外建立一个oaganization来作为AB隔离的。django的group用来做操作权限控制更好，而不是对象隔离。</p>
<p>所以现在的代码结构是：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">OrgGroup</span><span class="params">(models.Model)</span>:</span></div><div class="line">    name = models.CharField(max_length=<span class="number">200</span>, verbose_name=<span class="string">u"组织名称"</span>)</div><div class="line">    owners = models.CharField(max_length=<span class="number">100</span>, verbose_name=<span class="string">u"负责人"</span>, blank=<span class="keyword">True</span>, default=<span class="string">''</span>)</div><div class="line">    hdfs_path = models.CharField(max_length=<span class="number">100</span>, verbose_name=<span class="string">u"HDFS临时路径"</span>, blank=<span class="keyword">True</span>, default=<span class="string">''</span>)</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> self.name</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">UserProfile</span><span class="params">(models.Model)</span>:</span></div><div class="line">    user = models.OneToOneField(User)</div><div class="line">    phone = models.BigIntegerField(default=<span class="number">110</span>)</div><div class="line">    org_group = models.ForeignKey(OrgGroup, on_delete=models.DO_NOTHING, related_name=<span class="string">'user_cgroup'</span>, null=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> self.user.username</div></pre></td></tr></table></figure></p>
<p>重新定义了一个组织的model，然后每个人都有属于某个特定的组织。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">JarApp</span><span class="params">(models.Model)</span>:</span></div><div class="line">    .....</div><div class="line">    cgroup = models.ForeignKey(OrgGroup, on_delete=models.DO_NOTHING, </div><div class="line">    .....</div></pre></td></tr></table></figure>
<p>上面的cgroup原来是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cgroup = models.ForeignKey(auth.Group, on_delete=models.DO_NOTHING, related_name=&apos;jar_cgroup&apos;, null=True)</div></pre></td></tr></table></figure></p>
<p>然后还要重构JarApp的新建与查询的一些代码。</p>
<p>这样，使用自定义的组织来划分人员与面向的内容。使用django的group来控制是否组织内特定人员组具有的权限【ETL开发人员、与报表开发人员】。</p>
<p>自定义的组织用来限定报表和ETL所属的组织。而django的auth.group可以管理一组权限【对ETL、报表的访问权限、操作权限等】。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/05/09/ambari个别component扩张/" title="ambari个别component扩张" itemprop="url">ambari个别component扩张</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-05-09T03:08:30.000Z" itemprop="datePublished"> 发表于 2017-05-09</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>需要扩展20个NodeManager，ambari只能手动到每个datanode界面上去安装NodeManager，并启动。啰嗦，麻烦。</p>
<p>看了一下ajax请求，整理了一个脚本。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">#!/bin/bash</div><div class="line"></div><div class="line">for i in `seq 26 33`;</div><div class="line">do</div><div class="line"></div><div class="line">echo handing $i</div><div class="line"></div><div class="line"># 安装service</div><div class="line">curl -u admin:will@bj15. -H &quot;X-Requested-By: ambari&quot; -X POST -d &apos;</div><div class="line">&#123;&quot;RequestInfo&quot;:&#123;&quot;context&quot;:&quot;Install NodeManager&quot;&#125;,&quot;Body&quot;:&#123;&quot;host_components&quot;:[&#123;&quot;HostRoles&quot;:&#123;&quot;component_name&quot;:&quot;NODEMANAGER&quot;&#125;&#125;]&#125;&#125;&apos; http://namenode01.will.com:8080/api/v1/clusters/datacenter/hosts?Hosts/host_name=datanode$&#123;i&#125;.will.com</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"># 安装component</div><div class="line">curl -u admin:will@bj15. -H &quot;X-Requested-By: ambari&quot; -X PUT -d &apos;</div><div class="line">&#123;&quot;RequestInfo&quot;:&#123;&quot;context&quot;:&quot;Install NodeManager&quot;,&quot;operation_level&quot;:&#123;&quot;level&quot;:&quot;HOST_COMPONENT&quot;,&quot;cluster_name&quot;:&quot;datacenter&quot;,&quot;host_name&quot;:&quot;datanode$&#123;i&#125;.will.com&quot;,&quot;service_name&quot;:&quot;YARN&quot;&#125;&#125;,&quot;Body&quot;:&#123;&quot;HostRoles&quot;:&#123;&quot;state&quot;:&quot;INSTALLED&quot;&#125;&#125;&#125;&apos; http://namenode01.will.com:8080/api/v1/clusters/datacenter/hosts/datanode$&#123;i&#125;.will.com/host_components/NODEMANAGER?HostRoles/state=INIT</div><div class="line"></div><div class="line"></div><div class="line"># 启动</div><div class="line">curl -u admin:will@bj15. -H &quot;X-Requested-By: ambari&quot; -X PUT -d &apos;&#123;&quot;RequestInfo&quot;:&#123;&quot;context&quot;:&quot;Start NodeManager&quot;,&quot;operation_level&quot;:&#123;&quot;level&quot;:&quot;HOST_COMPONENT&quot;,&quot;cluster_name&quot;:&quot;datacenter&quot;,&quot;host_name&quot;:&quot;datanode$&#123;i&#125;.will.com&quot;,&quot;service_name&quot;:&quot;YARN&quot;&#125;&#125;,&quot;Body&quot;:&#123;&quot;HostRoles&quot;:&#123;&quot;state&quot;:&quot;STARTED&quot;&#125;&#125;&#125;&apos; http://namenode01.will.com:8080/api/v1/clusters/datacenter/hosts/datanode$&#123;i&#125;.will.com/host_components/NODEMANAGER</div><div class="line">done</div></pre></td></tr></table></figure></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/04/27/自制RPM包并发布到自己的yum源/" title="自制RPM包并发布到自己的yum源" itemprop="url">自制RPM包并发布到自己的yum源</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-04-27T03:29:46.000Z" itemprop="datePublished"> 发表于 2017-04-27</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>使用一个普通用户执行，以免对系统造成重伤。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install -y rpmdevtools rpm-build</div></pre></td></tr></table></figure>
<h2 id="自定义工作空间"><a href="#自定义工作空间" class="headerlink" title="自定义工作空间"></a>自定义工作空间</h2><p>方案1：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rpmdev-setuptree</div></pre></td></tr></table></figure>
<p>方案2</p>
<p>创建文件~/.rpmmacros<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">%_topdir        /home/will/rpmbuild</div></pre></td></tr></table></figure></p>
<p>配置了空间之后，还得手动创建一下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mkdir /home/will/rpmbuild</div></pre></td></tr></table></figure></p>
<p>创建需要的目录<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd ~/rpmbuild  </div><div class="line">mkdir -pv &#123;BUILD,BUILDROOT,RPMS,SOURCES,SPECS,SRPMS&#125;</div></pre></td></tr></table></figure></p>
<ul>
<li>BUILD #编译之前，如解压包后存放的路径</li>
<li>BUILDROOT #编译后存放的路径</li>
<li>RPMS #打包完成后rpm包存放的路径</li>
<li>SOURCES #源包所放置的路径</li>
<li>SPECS #spec文档放置的路径</li>
<li>SPRMS #源码rpm包放置的路径</li>
</ul>
<p>注：一般我们都把源码打包成tar.gz格式然后存放于SOURCES路径下，而在SPECS路径下编写spec文档，通过命令打包后，默认会把打包后的rpm包放在RPMS下，而源码包会被放置在SRPMS下</p>
<h2 id="源码放到SOURCES目录"><a href="#源码放到SOURCES目录" class="headerlink" title="源码放到SOURCES目录"></a>源码放到SOURCES目录</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cp /tmp/redis-3.2.8.tar.gz SOURCES</div></pre></td></tr></table></figure>
<h2 id="SPECS下创建配置"><a href="#SPECS下创建配置" class="headerlink" title="SPECS下创建配置"></a>SPECS下创建配置</h2><p>到SPECS下创建指定配置，编辑的时候会自动生成模板。编辑<code>SPECS/redis.spec</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div></pre></td><td class="code"><pre><div class="line">Name:		redis</div><div class="line">Version:	3.2.8	</div><div class="line">Release:	3%&#123;dist&#125;</div><div class="line">Summary:	redis from will	</div><div class="line"></div><div class="line">Group:		System Environment/Daemons</div><div class="line">License:	GPLv2</div><div class="line">URL:		https://github.com/willcup</div><div class="line">Source0:	redis-3.2.8.tar.gz</div><div class="line"></div><div class="line">Packager:       WillCup &lt;willcup@163.com&gt; </div><div class="line">BuildRequires:	gcc,make</div><div class="line">Requires:	openssl,chkconfig</div><div class="line">BuildRoot:      %_topdir/BUILDROOT</div><div class="line"></div><div class="line"></div><div class="line">%define PortFindDir /usr/local/will_redis</div><div class="line"></div><div class="line">%description</div><div class="line">this is build from will, just for ambari service.</div><div class="line"></div><div class="line">%prep</div><div class="line">%setup -q</div><div class="line"></div><div class="line">%build</div><div class="line">make %&#123;?_smp_mflags&#125;</div><div class="line"></div><div class="line"></div><div class="line">%install</div><div class="line">[ ! -e $RPM_BUILD_ROOT%&#123;PortFindDir&#125; ] &amp;&amp; mkdir -p $RPM_BUILD_ROOT%&#123;PortFindDir&#125;</div><div class="line">cp -rfv * $RPM_BUILD_ROOT%&#123;PortFindDir&#125;</div><div class="line">[ ! -e $RPM_BUILD_ROOT/etc/init.d ] &amp;&amp; mkdir -p $RPM_BUILD_ROOT/etc/init.d</div><div class="line">[ ! -e $RPM_BUILD_ROOT/usr/local/bin ] &amp;&amp; mkdir -p $RPM_BUILD_ROOT/usr/local/bin</div><div class="line">cp -vf $RPM_BUILD_ROOT%&#123;PortFindDir&#125;/utils/redis_init_script $RPM_BUILD_ROOT/etc/init.d/redis</div><div class="line">cp -vf $RPM_BUILD_ROOT%&#123;PortFindDir&#125;/src/redis-server $RPM_BUILD_ROOT/usr/local/bin</div><div class="line">cp -vf $RPM_BUILD_ROOT%&#123;PortFindDir&#125;/src/redis-cli $RPM_BUILD_ROOT/usr/local/bin</div><div class="line">#mkdir -p &quot;$RPM_BUILD_ROOT&quot;</div><div class="line">#cp -rvf * &quot;$RPM_BUILD_ROOT&quot;</div><div class="line">#ls -l &quot;$RPM_BUILD_ROOT&quot;</div><div class="line">echo &quot;no reason to install redis, just move it&quot;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">%files</div><div class="line">%defattr (-,root,root,0755)</div><div class="line">%dir %&#123;PortFindDir&#125;</div><div class="line">%attr(0755, root, root) %&#123;PortFindDir&#125;/*</div><div class="line">%attr(0755, root, root)	/etc/init.d/redis</div><div class="line">%attr(0755, root, root) /usr/local/bin</div><div class="line">%doc</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">%postun	</div><div class="line">rm -fr %(PortFindDir&#125;</div><div class="line">rm -vf /usr/local/bin/redis-*</div><div class="line">rm -vf /etc/init.d/redis</div><div class="line"></div><div class="line">%changelog</div><div class="line">* Fri Dec 29 2016 willcup &lt;willcup@163.com&gt; - 3.2.8-1 </div><div class="line">- Initial version just changelog</div></pre></td></tr></table></figure></p>
<p>其实上面的buildroot就相当于是后面rpm安装时候的系统根目录。所以一般都需要指定一个子目录。不然是行不通的，会发现弄完以后RPM包里没有任何文件。</p>
<h2 id="开始构建"><a href="#开始构建" class="headerlink" title="开始构建"></a>开始构建</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rpmbuild -ba redis.spec</div></pre></td></tr></table></figure>
<p>可以看到已经有了结果</p>
<p>这个是构建过程中的源码目录：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">[will@datanode08 rpmbuild]$ ll BUILD/redis-3.2.8/</div><div class="line">total 204</div><div class="line">-rw-r--r--.  1 will will 85775 Feb 12 23:14 00-RELEASENOTES</div><div class="line">-rw-r--r--.  1 will will    53 Feb 12 23:14 BUGS</div><div class="line">-rw-r--r--.  1 will will  1805 Feb 12 23:14 CONTRIBUTING</div><div class="line">-rw-r--r--.  1 will will  1487 Feb 12 23:14 COPYING</div><div class="line">-rw-r--r--.  1 will will     0 Apr 27 12:25 debugfiles.list</div><div class="line">-rw-r--r--.  1 will will     0 Apr 27 12:25 debuglinks.list</div><div class="line">-rw-r--r--.  1 will will     0 Apr 27 12:25 debugsources.list</div><div class="line">drwxr-xr-x.  7 will will  4096 Apr 27 12:25 deps</div><div class="line">-rw-r--r--.  1 will will    11 Feb 12 23:14 INSTALL</div><div class="line">-rw-r--r--.  1 will will   151 Feb 12 23:14 Makefile</div><div class="line">-rw-r--r--.  1 will will  4223 Feb 12 23:14 MANIFESTO</div><div class="line">-rw-r--r--.  1 will will  6834 Feb 12 23:14 README.md</div><div class="line">-rw-r--r--.  1 will will 46695 Feb 12 23:14 redis.conf</div><div class="line">-rwxr-xr-x.  1 will will   271 Feb 12 23:14 runtest</div><div class="line">-rwxr-xr-x.  1 will will   280 Feb 12 23:14 runtest-cluster</div><div class="line">-rwxr-xr-x.  1 will will   281 Feb 12 23:14 runtest-sentinel</div><div class="line">-rw-r--r--.  1 will will  7606 Feb 12 23:14 sentinel.conf</div><div class="line">drwxr-xr-x.  2 will will  4096 Apr 27 12:25 src</div><div class="line">drwxr-xr-x. 10 will will  4096 Feb 12 23:14 tests</div><div class="line">drwxr-xr-x.  7 will will  4096 Feb 12 23:14 utils</div></pre></td></tr></table></figure></p>
<p>打包完成后rpm包存放的路径：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[will@datanode08 rpmbuild]$ ll RPMS/x86_64/</div><div class="line">total 8</div><div class="line">-rw-rw-r--. 1 will will 1752 Apr 27 12:25 redis-3.2.8-1.el6.x86_64.rpm</div><div class="line">-rw-rw-r--. 1 will will 1880 Apr 27 12:25 redis-debuginfo-3.2.8-1.el6.x86_64.rpm</div></pre></td></tr></table></figure></p>
<p>源码rpm包放置的路径<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[will@datanode08 rpmbuild]$ ll SRPMS/</div><div class="line">total 1516</div><div class="line">-rw-rw-r--. 1 will will 1549338 Apr 27 12:25 redis-3.2.8-1.el6.src.rpm</div></pre></td></tr></table></figure></p>
<p>然而查看rpm包的文件，竟然什么都没有。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[will@datanode08 rpmbuild]$ rpm -qlp RPMS/x86_64/redis-3.2.8-1.el6.x86_64.rpm </div><div class="line">(contains no files)</div></pre></td></tr></table></figure></p>
<p>修改之后，能够正常安装与使用了。</p>
<p>使用 rpm -ivh xx.rpm成功测试。</p>
<p>下一步，将RPM发布至我们自有的yum源上。</p>
<p>按照其他的类似hadoop之类，创建一个redis目录，然后把我们的rpm包放上去</p>
<p>目录样子<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">[root@datanode21 2.4.2.0]# ll</div><div class="line">total 2146284</div><div class="line">.....</div><div class="line">drwxr-xr-x  2 ambari-qa users       4096 Apr 25  2016 hadoop</div><div class="line">drwxr-xr-x  2 ambari-qa users       4096 Apr 25  2016 hadooplzo</div><div class="line">drwxr-xr-x  2 ambari-qa users       4096 Apr 25  2016 hbase</div><div class="line">.......</div><div class="line">drwxr-xr-x  2 ambari-qa users       4096 Apr 25  2016 oozie</div><div class="line">drwxr-xr-x  2 ambari-qa users       4096 Apr 25  2016 phoenix</div><div class="line">drwxr-xr-x  2 ambari-qa users       4096 Apr 25  2016 pig</div><div class="line">drwxr-xr-x  2 ambari-qa users       4096 Apr 25  2016 ranger</div><div class="line">drwxr-xr-x  2 root      root        4096 Apr 27 16:45 redis</div><div class="line">You have new mail in /var/spool/mail/root</div><div class="line">[root@datanode21 2.4.2.0]# pwd</div><div class="line">/server/www/html/hdp/HDP/centos6/2.x/updates/2.4.2.0</div></pre></td></tr></table></figure></p>
<p>先看下我们的HDP.repo<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[HDP-2.4]</div><div class="line">name=HDP-2.4</div><div class="line">baseurl=http://10.2.19.110/hdp/HDP/centos6/2.x/updates/2.4.2.0</div><div class="line"></div><div class="line">path=/</div><div class="line">enabled=1</div><div class="line">gpgcheck=0</div></pre></td></tr></table></figure></p>
<p>可以看到是同一个目录，我们需要在这个目录下重新执行<code>createrepo</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">[root@datanode21 2.4.2.0]# createrepo .</div><div class="line">Spawning worker 0 with 182 pkgs</div><div class="line">Workers Finished</div><div class="line">Gathering worker results</div><div class="line"></div><div class="line">Saving Primary metadata</div><div class="line">Saving file lists metadata</div><div class="line">Saving other metadata</div><div class="line">Generating sqlite DBs</div><div class="line">Sqlite DBs complete</div><div class="line">[root@datanode21 2.4.2.0]# ll repodata</div><div class="line">total 856</div><div class="line">-rw-r--r-- 1 root root 373992 Apr 27 17:59 458b198ae4b61c02b0f7bb03ae9421365dcb2076ffb6087e6808e7915ec31778-filelists.sqlite.bz2</div><div class="line">-rw-r--r-- 1 root root   9092 Apr 27 17:59 9a59871d45121b0be43f188ae7ffe788e2eceb07d03648717323dedd26faf567-other.xml.gz</div><div class="line">-rw-r--r-- 1 root root  12162 Apr 27 17:59 bb3c2dc4c1f7ae17b172f104e3df5171d0d09db797a5f5a9227ab4ae424a45b7-other.sqlite.bz2</div><div class="line">-rw-r--r-- 1 root root  37245 Apr 27 17:59 c23cec21ae4b3e9b89a029b593362ca1e2483316e1d07843a9035ad8e3c93053-primary.xml.gz</div><div class="line">-rw-r--r-- 1 root root 363468 Apr 27 17:59 c521ec682137ff19e61f7ec91e86c725d6d6fa7553be01c783a67ffb68b30afe-filelists.xml.gz</div><div class="line">-rw-r--r-- 1 root root  65483 Apr 27 17:59 eb98320b3ad040203135b91f26caee107900f2e9bdc86a4be6c5218fcc505036-primary.sqlite.bz2</div><div class="line">-rw-r--r-- 1 root root   2996 Apr 27 17:59 repomd.xml</div></pre></td></tr></table></figure></p>
<p>然后更新客户机上，也就是要安装redis 的机器上的repo信息。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">yum clean all</div><div class="line">yum update</div><div class="line">yum search redis</div></pre></td></tr></table></figure></p>
<p>能够搜到，至此结束。</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>我们要构建redis，主要是为了适应既有ambari的redis service，它执行安装的命令是<code>yum install redis.3.2.8</code>。当然我们是可以修改一下他的install代码的，但是考虑到以后其他组件很有可能还是通过yum安装，那还是现在就把自己动手构建yum的rpm包这个问题解决了吧，以绝后患。</p>
<p>问题来了，上面我们搜到的只是<code>redis.x86_64</code>,实际安装的时候请求的是3.2.8，需要版本号加进去才行。看到spec里有version关键字。。。折腾了好半天，都不是，构建出来search的时候都还是只有redis。</p>
<p>后来参考既有的hadoop、flume等yum源，成功搞定。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">flume_2_4_2_0_258-1.5.2.2.4.2.0-258.el6.noarch.rpm	25-Apr-2016 19:54	40M	 </div><div class="line">	</div><div class="line">flume_2_4_2_0_258-agent-1.5.2.2.4.2.0-258.el6.noarch.rpm	25-Apr-2016 19:54	6.4K</div></pre></td></tr></table></figure></p>
<p>发现这个版本号貌似是跟着文件夹的。</p>
<p>所以，修改如下:</p>
<ul>
<li>修改redis.spec为redis-3.2.8.spec</li>
<li>编辑spec文件<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Name:           redis-3.2.8</div><div class="line">Version:        1_0_0</div><div class="line"></div><div class="line">URL:            https://github.com/willcup</div><div class="line">Source0:        redis-3.2.8.tar.gz</div></pre></td></tr></table></figure>
</li>
</ul>
<p>关键在于Name，后面都是喽啰</p>
<ul>
<li>这样解压后会去redis-3.2.8-1_0_0，也就是根据name和version生成的规则，所以可能要调整一下tar.gz里的文件夹名称</li>
<li>重新构建预发布，即可<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">redis-3.2.8-1_0_0-4.el6.x86_64.rpm</div><div class="line"></div><div class="line">yum search redis</div><div class="line">redis.x86_64 : redis from will</div><div class="line">redis-3.2.8.x86_64 : redis 3 2 8 from will</div></pre></td></tr></table></figure>
</li>
</ul>
<p>参考：</p>
<ul>
<li><a href="https://docs.fedoraproject.org/en-US/Fedora_Draft_Documentation/0.1/html/Packagers_Guide/chap-Packagers_Guide-Spec_File_Reference-Preamble.html" target="_blank" rel="external">https://docs.fedoraproject.org/en-US/Fedora_Draft_Documentation/0.1/html/Packagers_Guide/chap-Packagers_Guide-Spec_File_Reference-Preamble.html</a></li>
<li><a href="https://fedoraproject.org/wiki/How_to_create_an_RPM_package/zh-cn#.E5.AE.9E.E4.BE.8B" target="_blank" rel="external">https://fedoraproject.org/wiki/How_to_create_an_RPM_package/zh-cn#.E5.AE.9E.E4.BE.8B</a></li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/04/26/TEZ-hadoop上数据处理的新篇章/" title="TEZ-hadoop上数据处理的新篇章" itemprop="url">TEZ-hadoop上数据处理的新篇章</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-04-26T12:15:47.000Z" itemprop="datePublished"> 发表于 2017-04-26</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="TEZ"><a href="#TEZ" class="headerlink" title="TEZ"></a>TEZ</h2><p>生成一个复杂的DAG task图</p>
<p>目前基本所有的hadoop任务都是MapReduce程序，面向批数据的特性使得它并不能够满足一些特定查询。TEZ是传统MR程序的另一个选择，可以更快地返回结果，而且减少过程中的吞吐。</p>
<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>分布式处理是hadoop的核心。存储与分析各种不同的大量的数据使得hadoop之上产生了很多工具。随着hadoop进入yarn时代，它把MR解耦了出来，这样可以使用其他的数据处理方式来迎接新的不同的挑战。</p>
<h2 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h2><p>hive,pig这些高层次的数据处理工具需要一个引擎来解析他们的语句，然后执行。TEZ就是这样一个引擎。</p>
<h4 id="解析，建模，执行"><a href="#解析，建模，执行" class="headerlink" title="解析，建模，执行"></a>解析，建模，执行</h4><p>TEZ把数据处理看作一个数据流图，节点代表数据处理逻辑，边代表着数据的流向。TEZ有一个很好的数据流相关API,能够让用户清晰表达出自己的复杂查询逻辑，也能够支持hive、pig等高级应用生成的查询计划。</p>
<p>如下图，使用range partitioning进行分布式sort的模型。Preprocessor stage中发送samples给Sampler，计算每个数据分区的range，以保证平均分配。然后这些range再被发送给Partition stage。然后partition stage和aggregate stage就读取分配的stage，执行数据的扫描与后续聚合工作。</p>
<p><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2013/09/tez1-450x257.png" alt=""></p>
<h4 id="灵活的input-processor-output任务模型"><a href="#灵活的input-processor-output任务模型" class="headerlink" title="灵活的input-processor-output任务模型"></a>灵活的input-processor-output任务模型</h4><p>TEZ中对于数据流中每个处理逻辑都是由三部分组成：input, processor, output。input和output决定数据接口。processor则是数据处理逻辑。TEZ只要求在同一个vertex task中这三部分之间是相互兼容的即可。</p>
<p><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2013/09/tez2-450x154.png" alt=""></p>
<h4 id="动态图配置的性能"><a href="#动态图配置的性能" class="headerlink" title="动态图配置的性能"></a>动态图配置的性能</h4><p>分布式数据处理天生就是动态的，所以很难提前知道最优并发和数据走向。更多的信息只能在运行时才获知，比如数据的内容和大小，这其实是可以帮助我们优化执行计划的。我们还注意到TEZ自身并不能总是自己执行这些动态优化。</p>
<p><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2013/09/tez3-450x208.png" alt=""></p>
<ul>
<li><a href="https://hortonworks.com/blog/apache-tez-a-new-chapter-in-hadoop-data-processing/" target="_blank" rel="external">https://hortonworks.com/blog/apache-tez-a-new-chapter-in-hadoop-data-processing/</a></li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/04/26/hiveserver2负载均衡/" title="hiveserver2负载均衡" itemprop="url">hiveserver2负载均衡</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-04-26T08:47:44.000Z" itemprop="datePublished"> 发表于 2017-04-26</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>hiveserver2是通过在zookeeper注册一个namespace，然后管理所有的hiveserver实例，实现动态服务发现的。</p>
<p>znode样式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/&lt;hiveserver2_namespace&gt;/serverUri=&lt;host:port&gt;;version=&lt;versionInfo&gt;; sequence=&lt;sequence_number&gt;,</div></pre></td></tr></table></figure></p>
<p>hiveserver实例会在znode上设置一个watch。当znode被修改的时候，watch会发送给hiveserver相关信息。这个通知能够让所有的hiveserver实例知道它是不是对于client端可用。</p>
<p>当有hiveserver实例退出时，会从zk的对应node里移除，但是只对新的客户端连接生效。(已经连接的session不能生效了)。只有已经连接到这个hiveserver的最后一个client的session结束后，才会自动把这个hiveserver完全关闭，下面这个命令就是做这个工作的。</p>
<p>使用下面命令移除一个hiveserver<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hive --service hiveserver2 --deregister &lt;package ID&gt;</div></pre></td></tr></table></figure></p>
<h4 id="没有zk时的查询"><a href="#没有zk时的查询" class="headerlink" title="没有zk时的查询"></a>没有zk时的查询</h4><p>下面是一个传统的查询流程：</p>
<ul>
<li>通过JDBC/ODBC driver连接到HS2实例，建立一个session</li>
<li>然后每次查询的时候client都发送语句给HS2，转化成Hadoop上的执行任务</li>
<li>每个查询的结果都写道一个临时文件中</li>
<li>客户端driver从HS2抽取临时文件中的数据记录</li>
</ul>
<p><img src="https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.4.0/bk_hadoop-ha/content/figures/2/figures/Query_Ex_Path_No_ZK.png" alt="典型查询流程"></p>
<h4 id="带有zk的查询"><a href="#带有zk的查询" class="headerlink" title="带有zk的查询"></a>带有zk的查询</h4><p>因为可以使用动态服务发现，所以客户端driver必须知道怎样使用这个特性。对于HDP2.2或者JDBC driver2.0.0版本之后才能支持。</p>
<p>动态服务发现实现如下：</p>
<ul>
<li>多个HS2实例使用zk注册自己</li>
<li>客户端driver连接zk<blockquote>
<p> jdbc:hive2://<zookeeper_ensemble>;serviceDiscoveryMode=zooKeeper; zooKeeperNamespace=&lt;hiveserver2_namespace</zookeeper_ensemble></p>
</blockquote>
</li>
<li>zk随机返回一个host:port给客户端</li>
<li>客户端执行单个服务传统查询过程</li>
</ul>
<p><img src="https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.4.0/bk_hadoop-ha/content/figures/2/figures/Query_Ex_Path_With_ZK.png" alt="带有zk的查询过程"></p>
<h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><p>hive.zookeeper.quorum zk列表<br>hive.zookeeper.session.timeout 超时就关闭session<br>hive.server2.support.dynamic.service.discovery  设置为true<br>hive.server2.zookeeper.namespace    指定一个就行了，默认是hiveserver2</p>
<ul>
<li><a href="https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.4.0/bk_hadoop-ha/content/ha-hs2-requests.html" target="_blank" rel="external">https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.4.0/bk_hadoop-ha/content/ha-hs2-requests.html</a></li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/04/26/hue对于多个hiveserver2的支持/" title="hue对于多个hiveserver2的支持" itemprop="url">hue对于多个hiveserver2的支持</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-04-26T08:26:28.000Z" itemprop="datePublished"> 发表于 2017-04-26</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>相关连接代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">hiveserver2_jdbc_url</span><span class="params">()</span>:</span></div><div class="line">  urlbase = <span class="string">'jdbc:hive2://%s:%s/default'</span> % (beeswax.conf.HIVE_SERVER_HOST.get(),</div><div class="line">                                            beeswax.conf.HIVE_SERVER_PORT.get())</div><div class="line">  <span class="keyword">if</span> get_conf().get(_CNF_HIVESERVER2_USE_SSL, <span class="string">'FALSE'</span>).upper() == <span class="string">'TRUE'</span>:</div><div class="line">    <span class="keyword">return</span> <span class="string">'%s;ssl=true;sslTrustStore=%s;trustStorePassword=%s'</span> % (urlbase,</div><div class="line">            get_conf().get(_CNF_HIVESERVER2_TRUSTSTORE_PATH),</div><div class="line">            get_conf().get(_CNF_HIVESERVER2_TRUSTSTORE_PASSWORD))</div><div class="line">  <span class="keyword">else</span>:</div><div class="line">     <span class="keyword">return</span> urlbase</div></pre></td></tr></table></figure></p>
<p>可以看到，除非启用SSL，否则咋样都拼不进去下面这种串：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">jdbc:hive2://zkNode1:<span class="number">2181</span>,zkNode2:<span class="number">2181</span>,zkNode3:<span class="number">2181</span>/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2_zk</div></pre></td></tr></table></figure></p>
<p>Tip:</p>
<p>可以先用tengine配置TCP代理，然后在这里实现负载均衡，hue端只需要配置代理的地址就可以了。 —— 希望hive的driver可以支持，有待测试。</p>
<p>参考：</p>
<ul>
<li><a href="http://lxw1234.com/archives/2016/05/675.htm" target="_blank" rel="external">http://lxw1234.com/archives/2016/05/675.htm</a></li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/04/25/hive中使用向量化查询引擎Vectorized-Query-Execution/" title="hive中使用向量化查询引擎Vectorized-Query-Execution" itemprop="url">hive中使用向量化查询引擎Vectorized-Query-Execution</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-04-25T11:59:52.000Z" itemprop="datePublished"> 发表于 2017-04-25</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>向量化查询引擎可以在执行scan, filter, aggregate, join等操作的时候很大程度上降低CPU损耗。标准sql执行系统每次只处理一行数据，内部执行的时候会包括很长的代码路径和重要的metadata解析。向量化查询引擎简化了这个过程，一次读取1024行数据，在这个数据块中，每个字段都被存储成向量化的结构(一个原是数据类型的数组)。对于一些简单的算法可以通过快速迭代这个vector完成，只需要在循环过程中调用甚至不用调用几个函数。这些loop以一种流式方式编译，在固定时间内结束，为了提高效率，会使用processor pipline和内存缓存。<a href="https://issues.apache.org/jira/browse/HIVE-4160" target="_blank" rel="external">详细设计</a></p>
<p>个人理解：就是每行都执行很小的计算，但是要处理N多次。改成一次处理多行，同时针对多行做计算处理，节省CPU时间。</p>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><h4 id="启用"><a href="#启用" class="headerlink" title="启用"></a>启用</h4><p>要使用向量化查询引擎，必须先把hive表存储成ORC格式的。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">set hive.vectorized.execution.enabled = true;</div></pre></td></tr></table></figure></p>
<p>默认是没有开启向量化查询引擎的，需要手动开启。</p>
<h4 id="支持的数据类型与操作"><a href="#支持的数据类型与操作" class="headerlink" title="支持的数据类型与操作"></a>支持的数据类型与操作</h4><ul>
<li>tinyint</li>
<li>smallint</li>
<li>int</li>
<li>bigint</li>
<li>boolean</li>
<li>float</li>
<li>double</li>
<li>decimal</li>
<li>date</li>
<li>timestamp (see Limitations below)</li>
<li>string<br>其他的数据类型还是会按照传统方式一行行处理。</li>
</ul>
<p>支持的表达式：</p>
<ul>
<li>简单算法: +, -, *, /, %</li>
<li>AND, OR, NOT</li>
<li>比较 &lt;, &gt;, &lt;=, &gt;=, =, !=, BETWEEN, IN ( list-of-constants ) as filters</li>
<li>布尔表达式 (non-filters) using AND, OR, NOT, &lt;, &gt;, &lt;=, &gt;=, =, !=</li>
<li>IS [NOT] NULL</li>
<li>所有的匹配函数 (SIN, LOG, etc.)</li>
<li>string相关函数 SUBSTR, CONCAT, TRIM, LTRIM, RTRIM, LOWER, UPPER, LENGTH</li>
<li>类型转换</li>
<li>UDF</li>
<li>日期函数 (YEAR, MONTH, DAY, HOUR, MINUTE, SECOND, UNIX_TIMESTAMP)</li>
<li>IF 条件表达式</li>
</ul>
<p>UDF通过向后兼容的方式支持，不过执行的时候就是执行向量化查询引擎，但是没有内置的快。向量化的filter操作是从左到右执行，所以最好把UDF放在带有and的where语句的最后：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">where column1 = 10 and myUDF(column2) = "x"</div></pre></td></tr></table></figure></p>
<h2 id="限制"><a href="#限制" class="headerlink" title="限制"></a>限制</h2><p>Timestamps 只能是 1677-09-20 到2262-04-11. </p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/04/21/集群service配置相关/" title="集群service配置相关" itemprop="url">集群service配置相关</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-04-21T08:41:02.000Z" itemprop="datePublished"> 发表于 2017-04-21</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h2><table>
<thead>
<tr>
<th>服务名称</th>
<th>现有配置</th>
<th>TO </th>
</tr>
</thead>
<tbody>
<tr>
<td>resourcemanager</td>
<td>1G</td>
<td>4G</td>
</tr>
<tr>
<td>nodemanager</td>
<td>1G</td>
<td>2G</td>
</tr>
<tr>
<td>timeline server</td>
<td>1G</td>
<td>4G</td>
</tr>
</tbody>
</table>
<p>resource + timline server = 2G</p>
<h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS "></a>HDFS </h2><table>
<thead>
<tr>
<th>服务名称</th>
<th>现有配置</th>
<th>TO</th>
</tr>
</thead>
<tbody>
<tr>
<td>datanode</td>
<td>1G</td>
<td>2G</td>
</tr>
<tr>
<td>namenode</td>
<td>3G </td>
</tr>
</tbody>
</table>
<p>namenode * 2 =  6G</p>
<h2 id="MAPRED"><a href="#MAPRED" class="headerlink" title="MAPRED"></a>MAPRED</h2><table>
<thead>
<tr>
<th>服务名称</th>
<th>现有配置</th>
<th>TO</th>
</tr>
</thead>
<tbody>
<tr>
<td>history server</td>
<td>1G</td>
<td>2G</td>
</tr>
</tbody>
</table>
<h2 id="HIVE"><a href="#HIVE" class="headerlink" title="HIVE"></a>HIVE</h2><table>
<thead>
<tr>
<th>服务名称</th>
<th>配置</th>
</tr>
</thead>
<tbody>
<tr>
<td>hiveserver2</td>
<td>769M</td>
</tr>
<tr>
<td>metastore</td>
<td>1G</td>
</tr>
<tr>
<td>hcatserver</td>
<td>1G</td>
</tr>
</tbody>
</table>
<p>3G</p>
<h2 id="HBASE"><a href="#HBASE" class="headerlink" title="HBASE"></a>HBASE</h2><table>
<thead>
<tr>
<th>服务名称</th>
<th>配置</th>
</tr>
</thead>
<tbody>
<tr>
<td>regionserver</td>
<td>2G</td>
</tr>
<tr>
<td>master</td>
<td>1G</td>
</tr>
</tbody>
</table>
<p>regionserver <em> 8 + master </em> 2 = 18G</p>
<h2 id="ZK"><a href="#ZK" class="headerlink" title="ZK"></a>ZK</h2><table>
<thead>
<tr>
<th>服务名称</th>
<th>配置</th>
</tr>
</thead>
<tbody>
<tr>
<td>zk server</td>
<td>1G</td>
</tr>
</tbody>
</table>
<p>zk * 3 = 3G</p>
<h2 id="KAFKA"><a href="#KAFKA" class="headerlink" title="KAFKA"></a>KAFKA</h2><table>
<thead>
<tr>
<th>服务名称</th>
<th>配置</th>
</tr>
</thead>
<tbody>
<tr>
<td>broker</td>
<td>1G</td>
</tr>
</tbody>
</table>
<p>broker * 3 =3G</p>
<h2 id="SPAKR"><a href="#SPAKR" class="headerlink" title="SPAKR"></a>SPAKR</h2><table>
<thead>
<tr>
<th>服务名称</th>
<th>配置</th>
</tr>
</thead>
<tbody>
<tr>
<td>spark history server</td>
<td>1G</td>
</tr>
</tbody>
</table>
<h2 id="需要copy的机器"><a href="#需要copy的机器" class="headerlink" title="需要copy的机器"></a>需要copy的机器</h2><p>以下机器copy完成后，全部将内存提升至32G、CPU提升到8核</p>
<h5 id="迁出机器"><a href="#迁出机器" class="headerlink" title="迁出机器"></a>迁出机器</h5><ul>
<li>datanode15.will.com     -&gt; NM，DN</li>
<li>1.103-prd-datanode14.will.com   -&gt;kafka, DN,NM</li>
<li>1.108-prd-datanode19.will.com -&gt; regionserver, DN,NM</li>
<li>1.110-prd-datanode21.will.com -&gt; NM, DN</li>
<li>1.99-prd-datanode10.will.com -&gt; kafka, DB, NM</li>
<li>1.113-fengkong.data.com 风控 -&gt; NONE</li>
<li>1.87-prd-datanode05.data.com -&gt; DN, NM, regionserver</li>
<li>1.97-prd-datanode08.data.com -&gt; DN, NM, regionserver</li>
<li>1.95-prd-datanode06.data.com -&gt; kafka, DN, NM, SB HbaseMaster</li>
<li>1.96-prd-datanode07.data.com -&gt; DN, NM, regionserver</li>
</ul>
<p>原有机器迁出会占新资源的内存32G <em> 10 + CPU</em>80</p>
<h5 id="原有机器资源升级"><a href="#原有机器资源升级" class="headerlink" title="原有机器资源升级"></a>原有机器资源升级</h5><p>在原有资源基础上，添加16G内存，CPU核数翻倍【把迁移出去的机器空闲出来的资源充分利用】：</p>
<ul>
<li>1.107-prd-datanode18.will.com</li>
<li>1.109-prd-datanode20.will.com</li>
<li>1.102-prd-datanode13.will.com</li>
<li>1.106-prd-datanode17.will.com</li>
<li>1.100-prd-datanode11.will.com</li>
<li>1.98-prd-datanode09.will.com</li>
<li>1.110-prd-datanode21.will.com</li>
<li>1.86-prd-datanode04.data.com</li>
<li>1.82-prd-datanode01.data.com</li>
<li>1.83-prd-datanode02.data.com</li>
<li>1.84-prd-datanode03.data.com</li>
<li>1.105-prd-datanode16.will.com</li>
<li>1.101-prd-datanode12.will.com</li>
</ul>
<p>理论上，对原有机器不会有额外资源要求，对新机器资源也不会有影响。</p>
<h2 id="需要新建的机器"><a href="#需要新建的机器" class="headerlink" title="需要新建的机器"></a>需要新建的机器</h2><h4 id="新服务节点"><a href="#新服务节点" class="headerlink" title="新服务节点"></a>新服务节点</h4><p>可按照service01.will.com开始弄主机名。</p>
<p>单机配置： 32G内存 + 8核 + 50G硬【整机空间即可】 + CentOS release 6.8 (Final)</p>
<p>机器数量： 8台<br>共占：内存32G <em> 8 + CPU8 </em> 8 = 内存256G + CPU 64</p>
<h4 id="新数据节点"><a href="#新数据节点" class="headerlink" title="新数据节点"></a>新数据节点</h4><p>目前最新数据节点的主机名编号到了21，新机器可以datanode22.will.com开始。</p>
<p>单机配置：32G内存 + 8核CPU + 640G硬盘【/server/目录挂载空间】 + CentOS release 6.8 (Final)</p>
<p>机器数量： 12【如果物理机资源不够，可以暂时弄10台，以后酌情扩容】</p>
<p>共占：内存32G <em> 12 + CPU8 </em> 12 = 内存384G + CPU 96</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






  <nav id="page-nav" class="clearfix">
    <a class="extend prev" rel="prev" href="/page/10/"><span></span>Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><a class="page-number" href="/page/10/">10</a><span class="page-number current">11</span><a class="page-number" href="/page/12/">12</a><a class="page-number" href="/page/13/">13</a><span class="space">&hellip;</span><a class="page-number" href="/page/25/">25</a><a class="extend next" rel="next" href="/page/12/">Next<span></span></a>
  </nav>

</div>
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  


  

  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/youdaonote/" title="youdaonote">youdaonote<sup>187</sup></a></li>
			
		
			
				<li><a href="/tags/源码/" title="源码">源码<sup>10</sup></a></li>
			
		
			
				<li><a href="/tags/akka/" title="akka">akka<sup>9</sup></a></li>
			
		
			
				<li><a href="/tags/flume/" title="flume">flume<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/ETL/" title="ETL">ETL<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/solr/" title="solr">solr<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/spring/" title="spring">spring<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/调度平台/" title="调度平台">调度平台<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/azkaban/" title="azkaban">azkaban<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/mysql/" title="mysql">mysql<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/scala/" title="scala">scala<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/ambari/" title="ambari">ambari<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/quartz/" title="quartz">quartz<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/django/" title="django">django<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/架构/" title="架构">架构<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/架构，jaeger/" title="架构，jaeger">架构，jaeger<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/ember/" title="ember">ember<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/nodejs/" title="nodejs">nodejs<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/R/" title="R">R<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/guava/" title="guava">guava<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="https://github.com/willcup" target="_blank" title=" 我自己的github">github</a>
            
          </li>
        
          <li>
            
            	<a href="http://thisding.com" target="_blank" title="朋友的主页">Steven&#39;s Blog</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

  <div class="weiboshow">
  <p class="asidetitle">新浪微博</p>
    <iframe width="100%" height="119" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=null&verifier=&dpc=1"></iframe>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m Will Chen in MeiTuan. <br/>
			元 亨 利 贞.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
		<a href="mailto:chenxin15@meituan.com" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2018 
		
		<a href="/about" target="_blank" title="Will Chen">Will Chen</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>










<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3Fe6d1f421bbc9962127a50488f9ed37d1' type='text/javascript'%3E%3C/script%3E"));
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
 </html>
