
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <script type="text/javascript">
    (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
    })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');
    
    _st('install','yNiKTKaAnwd1uuxVMfiE','2.0.0');
  </script>
  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?5b99dfd487346155d274c0c49c3fb869";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
  </script>

  
    <title>Will&#39;s Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Will Chen">
    

    
    <meta name="description" content="左右水色 右手天光">
<meta property="og:type" content="website">
<meta property="og:title" content="Will's Blog">
<meta property="og:url" content="https://runningdata.github.io/page/6/index.html">
<meta property="og:site_name" content="Will's Blog">
<meta property="og:description" content="左右水色 右手天光">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Will's Blog">
<meta name="twitter:description" content="左右水色 右手天光">

    
    <link rel="alternative" href="/atom.xml" title="Will&#39;s Blog" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="Will&#39;s Blog" title="Will&#39;s Blog"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Will&#39;s Blog">Will&#39;s Blog</a></h1>
				<h2 class="blog-motto">简易 变易 不易</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">首页</a></li>
					
						<li><a href="/archives">归档</a></li>
					
						<li><a href="/about">关于</a></li>
					
					<li>
 					
                                                <form class="search" action="/search/index.html" method="get" accept-charset="utf-8" target="_blank">
                                                        <label>搜索</label>
                                                <input name="s" type="hidden" value= null ><input type="text" class="st-default-search-input" name="q" size="30" placeholder="搜索"><br>
                                                </form>
					
					</li>
				</ul>
			</nav>			
</div>

    </header>
    <div id="container">
      <div id="main">

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/10/26/对于spark-streaming通过runningdata运行的简单规划/" title="对于spark-streaming通过runningdata运行的简单规划" itemprop="url">对于spark-streaming通过runningdata运行的简单规划</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-10-26T10:41:07.000Z" itemprop="datePublished"> 发表于 2017-10-26</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h4 id="提交流程"><a href="#提交流程" class="headerlink" title="提交流程"></a>提交流程</h4><ol>
<li>添加spark jar</li>
<li>添加参数</li>
<li>配置调度</li>
</ol>
<h4 id="后台流程"><a href="#后台流程" class="headerlink" title="后台流程"></a>后台流程</h4><ol>
<li>扫描updatetime，检测新更新的spark streaming程序</li>
<li>检查jar包修改，将修改后的jar包重新上传到HDFS/mesos集群公共访问部分</li>
<li>创建/修改marathon app配置</li>
<li>重启/启动marathon app</li>
</ol>
<h4 id="日志检查"><a href="#日志检查" class="headerlink" title="日志检查"></a>日志检查</h4><p>这方面其实marathon已经做得很好了。可以直接拼接marathon的日志API搞定。</p>
<p>marathon api<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://10.2.19.125:5051/files/download?path=/server/mesos/agent/slaves/5fc969e7-c2da-4435-a0cb-278240c52f25-S2/frameworks/d2f4a97d-de35-4d1b-bf6d-07b8f2ad7666-0000/executors/willsparkstreamingtest01.cfcd8dde-ba34-11e7-9beb-3e15ac098cb2/runs/1128e325-ad92-4266-8348-04f43cfaa4c4/stderr</div></pre></td></tr></table></figure></p>
<p>mesos api<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://10.2.19.124:5050/#/agents/5fc969e7-c2da-4435-a0cb-278240c52f25-S2/browse?path=/server/mesos/agent/slaves/5fc969e7-c2da-4435-a0cb-278240c52f25-S2/frameworks/d2f4a97d-de35-4d1b-bf6d-07b8f2ad7666-0000/executors/willsparkstreamingtest01.cfcd8dde-ba34-11e7-9beb-3e15ac098cb2/runs/latest</div></pre></td></tr></table></figure></p>
<p>mesos 增量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://10.2.19.125:5051/files/read?path=/server/mesos/agent/slaves/5fc969e7-c2da-4435-a0cb-278240c52f25-S2/frameworks/d2f4a97d-de35-4d1b-bf6d-07b8f2ad7666-0000/executors/willsparkstreamingtest01.cfcd8dde-ba34-11e7-9beb-3e15ac098cb2/runs/latest/stdout&amp;offset=115771&amp;length=50000&amp;jsonp=jQuery17109253805122640539_1509014182353&amp;_=1509014197811</div></pre></td></tr></table></figure>
<p>mesos 下载<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://10.2.19.125:5051/files/download?path=/server/mesos/agent/slaves/5fc969e7-c2da-4435-a0cb-278240c52f25-S2/frameworks/d2f4a97d-de35-4d1b-bf6d-07b8f2ad7666-0000/executors/willsparkstreamingtest01.cfcd8dde-ba34-11e7-9beb-3e15ac098cb2/runs/latest/stdout</div></pre></td></tr></table></figure></p>
<p>因为有增量，所以我们会优先考虑过滤改造mesos的API。</p>
<p>对于上面所有的路径信息，<br>主要就是framework的id，mesos salve的id，task的id。</p>
<p>slaveid, taskid可以通过marathon的task接口获取到。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">curl http://10.2.19.124:8080/v2/apps/willsparkstreamingtest01</div></pre></td></tr></table></figure></p>
<p>framework的ID可以去<a href="http://mesos.apache.org/documentation/latest/endpoints/master/frameworks/" target="_blank" rel="external">mesos的api</a>里找到。其实后面这个就包含了上面的所有信息了。</p>
<p>另外，考虑到可能出现程序错误，导致app在marathon上不停部署，那么此时我们是需要获取前面失败的log的。失败log其实也是一次部署的log，所以路径上没有什么区别，但是可能taskid会有所变化，仔细观察上面的数据里其实是有lastTaskFailure的信息的，可以找到上个失败task的id，进而找到失败的log。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/10/26/ambari添加异构OS/" title="ambari添加异构OS" itemprop="url">ambari添加异构OS</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-10-26T07:35:13.000Z" itemprop="datePublished"> 发表于 2017-10-26</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>首先声明，HDFS集群中肯定是最好不要有异构机器存在的，会造成很多兼容性问题。</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><table>
<thead>
<tr>
<th>系统</th>
<th>作用</th>
<th>数量</th>
</tr>
</thead>
<tbody>
<tr>
<td>centos6</td>
<td>yarn/HDFS等服务的选定集群，主要用来运行日常任务</td>
<td>50</td>
</tr>
<tr>
<td>centos7</td>
<td>marathon/docker所在的小集群，预想用来调度任务</td>
<td>5</td>
</tr>
</tbody>
</table>
<p>其实我们已经基于centos6.8 final有了一个比较稳定的集群，上面通过ambari安装并稳健运行着HDFS、MR、Yarn、Spark、HBase等大数据服务。但是我们想要将spark streaming、hive等ETL工作的客户端放置在mesos上运行，因为当这些工作比较多的时候，也同样需要资源管理工作。鉴于mesos的资源管理相对yarn来说更加可定制化、而且已经有很多开源且稳定的framework可用，我们就选用mesos来做这个客户端集群的工作。对于long time的spark streaming，我们期望使用marathon来管理。一段时间的hive ETL任务，可以使用docker或者chronos来执行。</p>
<p>鉴于以上计划，我们需要在mesos的agent机器上安装spark、hive等客户端配置文件。考虑到易操作性和软件的版本统一兼容问题，决定继续使用ambari在mesos agent上安装这些软件的client端，然后就可以直接调用了。</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>在添加新host的过程中，ambari会比较智能的告诉我们，新的OS与既有的集群OS可能存在不兼容的问题，并阻止我们进一步执行。</p>
<h2 id="处理"><a href="#处理" class="headerlink" title="处理"></a>处理</h2><p>考虑到我们只是使用客户端，而且我们的程序客户端是基于java的，具有可移植性。所以我就去找到ambari-server在新增机器的时候，对于OS的检测脚本，暂时注释掉，添加完新的host之后，再放开。</p>
<p>2.2.2.0的脚本位置:<code>/usr/lib/python2.6/site-packages/ambari_server/bootstrap.py</code>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">def run(self):</div><div class="line">    &quot;&quot;&quot; Copy files and run commands on remote host &quot;&quot;&quot;</div><div class="line">    self.status[&quot;start_time&quot;] = time.time()</div><div class="line">    # Population of action queue</div><div class="line">    action_queue = [self.createTargetDir,</div><div class="line">                    self.copyCommonFunctions,</div><div class="line">                    self.copyOsCheckScript,</div><div class="line">                    self.runOsCheckScript,</div><div class="line">                    self.checkSudoPackage</div><div class="line">    ]</div><div class="line">    if self.hasPassword():</div><div class="line">      action_queue.extend([self.copyPasswordFile,</div><div class="line">                           self.changePasswordFileModeOnHost])</div><div class="line">    action_queue.extend([</div><div class="line">      self.copyNeededFiles,</div><div class="line">      self.runSetupAgent,</div><div class="line">    ])</div><div class="line">    ....</div></pre></td></tr></table></figure></p>
<p>把action_queue里的OSCheck相关的暂时注释掉就可以了。然后去添加host的界面上点击retry failed。只要注册成功就可以了。</p>
<p>install过程跳过去了，但是注册的时候出现了问题。</p>
<p>报错：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">INFO 2017-10-26 16:14:42,747 NetUtil.py:60 - Connecting to https://namenode01.will.com:8440/ca</div><div class="line">ERROR 2017-10-26 16:14:42,848 NetUtil.py:84 - [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:579)</div><div class="line">ERROR 2017-10-26 16:14:42,848 NetUtil.py:85 - SSLError: Failed to connect. Please check openssl library versions. </div><div class="line">Refer to: https://bugzilla.redhat.com/show_bug.cgi?id=1022468 for more details.</div><div class="line">WARNING 2017-10-26 16:14:42,850 NetUtil.py:112 - Server at https://namenode01.will.com:8440 is not reachable, sleeping for 10 seconds...</div><div class="line">&apos;, None)</div></pre></td></tr></table></figure></p>
<p>在新的host上找到ambari-agent相关代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">def checkURL(self, url):</div><div class="line">  &quot;&quot;&quot;Try to connect to a given url. Result is True if url returns HTTP code 200, in any other case</div><div class="line">  (like unreachable server or wrong HTTP code) result will be False.</div><div class="line"></div><div class="line">     Additionally returns body of request, if available</div><div class="line">  &quot;&quot;&quot;</div><div class="line">  logger.info(&quot;Connecting to &quot; + url)</div><div class="line">  responseBody = &quot;&quot;</div><div class="line"></div><div class="line">  try:</div><div class="line">    parsedurl = urlparse(url)</div><div class="line"></div><div class="line">    if sys.version_info &gt;= (2,7,9):</div><div class="line">        import ssl</div><div class="line">        ca_connection = httplib.HTTPSConnection(parsedurl[1], context=ssl._create_unverified_context())</div><div class="line">    else:</div><div class="line">        ca_connection = httplib.HTTPSConnection(parsedurl[1])</div><div class="line">    ...</div><div class="line">  except SSLError as slerror:</div><div class="line">    logger.error(str(slerror))</div><div class="line">    logger.error(ERROR_SSL_WRONG_VERSION)</div><div class="line">    return False, responseBody</div><div class="line"></div><div class="line">  except Exception, e:</div><div class="line">    logger.warning(&quot;Failed to connect to &quot; + str(url) + &quot; due to &quot; + str(e) + &quot;  &quot;)</div><div class="line">    return False, responseBody</div></pre></td></tr></table></figure></p>
<p>从报错来看，是出现了SSLError，好像是SSL的兼容问题。对比看一下ssl的版本：</p>
<ul>
<li>centos7 openssl-1.0.2k-8.el7.x86_64</li>
<li>centos6 openssl-1.0.1e-57.el6.x86_64</li>
</ul>
<p>考虑到既有集群的稳定性，失败告终。配置同步问题转由rsync、nfs之类的方案解决吧。</p>
<p>参考：</p>
<ul>
<li><a href="https://community.hortonworks.com/questions/4324/hdp-support-for-mix-of-os-releases-within-a-cluste.html" target="_blank" rel="external">https://community.hortonworks.com/questions/4324/hdp-support-for-mix-of-os-releases-within-a-cluste.html</a></li>
<li><a href="https://community.hortonworks.com/questions/18479/how-to-register-host-with-different-os-to-ambari.html" target="_blank" rel="external">https://community.hortonworks.com/questions/18479/how-to-register-host-with-different-os-to-ambari.html</a></li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/10/25/主从备份问题/" title="主从备份问题" itemprop="url">主从备份问题</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-10-25T02:57:57.000Z" itemprop="datePublished"> 发表于 2017-10-25</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>昨天同事聊起mysql的主从备份问题。我们都知道mysql的主从同步是通过binlog实现的，抛开已经成行的主从不说，如果要新增从库的话，那么具体是精准的copy数据库镜像，然后记录binlog位置的呢？如果说copy镜像的话，那么一定要停库或者锁表了，如果是copy主库的话，那势必会影响线上业务了。</p>
<p>参考了一些资料，自己脑袋也跟着转了一下，总结出以下几种情况。</p>
<ol>
<li>当前已经有了健壮的主从结构/或者是健壮的双热备，只需要新增一个从库。</li>
</ol>
<ul>
<li>将从库暂时停掉</li>
<li>进行这个mysql的所有数据的拷贝</li>
<li>在目标新从库修改server-id</li>
<li>启动新老从库</li>
<li>验证确认</li>
</ul>
<ol>
<li>当前只有主库，前面并没有配置从库，但是已经有了binlog。</li>
</ol>
<ul>
<li>最稳妥的：停掉，copy，配置，重启。</li>
<li>使用mysqldump，这种最不推荐，因为会锁表，那么对于线上应用来说一样是会收到影响。反正都会影响线上，还不如停掉更为稳妥</li>
<li>使用xtrabackup进行备份，不锁表，不影响线上业务。具体参考<a href="http://sofar.blog.51cto.com/353572/1313649" target="_blank" rel="external">xtrabackup原理及实施</a>。大概流程如下图：<br><img src="C:\Users\will\Pictures\xtrabakcup.png" alt=""><br>具体来说，首先在logfile中找到并记录最后一个checkpoint（“last checkpoint LSN”），然后开始从LSN的位置开始拷贝InnoDB的logfile到xtrabackup_logfile；然后开始拷贝全部的数据文件.ibd；在拷贝全部数据文件结束之后，才停止拷贝logfile。<br>因为<strong>logfile里面记录全部的数据修改情况</strong>，所以即使在备份过程中数据文件被修改过了，恢复时仍然能够通过解析xtrabackup_logfile保持数据的一致。</li>
</ul>
<p>参考：</p>
<ul>
<li><a href="http://sofar.blog.51cto.com/353572/1313649" target="_blank" rel="external">http://sofar.blog.51cto.com/353572/1313649</a></li>
<li><a href="http://database.51cto.com/art/201507/483499.htm" target="_blank" rel="external">http://database.51cto.com/art/201507/483499.htm</a></li>
<li><a href="http://lizhenliang.blog.51cto.com/7876557/1612800" target="_blank" rel="external">http://lizhenliang.blog.51cto.com/7876557/1612800</a></li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/10/16/一次查询hang事件/" title="一次查询hang事件" itemprop="url">一次查询hang事件</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-10-16T07:56:14.000Z" itemprop="datePublished"> 发表于 2017-10-16</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><p>同事在navicat上为table A修改了了一个字段长度，然后navicati卡死了。重启后这个表就不能查询了。</p>
<h2 id="排查"><a href="#排查" class="headerlink" title="排查"></a>排查</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">show processlist</div></pre></td></tr></table></figure>
<p>查看慢查询发现有status为Waiting for table metadata lock的查询出现。</p>
<p>查看运行中的事务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from information_schema.innodb_trx</div></pre></td></tr></table></figure></p>
<p>根据trx_started找到运行时间最长的kill掉慢查询对应的trx_mysql_thread_id，之后就恢复了。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/10/10/Chronos/" title="Chronos" itemprop="url">Chronos</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-10-10T09:32:56.000Z" itemprop="datePublished"> 发表于 2017-10-10</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>Chronos 内部很简单：</p>
<ul>
<li>从zk的state store中读取所有job的state</li>
<li>job都在scheduler里注册过了，会别加载进job graph，以追踪依赖关系</li>
<li>根据host时间，job被分成不同的list中，有些现在就要跑，有些不用</li>
<li>需要跑的job会被放进队列，只要有充足的资源就马上运行</li>
<li>等再有job需要run的时候，就重复1</li>
</ul>
<p>一个job只有在它的所有parent都运行完成过才能运行。它跑完之后，这个轮次就结束了。</p>
<p>这段代码在mainLoop()方法中。<a href="https://github.com/mesos/chronos/blob/be96c4540b331b08d9742442e82c4516b4eaee85/src/main/scala/org/apache/mesos/chronos/scheduler/jobs/JobScheduler.scala#L469-L498" target="_blank" rel="external">https://github.com/mesos/chronos/blob/be96c4540b331b08d9742442e82c4516b4eaee85/src/main/scala/org/apache/mesos/chronos/scheduler/jobs/JobScheduler.scala#L469-L498</a></p>
<p>其他特性</p>
<ul>
<li>向cassandra写入job metrics，用来分析、估计等</li>
<li>发送不同的通知：email、slack等</li>
<li>导出metric到graphite或其他地方</li>
</ul>
<p>不能做的</p>
<ul>
<li>解决所有分布式问题</li>
<li>保证精准调度</li>
<li>保证时间同步</li>
<li>保证job真正运行了</li>
</ul>
<h2 id="实例架构"><a href="#实例架构" class="headerlink" title="实例架构"></a>实例架构</h2><p><img src="https://mesos.github.io/chronos/img/emr_use_case.png" alt=""></p>
<h2 id="UI"><a href="#UI" class="headerlink" title="UI"></a>UI</h2><ul>
<li>增删改job</li>
<li>运行job</li>
<li>展示job依赖关系</li>
<li>已经执行完的job的统计量</li>
</ul>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>要是已经安装了DC/OS的话<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">dcos package install chronos</div></pre></td></tr></table></figure></p>
<p>另外也可以使用docker启动，要保证两个端口资源：HTTP API， libprocess。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run --net=host -e PORT0=8080 -e PORT1=8081 mesosphere/chronos:v3.0.0 --zk_hosts 192.168.65.90:2181 --master zk://192.168.65.90:2181/mesos</div></pre></td></tr></table></figure>
<p>源码构建<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">export MESOS_NATIVE_LIBRARY=/usr/local/lib/libmesos.so</div><div class="line">git clone https://github.com/mesos/chronos.git</div><div class="line">cd chronos</div><div class="line">mvn package</div><div class="line">java -cp target/chronos*.jar org.apache.mesos.chronos.scheduler.Main --master zk://localhost:2181/mesos --zk_hosts localhost:2181</div></pre></td></tr></table></figure></p>
<p>运行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">java -jar chronos.jar --master zk://127.0.0.1:2181/mesos --zk_hosts 127.0.0.1:2181</div></pre></td></tr></table></figure></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/10/10/mesos框架概览：-mesos-master,-mesosframework,-kibana,-minimesos/" title="mesos框架概览：-mesos-master,-mesosframework,-kibana,-minimesos" itemprop="url">mesos框架概览：-mesos-master,-mesosframework,-kibana,-minimesos</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-10-10T03:03:07.000Z" itemprop="datePublished"> 发表于 2017-10-10</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="提纲"><a href="#提纲" class="headerlink" title="提纲"></a>提纲</h2><ul>
<li>使用<a href="http://www.github.com/ContainerSolutions/Mesos-Starter" target="_blank" rel="external">mesos-starter</a>做的自定义framework</li>
<li>使用<a href="http://www.github.com/ContainerSolutions/MesosFramework" target="_blank" rel="external">mesos framework</a>做的一个通用framework</li>
<li>一个为<a href="https://github.com/mesos/kibana" target="_blank" rel="external">kibana</a>定制的mesos framework</li>
<li>使用<a href="http://minimesos.org/" target="_blank" rel="external">minimesos</a>进行测试</li>
<li></li>
</ul>
<h2 id="mesos-starter"><a href="#mesos-starter" class="headerlink" title="mesos-starter"></a>mesos-starter</h2><p>这是一个spring工具，[简单参考(<a href="http://container-solutions.com/mesos-starter/)。下面是一些特性" target="_blank" rel="external">http://container-solutions.com/mesos-starter/)。下面是一些特性</a></p>
<ul>
<li>暴露一个bean来控制实例数量(提供水平扩展能力)</li>
<li>管理端口。用户可以请求静态的、或者mesos制定的端口，并且把它们用作环境变量</li>
<li>配置docker网络类型</li>
<li>mesos鉴权</li>
<li>用户可以指定任务的sandbox里下载二进制包以及其他附件资源的的URI</li>
</ul>
<p>这些新特性可以支撑framework更高的灵活性。例如，我们若是在minimesos中使用docker containerizer，就必须使用dcoker bridge模式来保护host上的端口不会冲突(所有的agent都使用同一个docker daemon)。但是在实际情况中，我们需要docker 运行在host模式，这样它们就可以直接使用主机ip了。</p>
<h2 id="mesosFramework"><a href="#mesosFramework" class="headerlink" title="mesosFramework"></a>mesosFramework</h2><p>MesosFramework是一个分布式的基于spring的二进制包，或者基于mesos-starter的docker容器。用户可以使用一个简单的配置文件快速创建一个可以运行在mesos上的framework，只需要告诉MesosFramework它应该运行什么任务就可以了。MesosFramework很通用，用户可以完全控制deployment。</p>
<p>我们讨论过<a href="http://container-solutions.com/reasons-use-apache-mesos-frameworks/" target="_blank" rel="external">为什么会想自己写一个mesos framwork</a>，希望你考虑使用Mesos-starter.许多简单的app都可以通过一个类似marathon的orchestration tool来启动。但是有些用例是介于这两个极端之间的，例如</p>
<ul>
<li>既想利用mesos-starter一些好的特性，又不想编写任何代码(authorisation， 一个orchestraion strategy等)</li>
<li>要打包一个特定的framework配置，这样用户就不用关心配置了（还是没有代码）</li>
<li>为某framework快速部署一个POC</li>
</ul>
<p>对我们来说，有很多frameworkd都落入了这个灰色地带。主要的好处就是减少了代码编写，也就减少了维护成本。</p>
<p>MesosFramework还添加了一些Mesos-Starter之外的特性。比如：查看task状态的REST接口、水平扩容等。</p>
<h2 id="Kibana-framework"><a href="#Kibana-framework" class="headerlink" title="Kibana framework"></a>Kibana framework</h2><p>新的<a href="https://github.com/mesos/kibana" target="_blank" rel="external">Kibana framework</a>就是基于MesosFramework和Mesos-starter构建的。它继承了这两个项目的所有特性。也就是说对于这两个项目的更新与特性发布会自动包含进像kibana这种下游项目中。这就是天堂，不用管理代码就能获得最新的特性。</p>
<p>但是最大的特点其实是：没有代码！！同样的重构也会应用到Logstash framework中。很多mesos framework都有对于代码的过度引用。每个framework都使用同样的方式添加mesos authorisation特性。全球的工程师都在同样的代码。我们都知道：代码越多，bug越多。</p>
<p>移除kibana的一些特定代码之后，我们同时搞定了潜在的bug，添加了新的特性，还降低了维护成本。</p>
<h2 id="minimesos"><a href="#minimesos" class="headerlink" title="minimesos"></a>minimesos</h2><p>以前，我们使用一个真正的mesos cluster给我们的demo使用。现在只需要使用minimesos就可以了。例如，有一天我想要测试<a href="https://github.com/mesos/elasticsearch" target="_blank" rel="external">Elasticsearch framework</a>是不是能够在mesos0.27版本正常工作(它本身是针对0.25版本编译的)。以前我需要写一个0.27版本集群的脚本，现在我只需要修改nimimesos配置文件中的一行就可以了。</p>
<p>参考：<a href="http://container-solutions.com/mesos-framework-overview/" target="_blank" rel="external">http://container-solutions.com/mesos-framework-overview/</a></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/10/09/presto架构/" title="presto架构" itemprop="url">presto架构</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-10-09T09:18:53.000Z" itemprop="datePublished"> 发表于 2017-10-09</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="server-类型"><a href="#server-类型" class="headerlink" title="server 类型"></a>server 类型</h2><h4 id="Coordinator"><a href="#Coordinator" class="headerlink" title="Coordinator"></a>Coordinator</h4><h4 id="Worker"><a href="#Worker" class="headerlink" title="Worker"></a>Worker</h4><h2 id="数据源"><a href="#数据源" class="headerlink" title="数据源"></a>数据源</h2><h4 id="Connector"><a href="#Connector" class="headerlink" title="Connector"></a>Connector</h4><p>用来适配presto到类似hive的RDBMS。可以把connector当成database的driver。是Presto的SPI的一个实现，允许presto使用标准API与资源进行交互。</p>
<p>Presto包含几个内置的connectors：JMX, HIVE, System connector用来提供访问内部系统表的访问方式， TPCH connector用来提供TPC-H benchmark数据。还有一些第三方的connector。</p>
<p>每个catalog是与一个指定的connector进行协作的。如果你看过catalog的配置文件，你会发现每个都必须包含一个connector.name属性，catalog manager用这个来为指定catalog创建对应的connector。可以多个catalog共用同一个connector来连接两个相同数据库的不同实例。例如，假设我们有两个hive集群，我们就配置两个catalog实例，都用hive connector，这样甚至能在同一个SQL查询中查询到两个hive集群中的数据。</p>
<h4 id="catalog"><a href="#catalog" class="headerlink" title="catalog"></a>catalog</h4><p>一个catalog包含多个数据库schema和通过一个connector关联的数据源。在运行sql语句的时候，可以在一个或多个catalog中进行数据查询。</p>
<p>在presto中，数据表的全名是catalog的根部。例如hive.test.data.test就是hive catalog中的test_data数据库中的test表。</p>
<p>catalog是通过presto配置目录中的properties文件定义的。</p>
<h4 id="schema"><a href="#schema" class="headerlink" title="schema"></a>schema</h4><p>schema是用来组织table的。catalog和schema用来定义一组可供查询的数据表。在prestor查询hive或者mysql等关系型数据库的时候，schema就对应于数据库名。其他类型的connector也可以根据具体场景进行对应</p>
<h4 id="Table"><a href="#Table" class="headerlink" title="Table"></a>Table</h4><p>未排序的数据行的组合，每个列都有自己的类型。与关系型数据库定义一样。</p>
<h2 id="查询模型"><a href="#查询模型" class="headerlink" title="查询模型"></a>查询模型</h2><h4 id="Statement"><a href="#Statement" class="headerlink" title="Statement"></a>Statement</h4><p>Presto执行ANSI兼容的SQL语句。当一个statement被执行的时候，presto创建一个query和一个query plan，然后这个plan被分布到presto worker中执行。</p>
<h4 id="Query"><a href="#Query" class="headerlink" title="Query"></a>Query</h4><p>Presto解析statement的时候，把statement转化成一个query，创建一个分布式的query plan，然后形成一系列相互关联的stage，运行到不同的presto worker上。当我们抽取一个查询的信息的时候，我们会获取到对应于这个satement的每个组件的状态快照。</p>
<p>statement和query的区别很简单，statement可以看作传递给presto的SQL语句，一个query则对应于执行这个statement的配置与实例化的组件。一个query包含了stage、task、split、connector、数据源以及其他组件。</p>
<h4 id="Stage"><a href="#Stage" class="headerlink" title="Stage"></a>Stage</h4><p>presto执行query时，会把query plan打成一系列有层级的stage。例如，如果presto需要聚合hive里的一亿行数据，他需要创建一个root stage来对其他stage的output执行聚合操作，这些其他stage负责query plan中的不同部分。</p>
<p>这些stage可以使用tree来表示。每个query都有一个root stage来执行其他stage的聚合操作。coordinator 是coordinator用来模型化分布式query plan的，但是stage本身并不运行在presto worker上。</p>
<h4 id="Task"><a href="#Task" class="headerlink" title="Task"></a>Task</h4><p>前面提到，stage只是模型化分布式查询计划的一个特定部分，而不在presto worker上执行。一个stage其实又被一系列task实现，分布式运行在presto worker上。</p>
<p>presto task是有多个input和output的，可以与一系列driver并行执行。</p>
<h4 id="Split"><a href="#Split" class="headerlink" title="Split"></a>Split</h4><p>stage是通过connector从数据源以split为单位抽取数据的，然后中间的stage或高层stage又从其他stage中抽取数据。</p>
<p>prestor执行query时，coordinator会从一个connector查到指定table的所有的split。coordinator追踪哪些机器在运行哪些task，哪些split在被哪些task处理。</p>
<h4 id="Driver"><a href="#Driver" class="headerlink" title="Driver"></a>Driver</h4><p>task包含一个或多个并行的driver，一个driver只有一个input和output。dirver整合operator来生成output，这个output会被task聚合，再传递给其他stage的一个task。一个driver是一个operator实例的序列，可以把他看成内存中的一系列operator集合。它是presto并发执行的最低层单元了。</p>
<h4 id="Operator"><a href="#Operator" class="headerlink" title="Operator"></a>Operator</h4><p>operator消费、转换、生产数据。例如，一个table scan从connector中抽取数据，然后生产可以被其他operator消费的数据。一个filter operator消费数据，生产已经过滤掉的一个数据子集。</p>
<h4 id="Exchange"><a href="#Exchange" class="headerlink" title="Exchange"></a>Exchange</h4><p>Exchange负责在Presto节点间传递同一个query的不同stage的数据。task把数据生成进一个output buffer，并使用exchange client消费其他task生成的数据。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/10/09/impala架构/" title="impala架构" itemprop="url">impala架构</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-10-09T07:52:50.000Z" itemprop="datePublished"> 发表于 2017-10-09</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="impala-Daemon"><a href="#impala-Daemon" class="headerlink" title="impala Daemon"></a>impala Daemon</h2><p>核心的impala组件是impala daemon，它需要在每个datanode上部署一个，进程名是impalad。它负责读写数据文件、接收来自impala-shell命令行、hue、JDBC或者ODBC的查询；并行执行查询、为集群分配分布式任务、再把中间查询结果发送回coordinator node。</p>
<p>可以通过任何一个datanode上的impala daemon提交查询，然后这个node上的impala daemon就作为这个查询的coordinator node。其他node把部分结果回传给coordinator node，coordinator node负责把这些结果进行组织，并产生最终结果。当通过impala-shell命令运行查询的时候，我们可能需要一直连接着同一个impala daemon。对于集群生产环境，我们需要考虑负载均衡，将查询放到不同的node上去提交。</p>
<p>impala daemon需要与statestore持续联系，以确认哪些node是健康的，可以接受任务。</p>
<p>impala daemon还要接收catalogd的广播信息，获取集群中哪些impala node新建、修改、drop一些类型的对象、或insert或者load data语句的执行。这个动作最小化了REFRESH和INVALIDATE METADATA语句的执行次数，这两个动作在1.2之前必须要协调所有node的元数据。</p>
<p>在2.9或更高版本中，我们可以控制哪些node可以用作query coordinator，那些是query executor，以此提升扩展性。</p>
<h2 id="impala-statestore"><a href="#impala-statestore" class="headerlink" title="impala statestore"></a>impala statestore</h2><p>statestore负责检查所有 datanode上的impala daemon的健康状态，同时也通知每个impala daemon它的新发现。他是一个独立的进程，statestored，需要集群中的某个机器上有一个就可以。如果一个impala daemon掉线的话，statestore会通知所有其他的impala daemon，这要后面的查询任务就不会分配到这个掉线的node上。</p>
<p>因为statestore的职责是处理问题情况，所以它并不是impala 集群执行正常任务的核心所在。如果statestore挂掉，impala daemon会像往常一样继续运行、分配任务、执行任务。只是集群会在某些impala daemon挂掉的时候变得不那么强壮。当statestore恢复之后，它会重建与impala daemon的联系。</p>
<p>多数既有的HA和LB方案都可以用于impala daemon。而statestored和catalogd进程就不需要，因为它们挂掉并不会造成数据丢失。如果这些进程变为不可用的话，可以直接停掉impala服务，删掉基友的impala statestore和impala catalog server，然后把它们分配到其他的node上，重启impala service就可以了。</p>
<h2 id="impala-catalog服务"><a href="#impala-catalog服务" class="headerlink" title="impala catalog服务"></a>impala catalog服务</h2><p>catalog服务负责将impala SQL语句导致的源数据变化传递给集群中的所有的Datanode节点，进程为catalogd，整个集群只需要一个。因为查询请求会通过statestore daemon，最好将statestored和catalogd两个服务运行在同一个host上。</p>
<p>catalog服务避免了由元数据变化引起的REFRESH和INVALIDATE METADATA操作。当我们通过hive创建表、加载数据的时候，我们必须要执行REFRESH和INVALIDATE METADATA操作才能执行数据查询。</p>
<p>这个特性有关于impala的以下几个方面：</p>
<ul>
<li>见安装impala、升级impala</li>
<li>通过impala执行CREATE TABLE, INSERT或者其他修改表、修改数据的操作并不需要REFRESH和INVALIDATE METADATA操作。但是如果是通过hive或者手动加载HDFS文件方式的话，就需要。</li>
</ul>
<p>默认地，加载元数据和加载缓存是异步的，所以impala可以立刻接收请求。可以通过参数配置load_catalog_in_background=false.。</p>
<h2 id="impala对于hadoop生态的兼容与适配"><a href="#impala对于hadoop生态的兼容与适配" class="headerlink" title="impala对于hadoop生态的兼容与适配"></a>impala对于hadoop生态的兼容与适配</h2><h4 id="hive"><a href="#hive" class="headerlink" title="hive"></a>hive</h4><p>impala维护了table定义，也就是metastore，其实就是hive 的metastore的数据库。impala还要追踪对应的数据文件：HDFS中数据的block的具体位置。</p>
<p>对于数据量特别大、分区数特别多的表来说，单抽取元数据就可能花掉数分钟的时间。因此，每个impala  node都会把这些信息缓存起来以供后面重用。</p>
<p>如果某个表的定义改变或者数据被更新，那么其他所有的impala daemon都要在对这个表执行查询之前同步最新的metadata，替换掉老的那份缓存。1.2版本之后，这个过程是自动的通过catalogd进程完成。</p>
<p>对于未通过impala操作的修改，则需要执行REFRESH（已经存在的表加入新的数据文件或更新）或者INVALIDATE METADATA(创建新标、删除表、执行了HDFS rebalance、 删除了数据文件等)。INVALIDATE METATDATA会重新抽取所有的表的metadata。所有如果要是知道哪个表有变化的话，可以使用REFRESH table_name来执行只拉取这个表的相关元数据。</p>
<h4 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h4><p>impala使用HDFS作为主要的存储介质，利用HDFS的冗余来保证数据不丢失。impala表数据物理上就是HDFS的数据文件，可以是HDFS支持的任何格式或压缩格式。当数据文件是放在一个目录作为一个表存在是，impala会把这个目录下所有的文件都作为表的内容进行读取。通过impala新增的数据文件，则会由impala进行命名。</p>
<h4 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h4><p>HDFS的替代方案。需要在impala中额外定义对应表。</p>
<h2 id="并发控制"><a href="#并发控制" class="headerlink" title="并发控制"></a>并发控制</h2><p>通过准入控制来闲置资源的方式之一是限制一个最大并发查询数量。在我们没有内存使用情况的足够信息的时候这是一个比较初步的方式。这个参数可以分别给每个动态资源池进行设置。</p>
<p>这个配置也可以结合下面章节中内存控制的配置一起使用。不管是达到了内存最大使用量，或者超过了最大并发查询数，后续的查询都会被放到队列里，等待资源。</p>
<h2 id="内存控制"><a href="#内存控制" class="headerlink" title="内存控制"></a>内存控制</h2><p>每个动态资源池都可以配置一个最大内存使用量。最好是在已经明确知道工作量与使用大小的时候使用这个配置。</p>
<p>每个host上都要指定一个默认的最大内存Default Query<br>Memory Limit，相当于在这个资源池中为每个query指定一个MEM_LIMIT参数。</p>
<p>另外，也可以根据每个node的最大内存计算出一个集群级别的最大内存限制，来控制最多并行查询数。</p>
<p>例如下面场景：</p>
<ul>
<li>五个datanode上运行了impalad</li>
<li>设置一个动态资源池的最大内存为100G</li>
<li>host级别的最大内存Default Query<br>Memory Limit设置为10G，那么每个查询最多使用 5 * 10 = 50G</li>
<li>在这个动态资源池中可以并行运行的查询数为2，100 / 50 = 2.</li>
<li>如果查询并没有用满host或者集群级别的内存上限额度，并不会有什么惩罚措施。这些上限值只是用来估算资源池里可以并行多少查询。</li>
</ul>
<p>注意： 如果你为某个impala动态资源池指定了集群级别的最大内存，就必须指定host级别的最大内存Default Query<br>Memory Limit。</p>
<h2 id="与其他资源管理工具的关系"><a href="#与其他资源管理工具的关系" class="headerlink" title="与其他资源管理工具的关系"></a>与其他资源管理工具的关系</h2><p>admission control是轻量级、去中心化的。他设置的是一个soft limit，并不是像yarn把资源进行all-or-nothing方式处理。</p>
<p>因为admission control并不与其他hadoop组件(MR)交互，我们可以使用yarn的部分静态资源池，与其他hadoop应用共享yarn。要使用impala多租户的时候推荐使用此种配置。admission control控制查询并发和内存上限，yarn来管理其它的组件。这种情况中，impala的资源并不是由yarn管理的。</p>
<p>impala的admission control可以使用yarn的user与pool的认证关系。</p>
<p>虽然impala admission control使用了fair-scheduelr.xml配置文件，但是这个文件并不关心YARN实际使用哪个scheduler，也就是说它仍可以使用capacity scheduler。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/10/09/hadoop-vs-mpp/" title="hadoop-vs-mpp" itemprop="url">hadoop-vs-mpp</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-10-09T03:45:18.000Z" itemprop="datePublished"> 发表于 2017-10-09</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="什么是MPP"><a href="#什么是MPP" class="headerlink" title="什么是MPP"></a>什么是MPP</h2><p>MPP全名是massively parallel processing，是网格计算的一种实现，网格中的所有节点都参与计算过程。MPP DBMS是基于MPP的DBMS。每个查询都需要先切分计算任务，这会比传统的SMP RDBMS更快一些。另外，MPP还具有扩展性，我们可以方便的向网格中添加节点来扩展计算与存储能力。为了处理大量数据，需要对数据进行在节点之间进行shard，这样每个节点都只处理自己本地的数据。这进一步提升了数据处理速度，因为使用共享存储的话会出现一个很大的问题—— 更复杂，更昂贵，不易扩展，更高的网络IO，更小的并行度。这就是大多数MPP DBMS方案share-nothing不共享任何东西，运行在DAS（direct-attached storage）或者小组server共享机架存储的原因。Teradata、Greenplum、Vertica、Netezza等都是使用的这种方式。这些工具都有一个复杂且成熟，专为MPP方案订制的SQL optimizer。而且他们都是可扩展的，围绕这些方案有很多的工具包来支持用户的需求：地理位置分析、全文检索等。他们都是闭源的复杂的企业级解决方案(Greenplum在2015年开源)。</p>
<p><img src="https://0x0fff.com/wp-content/uploads/2015/07/MPP_arch.gif" alt=""></p>
<h2 id="hadoop"><a href="#hadoop" class="headerlink" title="hadoop"></a>hadoop</h2><p>那么hadoop呢？不是一个单一的技术，而是一个生态。基友好处也有坏处，最大的优点就是延展性好 - 催生了一些列的新组件（spark），而且这些组件的核心都与hadoop息息相关，这就给集群的扩展性很多可能性。一个缺点是弄一个整套的生态是比较费事儿的，现在没人手工弄，都是借助工具了。</p>
<p>hadoop的存储技术是一个完全不同的方式。并不是根据key去把数据进行shard，而是把数据弄成指定大小的block块进行切分，以block为单位存储在不同节点上。这些数据块一般是比较大且只读的，整个文件系统也是只读的。简单来说，对于加载100行数据表，MPP引擎会基于某个key把数据进行shard，对于较大的集群来说这种方式可能会出现每个node上只有一条记录的现象。而如果使用HDFS的话，这个小的表会被写在一个数据块中，对于datanode的文件系统来说只是一个普通的 文件而已。</p>
<p>资源管理呢？不同于MPP方案，hadoop的资源管理器具有更细粒度。MR任务不需要所有的计算任务都并行执行，如果集群资源满载的时候，我们甚至可以把某个任务的数据和所有计算任务都丢到一个节点上执行。还有一系列的其他延展性，支持长时间运行的container等..但是事实上，它比MPP的资源管理器会慢一些，而且对于并发管理表现也稍逊一筹。</p>
<h2 id="可选"><a href="#可选" class="headerlink" title="可选"></a>可选</h2><p>对于Hadoop的SQL接口工具，有很多工具可以选择：基于MR/Tez/Spark的hive、sparksql、impala、HAQW或者IBM BigSQL、或者完全不同的Splice Machine。因为有太多工具可选，也很容易迷失。</p>
<h4 id="hive"><a href="#hive" class="headerlink" title="hive"></a>hive</h4><p>把sql转化为MR/Tez/Spark任务，在集群上执行。所有的这些任务类型其实都是基于MR思想，可以很好的利用集群，也方便与其他的hadoop技术栈进行整合。缺点也很明显 —— 执行查询的延迟较大，对于表之间的join操作性能堪忧，没有查询优化器引擎只按照你说的方式进行执行。下图覆盖了废弃的MR1的设计图：<br><img src="https://0x0fff.com/wp-content/uploads/2015/07/HiveArchitecture.jpg" alt=""></p>
<h4 id="MPP"><a href="#MPP" class="headerlink" title="MPP"></a>MPP</h4><p>类似impala和HAWQ的解决方案则与hive相对，使用了基于HDFS的MPP执行引擎。他们对于查询有更小的延迟、更少的处理时间，但是牺牲了一些扩展性和稳定性。</p>
<p><img src="https://0x0fff.com/wp-content/uploads/2015/07/impala.png" alt=""></p>
<h4 id="SparkSQL"><a href="#SparkSQL" class="headerlink" title="SparkSQL"></a>SparkSQL</h4><p>sparkSQL是一个介于MR和MPP-over-hadoop之间的解决方案。与MR类似，它把job切分为一组task进行分别调度，这样来保证比较好的稳定性。又类似于MPP，试图把各个执行的stage之间流式串联起来来提高处理速度。他还使用类似于MPP的固定的executor来降低查询延迟。它继承了优点，同样缺点也跟了过来 —— 不及MPP快，不及MR稳定。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><table>
<thead>
<tr>
<th>指标</th>
<th>MPP</th>
<th>Hadoop</th>
</tr>
</thead>
<tbody>
<tr>
<td>平台开放性</td>
<td>闭塞且专利。对于一些技术甚至连文档都是闭源的</td>
<td>完全开源</td>
</tr>
<tr>
<td>硬件选择</td>
<td>很多都是必须依托服务方的，很少能部署在自己的集群上。所有的解决方案都需要企业级的硬件，比如快速硬盘，大ECC RAM的服务器，无线带宽等</td>
<td>任何硬件都可用。最推荐的就是使用廉价的带有DAS的硬件【就是磁盘单挂】</td>
</tr>
<tr>
<td>节点水平扩展</td>
<td>平均几十台，最多100-200台</td>
<td>平均100台，最多几千台</td>
</tr>
<tr>
<td>用户数据扩展性</td>
<td>几十TB，最多PB级别</td>
<td>几百TB, 最多几十PB</td>
</tr>
<tr>
<td>查询延迟</td>
<td>10-20 milliseconds</td>
<td>10-20 seconds</td>
</tr>
<tr>
<td>平均查询时间</td>
<td>5-7 seconds</td>
<td>10-15 minutes</td>
</tr>
<tr>
<td>最大查询时间</td>
<td>1-2 hours</td>
<td>1-2 weeks</td>
</tr>
<tr>
<td>查询优化</td>
<td>复杂的企业级查询优化引擎使用全局最优的方式</td>
<td>没有optimizer，或者有限制，有时甚至都不支持cost-based</td>
</tr>
<tr>
<td>查询debug与profile</td>
<td>有查询计划与查询静态量，提供错误信息</td>
<td>OON问题和java堆溢出分析，GC停止信息，分离的任务日志</td>
</tr>
<tr>
<td>技术代价</td>
<td>每个节点几千或者几万美元</td>
<td>每个节点最多几千美元</td>
</tr>
<tr>
<td>终端用户的访问</td>
<td>SQL接口和一些简单的数据库函数</td>
<td>SQL并不完全兼容。用户需要关注执行逻辑，数据的分布。函数一般需要用java进行编写，放到集群中</td>
</tr>
<tr>
<td>目标用户</td>
<td>商业分析师</td>
<td>java dev和经验丰富的DBA</td>
</tr>
<tr>
<td>单job冗余度</td>
<td>低，MPP节点失败，则job失败</td>
<td>高，job失败后有重试</td>
</tr>
<tr>
<td>目标系统</td>
<td>一般的DWH和分析系统</td>
<td>为特定目标构建的数据处理引擎</td>
</tr>
<tr>
<td>vendor lock-in</td>
<td>typical case</td>
<td>Rare case usually caused by technology misuse</td>
</tr>
<tr>
<td>推荐的最小的数据大小</td>
<td>任何</td>
<td>GB</td>
</tr>
<tr>
<td>最大并发</td>
<td>几十到几百个query</td>
<td>10-20个job</td>
</tr>
<tr>
<td>技术延展性</td>
<td>只能使用厂家提供的工具</td>
<td>可以随意组合开源工具</td>
</tr>
<tr>
<td>需要的DBA技术级别</td>
<td>一般水平</td>
<td>精通java和RDBMS背景</td>
</tr>
<tr>
<td>方案实现服务性</td>
<td>中</td>
<td>高</td>
</tr>
</tbody>
</table>
<p>有了以上信息，我们知道为什么hadoop不能完全取代传统企业级数据仓库，但是他是可以用作处理海量数据的一种分布式引擎。facebook有一个300PB的hadoop集群，它还额外用了50TB的Vertica集群。Linkedin有一个巨大的hadoop集群，也同样有一个Aster数据中心（Teradata提供的MPP工具）。</p>
<p>参考：<br><a href="https://0x0fff.com/hadoop-vs-mpp/" target="_blank" rel="external">https://0x0fff.com/hadoop-vs-mpp/</a></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/09/30/centos7-微服务相关环境部署/" title="centos7-微服务相关环境部署" itemprop="url">centos7-微服务相关环境部署</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-09-30T08:50:34.000Z" itemprop="datePublished"> 发表于 2017-09-30</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h4 id="系统环境"><a href="#系统环境" class="headerlink" title="系统环境"></a>系统环境</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">hostnamectl set-hostname xx.will.com --static</div><div class="line"></div><div class="line">yum install -y wget git vim ntpdate</div><div class="line"></div><div class="line">timedatectl set-timezone Asia/Shanghai</div><div class="line"></div><div class="line">/usr/sbin/ntpdate us.pool.ntp.org</div></pre></td></tr></table></figure>
<h4 id="docker安装"><a href="#docker安装" class="headerlink" title="docker安装"></a>docker安装</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">tee /etc/yum.repos.d/docker.repo &lt;&lt;-&apos;EOF&apos;</div><div class="line">[dockerrepo]</div><div class="line">name=Docker Repository</div><div class="line">baseurl=https://yum.dockerproject.org/repo/main/centos/7/</div><div class="line">enabled=1</div><div class="line">gpgcheck=1</div><div class="line">gpgkey=https://yum.dockerproject.org/gpg</div><div class="line">EOF</div><div class="line"></div><div class="line">yum install docker-engine -y</div><div class="line"></div><div class="line"># 获取最新版本的docker</div><div class="line"># curl -fsSL https://get.docker.com/ | sh</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">systemctl enable docker.service</div><div class="line">systemctl restart docker</div><div class="line"></div><div class="line"></div><div class="line">docker version</div></pre></td></tr></table></figure>
<p>ubuntu<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"># step 1: 安装必要的一些系统工具</div><div class="line">sudo apt-get update</div><div class="line">sudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common</div><div class="line"># step 2: 安装GPG证书</div><div class="line">curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -</div><div class="line"># Step 3: 写入软件源信息</div><div class="line">sudo add-apt-repository &quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot;</div><div class="line"># Step 4: 更新并安装 Docker-CE</div><div class="line">sudo apt-get -y update</div><div class="line">sudo apt-get -y install docker-ce</div><div class="line"></div><div class="line"># 安装指定版本的Docker-CE:</div><div class="line"># Step 1: 查找Docker-CE的版本:</div><div class="line"># apt-cache madison docker-ce</div><div class="line">#   docker-ce | 17.03.1~ce-0~ubuntu-xenial | http://mirrors.aliyun.com/docker-ce/linux/ubuntu xenial/stable amd64 Packages</div><div class="line">#   docker-ce | 17.03.0~ce-0~ubuntu-xenial | http://mirrors.aliyun.com/docker-ce/linux/ubuntu xenial/stable amd64 Packages</div><div class="line"># Step 2: 安装指定版本的Docker-CE: (VERSION 例如上面的 17.03.1~ce-0~ubuntu-xenial)</div><div class="line"># sudo apt-get -y install docker-ce=[VERSION]</div></pre></td></tr></table></figure></p>
<p>centos7<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"># step 1: 安装必要的一些系统工具</div><div class="line">sudo yum install -y yum-utils device-mapper-persistent-data lvm2</div><div class="line"># Step 2: 添加软件源信息</div><div class="line">sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</div><div class="line"># Step 3: 更新并安装 Docker-CE</div><div class="line">sudo yum makecache fast</div><div class="line">sudo yum -y install docker-ce</div><div class="line"># Step 4: 开启Docker服务</div><div class="line">sudo service docker start</div><div class="line"></div><div class="line"># 注意：</div><div class="line"># 官方软件源默认启用了最新的软件，您可以通过编辑软件源的方式获取各个版本的软件包。例如官方并没有将测试版本的软件源置为可用，你可以通过以下方式开启。同理可以开启各种测试版本等。</div><div class="line"># vim /etc/yum.repos.d/docker-ee.repo</div><div class="line">#   将 [docker-ce-test] 下方的 enabled=0 修改为 enabled=1</div><div class="line">#</div><div class="line"># 安装指定版本的Docker-CE:</div><div class="line"># Step 1: 查找Docker-CE的版本:</div><div class="line"># yum list docker-ce.x86_64 --showduplicates | sort -r</div><div class="line">#   Loading mirror speeds from cached hostfile</div><div class="line">#   Loaded plugins: branch, fastestmirror, langpacks</div><div class="line">#   docker-ce.x86_64            17.03.1.ce-1.el7.centos            docker-ce-stable</div><div class="line">#   docker-ce.x86_64            17.03.1.ce-1.el7.centos            @docker-ce-stable</div><div class="line">#   docker-ce.x86_64            17.03.0.ce-1.el7.centos            docker-ce-stable</div><div class="line">#   Available Packages</div><div class="line"># Step2 : 安装指定版本的Docker-CE: (VERSION 例如上面的 17.03.0.ce.1-1.el7.centos)</div><div class="line"># sudo yum -y install docker-ce-[VERSION]</div></pre></td></tr></table></figure></p>
<p><a href="https://yq.aliyun.com/articles/110806" target="_blank" rel="external">https://yq.aliyun.com/articles/110806</a></p>
<p>配置文件 /etc/docker/daemon.json<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">  &quot;graph&quot;: &quot;/server/dspace&quot;,</div><div class="line">  &quot;insecure-registries&quot;: [&quot;10.1.5.129&quot;],</div><div class="line">  &quot;registry-mirrors&quot;: [&quot;https://docker.mirrors.ustc.edu.cn&quot;,&quot;http://3a35aff6.m.daocloud.io&quot;,&quot;http://ethanzhu.m.tenxcloud.net&quot;],</div><div class="line">  &quot;hosts&quot;: [&quot;tcp://0.0.0.0:4243&quot;,&quot;unix:///var/run/docker.sock&quot;]</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">  &quot;registry-mirrors&quot;: [&quot;https://docker.mirrors.ustc.edu.cn&quot;,&quot;http://3a35aff6.m.daocloud.io&quot;,&quot;http://ethanzhu.m.tenxcloud.net&quot;],</div><div class="line">  &quot;metrics-addr&quot; : &quot;10.2.19.112:9323&quot;,</div><div class="line">  &quot;experimental&quot; : true,</div><div class="line">  &quot;dns&quot;: [&quot;10.2.19.112&quot;],</div><div class="line">  &quot;dns-search&quot;: [&quot;will.com&quot;]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="mesos-marathon"><a href="#mesos-marathon" class="headerlink" title="mesos + marathon"></a>mesos + marathon</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">rpm -Uvh http://repos.mesosphere.io/el/7/noarch/RPMS/mesosphere-el-repo-7-1.noarch.rpm</div><div class="line">yum -y install mesos marathon mesosphere-zookeeper</div></pre></td></tr></table></figure>
<p>master环境脚本</p>
<p>mesos_master_start.sh<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> MESOS_cluster=will</div><div class="line"><span class="comment">#export MESOS_zk=zk://10.1.5.65:2181/wesos</span></div><div class="line"><span class="built_in">export</span> MESOS_zk=zk://datanode01.will.com:2181,datanode02.will.com:2181,datanode04.will.com:2181,servicenode05.will.com:2181,servicenode06.will.com:2181/wesos</div><div class="line"><span class="built_in">export</span> MESOS_work_dir=/var/lib/mesos/master</div><div class="line"><span class="built_in">export</span> MESOS_quorum=1</div><div class="line"><span class="built_in">export</span> MESOS_log_dir=/server/mesos_log</div><div class="line"><span class="built_in">export</span> MESOS_zk_session_timeout=20secs</div><div class="line"><span class="built_in">export</span> MESOS_logging_level=WARNING</div><div class="line"><span class="comment">#export MESOS_log_dir=/var/log/mesos_master</span></div><div class="line"><span class="built_in">export</span> MESOS_hostname=10.2.19.124</div></pre></td></tr></table></figure></p>
<p>启动脚本：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">. /server/mesos_master_start.sh &amp;&amp; nohup /usr/sbin/mesos-master &amp;&gt; mesos_master.out&amp;</div></pre></td></tr></table></figure></p>
<p>mesos_agent_env.sh<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">export MESOS_executor_registration_timeout=5mins</div><div class="line">export MESOS_containerizers=docker,mesos</div><div class="line">export MESOS_isolation=cgroups/cpu,cgroups/mem</div><div class="line">export MESOS_work_dir=/server/mesos/agent</div><div class="line">export MESOS_master=zk://datanode01.will.com:2181,datanode02.will.com:2181,datanode04.will.com:2181/wesos_online</div><div class="line">export MESOS_resources=&apos;ports:[10000-60000]&apos;</div></pre></td></tr></table></figure></p>
<p>启动脚本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">. /server/mesos_agent_env.sh &amp;&amp; nohup mesos-agent &amp;&gt; mesos_agent.out&amp;</div></pre></td></tr></table></figure></p>
<p>marathon<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">nohup marathon  --master zk://datanode01.will.com:2181,datanode02.will.com:2181,datanode04.will.com:2181/wesos_online  --zk zk://datanode01.will.com:2181,datanode02.will.com:2181,datanode04.will.com:2181/mt_online  --zk_timeout 15000 &amp;&gt; marathon.out&amp;</div></pre></td></tr></table></figure></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






  <nav id="page-nav" class="clearfix">
    <a class="extend prev" rel="prev" href="/page/5/"><span></span>Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/25/">25</a><a class="extend next" rel="next" href="/page/7/">Next<span></span></a>
  </nav>

</div>
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  


  

  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/youdaonote/" title="youdaonote">youdaonote<sup>187</sup></a></li>
			
		
			
				<li><a href="/tags/源码/" title="源码">源码<sup>10</sup></a></li>
			
		
			
				<li><a href="/tags/akka/" title="akka">akka<sup>9</sup></a></li>
			
		
			
				<li><a href="/tags/flume/" title="flume">flume<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/ETL/" title="ETL">ETL<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/solr/" title="solr">solr<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/spring/" title="spring">spring<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/调度平台/" title="调度平台">调度平台<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/azkaban/" title="azkaban">azkaban<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/mysql/" title="mysql">mysql<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/scala/" title="scala">scala<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/ambari/" title="ambari">ambari<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/quartz/" title="quartz">quartz<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/django/" title="django">django<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/架构/" title="架构">架构<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/架构，jaeger/" title="架构，jaeger">架构，jaeger<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/ember/" title="ember">ember<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/nodejs/" title="nodejs">nodejs<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/R/" title="R">R<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/guava/" title="guava">guava<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="https://github.com/willcup" target="_blank" title=" 我自己的github">github</a>
            
          </li>
        
          <li>
            
            	<a href="http://thisding.com" target="_blank" title="朋友的主页">Steven&#39;s Blog</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

  <div class="weiboshow">
  <p class="asidetitle">新浪微博</p>
    <iframe width="100%" height="119" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=null&verifier=&dpc=1"></iframe>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m Will Chen in MeiTuan. <br/>
			元 亨 利 贞.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
		<a href="mailto:chenxin15@meituan.com" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2018 
		
		<a href="/about" target="_blank" title="Will Chen">Will Chen</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>










<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3Fe6d1f421bbc9962127a50488f9ed37d1' type='text/javascript'%3E%3C/script%3E"));
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
 </html>
