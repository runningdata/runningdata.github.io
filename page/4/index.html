
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?5b99dfd487346155d274c0c49c3fb869";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
  </script>

  
    <title>Will&#39;s Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Will Chen">
    

    
    <meta name="description" content="左右水色 右手天光">
<meta property="og:type" content="website">
<meta property="og:title" content="Will's Blog">
<meta property="og:url" content="http://willcup.com/page/4/index.html">
<meta property="og:site_name" content="Will's Blog">
<meta property="og:description" content="左右水色 右手天光">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Will's Blog">
<meta name="twitter:description" content="左右水色 右手天光">

    
    <link rel="alternative" href="/atom.xml" title="Will&#39;s Blog" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="Will&#39;s Blog" title="Will&#39;s Blog"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Will&#39;s Blog">Will&#39;s Blog</a></h1>
				<h2 class="blog-motto">简易 变易 不易</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">首页</a></li>
					
						<li><a href="/archives">归档</a></li>
					
						<li><a href="/about">关于</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:willcup.com">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main">

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/22/hive2---轻松更新hive表2/" title="hive2---轻松更新hive表2" itemprop="url">hive2---轻松更新hive表2</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-22T09:58:13.000Z" itemprop="datePublished"> 发表于 2017-11-22</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>前面讲了使用MERGE,UPDATE,DELETE更新hive数据。现在我们进一步谈一下hive管理slowly-changing dimensions(SCDs，就是缓慢更新的维度表)的策略。在数据仓库中，SCDs更新数据是无规律的。对应于不同的业务需求，有不同的策略。假如你要一个用户维度表的所有历史，以跟踪某个用户随时间的变化情况。还有些情况，我们只关心最新的维度状态 。</p>
<p>下面是三种SCD更新策略：</p>
<ul>
<li>使用新数据覆盖旧数据。很简单，如果只是要同步最新状态的话，就用这个，但是会丢失历史维度值。</li>
<li>添加带有version的新数据行。可以追踪到所有历史。但是随着时间的退役，可能会特别大，还有就是查询的时候需要只看最新版本的维度值。</li>
<li>添加新数据行，管理有限版本的历史。有一些历史数据，然是控制在一定范围内。</li>
<li></li>
</ul>
<p>这个blog是讲一下怎样使用hive的MERGE来管理SCD。所有的例子都可以在<a href="https://github.com/cartershanklin/hive-scd-examples" target="_blank" rel="external">这里</a>找到。管理SCD是很麻烦的事情，所以最好能够用一些工作，比如<a href="https://www.amazon.com/Data-Warehouse-Toolkit-Complete-Dimensional/dp/0471200247" target="_blank" rel="external">数仓工具</a></p>
<h4 id="SCD管理策略一览"><a href="#SCD管理策略一览" class="headerlink" title="SCD管理策略一览"></a>SCD管理策略一览</h4><p><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/1Slowly-changing-dimensions-1024x695.png" alt=""></p>
<h4 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h4><p>所有的是例子都是从一个外部表，copy到hive的managed table，这个managed table就是merge target。第二个外部表，代表第二次从某个系统全量dump出来的数据。这两个外部表是一样的csv文件，包含字段:ID,Name, Email,State。初始化的数据有1000条，第二次数据有1100条，其中包含100个新纪录和93个需要更新项。</p>
<h4 id="第一种策略"><a href="#第一种策略" class="headerlink" title="第一种策略"></a>第一种策略</h4><p>有就直接替换，没有就添加。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">merge into</div><div class="line"> contacts_target</div><div class="line">using</div><div class="line"> contacts_update_stage as stage</div><div class="line">on</div><div class="line"> stage.id = contacts_target.id</div><div class="line">when matched then</div><div class="line"> update set name = stage.name, email = stage.email, state = stage.state</div><div class="line">when not matched then</div><div class="line"> insert values (stage.id, stage.name, stage.email, stage.state);</div></pre></td></tr></table></figure>
<p>值得注意的是，上面的操作也是单独一个，是原子且独立的，如果出现错误会正确rollback。在SQL-on-Hasdoop方式里提供这些特性是很困难的，但是hive的MERGE操作就实现了。</p>
<h4 id="第二种策略"><a href="#第二种策略" class="headerlink" title="第二种策略"></a>第二种策略</h4><p>保留所有的历史版本，提供单独的版本相关字段:ValidFrom, ValidTo。</p>
<p><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/2Hive-Type-2_1-1024x319.png" alt=""></p>
<p>我们可以使用这个策略来满足并发用户对于正在更新的数据的数据读取。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">merge into contacts_target</div><div class="line">using (</div><div class="line"> — The base staging data.</div><div class="line"> select</div><div class="line">contacts_update_stage.id as join_key,</div><div class="line">contacts_update_stage.* from contacts_update_stage</div><div class="line"> union all</div><div class="line">— Generate an extra row for changed records.</div><div class="line"> — The null join_key forces records down the insert path.</div><div class="line"> select</div><div class="line">   null, contacts_update_stage.*</div><div class="line"> from</div><div class="line">   contacts_update_stage join contacts_target</div><div class="line">   on contacts_update_stage.id = contacts_target.id</div><div class="line"> where</div><div class="line">   ( contacts_update_stage.email &lt;&gt; contacts_target.email</div><div class="line">     or contacts_update_stage.state &lt;&gt; contacts_target.state )</div><div class="line">   and contacts_target.valid_to is null</div><div class="line">) sub</div><div class="line">on sub.join_key = contacts_target.id</div><div class="line">when matched</div><div class="line"> and sub.email &lt;&gt; contacts_target.email or sub.state &lt;&gt; contacts_target.state</div><div class="line"> then update set valid_to = current_date()</div><div class="line">when not matched</div><div class="line"> then insert</div><div class="line"> values (sub.id, sub.name, sub.email, sub.state, current_date(), null);</div></pre></td></tr></table></figure>
<p>需要注意的是，using语句中对于每个更新的row会输出2个record。这些record会有一个null join key(就会成为一个insert了), 还会有一个valid jonk key(这是一个update)。如果都过去i安眠文章的话，其实有类似于在分区之间移动数据，只不过是使用update而不是delete。</p>
<p>看下93条记录的情况。<br><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/2Hive-Type-2_2-1024x304.png" alt=""></p>
<h4 id="第三种类型"><a href="#第三种类型" class="headerlink" title="第三种类型"></a>第三种类型</h4><p>第二种类型其实挺强大的了，不过比较复杂，而且维度表会无限增长下去。第三种策略中维度表基本跟数据源大小差不多，但是只提供部分历史。</p>
<p>下面我们就只保存上一个版本的纬度值</p>
<p><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/3Hive-Type-3_1.png" alt=""></p>
<p>当update的时候，我们任务就是把当前的版本放到last的值里。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">merge</span> <span class="keyword">into</span></div><div class="line"> contacts_target</div><div class="line"><span class="keyword">using</span></div><div class="line"> contacts_update_stage <span class="keyword">as</span> stage</div><div class="line"><span class="keyword">on</span> stage.id = contacts_target.id</div><div class="line"><span class="keyword">when</span> <span class="keyword">matched</span> <span class="keyword">and</span></div><div class="line"> contacts_target.email &lt;&gt; stage.email</div><div class="line"> <span class="keyword">or</span> contacts_target.state &lt;&gt; stage.state — <span class="keyword">change</span> detection</div><div class="line"> <span class="keyword">then</span> <span class="keyword">update</span> <span class="keyword">set</span></div><div class="line"> last_email = contacts_target.email, email = stage.email, — email history</div><div class="line"> last_state = contacts_target.state, state = stage.state  — state history</div><div class="line"><span class="keyword">when</span> <span class="keyword">not</span> <span class="keyword">matched</span> <span class="keyword">then</span> <span class="keyword">insert</span></div><div class="line"> <span class="keyword">values</span> (stage.id, stage.name, stage.email, stage.email,</div><div class="line"> stage.state, stage.state);</div></pre></td></tr></table></figure>
<p>我们看到相比第二种策略，这种就简单多了。</p>
<p><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/3Hive-Type-3_2.png" alt=""></p>
<h4 id="一个更简单的变化追踪方法"><a href="#一个更简单的变化追踪方法" class="headerlink" title="一个更简单的变化追踪方法"></a>一个更简单的变化追踪方法</h4><p>如果有很多字段需要比较，那么对于变化的探测逻辑会比较笨重。幸运的是，hive引入了一个hash UDF让这个变得简单，可以接收任意数量的参数，然会一个checksum。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">merge into</div><div class="line"> contacts_target</div><div class="line">using</div><div class="line"> contacts_update_stage as stage</div><div class="line">on stage.id = contacts_target.id</div><div class="line">when matched and</div><div class="line"> hash(contacts_target.email, contacts_target.state) &lt;&gt;</div><div class="line">   hash(stage.email, stage.state)</div><div class="line"> then update set</div><div class="line"> last_email = contacts_target.email, email = stage.email, — email history</div><div class="line"> last_state = contacts_target.state, state = stage.state  — state history</div><div class="line">when not matched then insert</div><div class="line"> values (stage.id, stage.name, stage.email, stage.email,</div><div class="line"> stage.state, stage.state);</div></pre></td></tr></table></figure>
<p>好处就是，不管有多少个字段要比较，我们对于代码的修改可以几乎没有。</p>
<h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>SCD管理是数据仓库机器重要的概念，是一个有很多策略和方法实现的子模块。有了ACID MERGE，hive让我们在hadoop上管理SCD变的简单。</p>
<p>参考：<a href="https://zh.hortonworks.com/blog/update-hive-tables-easy-way-2/" target="_blank" rel="external">https://zh.hortonworks.com/blog/update-hive-tables-easy-way-2/</a></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/22/hive2---轻松更新hive表1/" title="hive2---轻松更新hive表1" itemprop="url">hive2---轻松更新hive表1</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-22T09:07:16.000Z" itemprop="datePublished"> 发表于 2017-11-22</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>首先是merge、insert、update、delete。</p>
<p>以前，让hive里的数据持续更新是需要很复杂的成本的，很难去维护与执行。HDP2.6借助hive里的merge语法彻底地简化了数据维护成本，完成了INSERT, UPDATE, DELETE能力。</p>
<p>这个blog会说明怎样解释以下三种问题：</p>
<ul>
<li>hive update，从RDBMS同步数据到hive</li>
<li>更新hive里数据的分区</li>
<li>选择性地mask或者purge数据</li>
</ul>
<h4 id="基础操作：SQL-MERGE-UPDATE-AND-DELETE"><a href="#基础操作：SQL-MERGE-UPDATE-AND-DELETE" class="headerlink" title="基础操作：SQL MERGE, UPDATE AND DELETE"></a>基础操作：SQL MERGE, UPDATE AND DELETE</h4><p>MERGE是SQL 2008标准里的，是一个强大的SQL语句，它可以在同一个statement中inert，update，delete数据。MERGE让两个系统一致性工作变得简单。咱们看一下MERGE的语法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">MERGE INTO &lt;target table&gt;</div><div class="line"> USING &lt;table reference&gt;</div><div class="line">ON &lt;search condition&gt;</div><div class="line"> &lt;merge when clause&gt;...</div><div class="line">WHEN MATCHED [ AND &lt;search condition&gt; ]</div><div class="line">THEN &lt;merge update or delete specification&gt;</div><div class="line">WHEN NOT MATCHED [ AND &lt;search condition&gt; ]</div><div class="line">THEN &lt;merge insert specification&gt;</div></pre></td></tr></table></figure></p>
<p>WHEN MATCHED/WHEN NOT MATCHED语句可以无限量的。</p>
<p>我们也会使用到比较熟悉的UPDATE，语法<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">UPDATE &lt;target table&gt;</div><div class="line">SET &lt;set clause list&gt;</div><div class="line">[ WHERE &lt;search condition&gt; ]</div></pre></td></tr></table></figure></p>
<p>当没必要把insert 和update的数据在一个sql statement里进行合并的时候，就可以使用update了。</p>
<h4 id="保持数据fresh"><a href="#保持数据fresh" class="headerlink" title="保持数据fresh"></a>保持数据fresh</h4><p>在HDP2.6中，需要先做两个工作：</p>
<ul>
<li>开启Hive transaction。</li>
<li>我们table必须是一个transactional table。就是说这个table必须是clustered的，必须是ORCFile存储格式，而且有一个table属性：transactional=true。下面是一个例子：<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">create table customer_partitioned</div><div class="line"> (id int, name string, email string, state string)</div><div class="line"> partitioned by (signup date)</div><div class="line"> clustered by (id) into 2 buckets stored as orc</div><div class="line"> tblproperties(&quot;transactional&quot;=&quot;true&quot;);</div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="例1：HIVE-UPSERT"><a href="#例1：HIVE-UPSERT" class="headerlink" title="例1：HIVE UPSERT"></a>例1：HIVE UPSERT</h4><p>假设我们有一个源数据库，想要load进hadoop来运行ing大批量的分析。这个RDBMS中的数据不断的被添加和修改，而且并没有log告诉你哪些数据有变化【就是说没有binlog】。最简单的处理就是每24小时完整的copy一下这个RDBMS的数据镜像。</p>
<p><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/RDBMS-Source.png" alt=""></p>
<p>下面我们创建table：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">create table customer_partitioned</div><div class="line">(id int, name string, email string, state string)</div><div class="line"> partitioned by (signup date)</div><div class="line"> clustered by (id) into 2 buckets stored as orc</div><div class="line"> tblproperties(&quot;transactional&quot;=&quot;true&quot;);</div></pre></td></tr></table></figure></p>
<p>假设我们的数据在Time = 1的时候是这样的：<br><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/Time-equals-1.png" alt=""></p>
<p>在Time = 2的时候是这样的<br><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/Time-equals-2.png" alt=""></p>
<p>Upsert操作是吧update和insert放在一个操作里，这样我们就不用关心这些数据是不是原来就已经存在于目标table中。MERGE就是用来做这个事情的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">merge into customer_partitioned</div><div class="line"> using all_updates on customer_partitioned.id = all_updates.id</div><div class="line"> when matched then update set</div><div class="line">   email=all_updates.email,</div><div class="line">   state=all_updates.state</div><div class="line"> when not matched then insert</div><div class="line">   values(all_updates.id, all_updates.name, all_updates.email,</div><div class="line">   all_updates.state, all_updates.signup);</div></pre></td></tr></table></figure></p>
<p>注意我们的两个when条件语句是用来管理update或者insert的。在merge过后，这个managed table就与Time=2的staged Table完全一样了，而且所有数据也都在其对应的分区中。</p>
<h4 id="例2：更新hive-partition"><a href="#例2：更新hive-partition" class="headerlink" title="例2：更新hive partition"></a>例2：更新hive partition</h4><p>hive中很多会用日期作为partition策略。这样可以简化数据加载，提升性能。只是有时我们偶尔会出现数据进入错误的分区的情形。例如，假设用户数据是由一个第三方提供的，里面包含一个用户的singup日期。如果这个第三方数据提供者提供的数据开始有问题，后面又修正了，那么前面的在错误分区里的数据就应该被清除了。</p>
<p><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/update-hive-partitions.png" alt="初始数据"></p>
<p><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/second-load.png" alt="修复后的数据"></p>
<p>注意到ID为2的数据第一次跟第二次的signup日期是不一样的，这就需要更新2017-01-08分区，从里面把它删除，然后把它加入到2017-01-10里面去。</p>
<p>在MERGE出现之前，基本不可能管理这些分区裱花的。Hive的MERGE statement不是原生支持更新partition key，但是有一个小的技巧。 We introduce a delete marker which we set any time the partition keys and UNION this with a second query that produces an extra row on-the-fly for each of these non-matching records.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">merge into customer_partitioned</div><div class="line"> using (</div><div class="line">-- Updates with matching partitions or net new records.</div><div class="line">-- 更新符合分区的或者</div><div class="line">select</div><div class="line">  case</div><div class="line">       when all_updates.signup &lt;&gt; customer_partitioned.signup then 1</div><div class="line">       else 0</div><div class="line">     end as delete_flag,</div><div class="line">     all_updates.id as match_key,</div><div class="line">     all_updates.* from</div><div class="line">    all_updates left join customer_partitioned</div><div class="line">   on all_updates.id = customer_partitioned.id</div><div class="line">      union all</div><div class="line"></div><div class="line"> -- Produce new records when partitions don’t match.</div><div class="line"> -- 分区不匹配的时候，生成新的record</div><div class="line">     select 0, null, all_updates.*</div><div class="line">     from all_updates, customer_partitioned where</div><div class="line">     all_updates.id = customer_partitioned.id</div><div class="line">     and all_updates.signup &lt;&gt; customer_partitioned.signup</div><div class="line"> ) sub</div><div class="line">on customer_partitioned.id = sub.match_key</div><div class="line"> when matched and delete_flag=1 then delete</div><div class="line"> when matched and delete_flag=0 then</div><div class="line">   update set email=sub.email, state=sub.state</div><div class="line"> when not matched then</div><div class="line">   insert values(sub.id, sub.name, sub.email, sub.state, sub.signup);</div></pre></td></tr></table></figure></p>
<p>在MERGE处理过这个managed table之后，它就跟源数据表完全一致了。虽然过程中有分区的修改，但是这是一个操作，是原子、且独立的操作。</p>
<h4 id="例3：mask或者purge-hive的数据"><a href="#例3：mask或者purge-hive的数据" class="headerlink" title="例3：mask或者purge hive的数据"></a>例3：mask或者purge hive的数据</h4><p>假设有一天你们公司的安全部门过来，让我们把某个用户的所有数据进行mask或者purge操作。那么我们就需要花费很长的时间对很多收到影响的分区进行数据重写。</p>
<p>假设有一个contact table<br><img src="https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/contracts-table.png" alt=""></p>
<p>我们对应的hive表是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">create table contacts</div><div class="line"> (id int, name string, customer string, phone string)</div><div class="line"> clustered by (id) into 2 buckets stored as orc </div><div class="line">tblproperties(&quot;transactional&quot;=&quot;true&quot;);</div></pre></td></tr></table></figure></p>
<p>安全部门提出以下要求：</p>
<h5 id="把MaxLeads的所有的电话号码mask掉"><a href="#把MaxLeads的所有的电话号码mask掉" class="headerlink" title="把MaxLeads的所有的电话号码mask掉"></a>把MaxLeads的所有的电话号码mask掉</h5><p>我们可以使用hive内置的mask方法<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">update contacts set phone = mask(phone) where customer = &apos;MaxLeads&apos;;</div></pre></td></tr></table></figure></p>
<h5 id="把所有LeadMax的记录都purge掉"><a href="#把所有LeadMax的记录都purge掉" class="headerlink" title="把所有LeadMax的记录都purge掉"></a>把所有LeadMax的记录都purge掉</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">delete from contacts where customer = &apos;LeadMax&apos;;</div></pre></td></tr></table></figure>
<h5 id="把给定id列表的所有记录都删掉"><a href="#把给定id列表的所有记录都删掉" class="headerlink" title="把给定id列表的所有记录都删掉"></a>把给定id列表的所有记录都删掉</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">delete from contacts where id in ( select id from purge_list );</div></pre></td></tr></table></figure>
<h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>hive的MERGE和ACID事务让hive里的数据管理工作变得简单、强大、而且兼容于现有的EDW平台。</p>
<p>参考：<a href="https://zh.hortonworks.com/blog/update-hive-tables-easy-way/" target="_blank" rel="external">https://zh.hortonworks.com/blog/update-hive-tables-easy-way/</a></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/22/实时系统的特性/" title="实时系统的特性" itemprop="url">实时系统的特性</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-22T06:20:41.000Z" itemprop="datePublished"> 发表于 2017-11-22</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h4 id="关键特性"><a href="#关键特性" class="headerlink" title="关键特性"></a>关键特性</h4><p>首先，各个微服务之间应该是解耦的，最好通过stream进行结构。</p>
<ul>
<li>持久化，把数据流暂存起来，供消费。具体持久化的时间，可以根据自己的业务处理</li>
<li>高性能，最快的处理每个环节，最大化单个处理单元的吞吐量</li>
<li>易扩展性，主要是易于应对数据量的海量增加</li>
</ul>
<p>参考：<a href="https://www.youtube.com/watch?v=4lUxf5pzAHs" target="_blank" rel="external">https://www.youtube.com/watch?v=4lUxf5pzAHs</a></p>
<h4 id="Move-from-State-to-Flow"><a href="#Move-from-State-to-Flow" class="headerlink" title="Move from State to Flow"></a>Move from State to Flow</h4><p>把微服务中的state转移到flow中去。</p>
<p>如果多个微服务都更新自己的state到同一个本地存储【比如mysql】，那么这个mysql就会变成一个比较危险的地方。如果我们单个微服务要修改mysql的配置，其他几个服务也要受到影响。</p>
<p>但是我们期望，每个微服务自己有修改的时候，相互之间没有影响，每个微服务的变化都是独立的。假设有A,B,C三个微服务，如果给C单独的mysql，那么c对于A,B就是完全独立的。然后针对A,B,C的更新操作全部看作business event放入一个queue，然后再由consumer从queue里消费event，针对不同的event进行处理。</p>
<p>参考：<a href="https://www.youtube.com/watch?v=_xqK0Es9zP4" target="_blank" rel="external">https://www.youtube.com/watch?v=_xqK0Es9zP4</a></p>
<h4 id="财政部门的flow数据架构"><a href="#财政部门的flow数据架构" class="headerlink" title="财政部门的flow数据架构"></a>财政部门的flow数据架构</h4><table>
<thead>
<tr>
<th>state</th>
<th>flow</th>
</tr>
</thead>
<tbody>
<tr>
<td>共享的DB</td>
<td>不共享任何，只共享flow</td>
</tr>
<tr>
<td>复杂的语义，需要小心的使用事务</td>
<td>好的沟通规范</td>
</tr>
<tr>
<td>人们较熟悉</td>
<td>生活中的真实流程</td>
</tr>
<tr>
<td>控制流 + state更新</td>
<td>控制流 + offset/message</td>
</tr>
</tbody>
</table>
<p>bank1和bank2都监听同一个message queue，处理过后持久化到自己的私有db。</p>
<p>参考：<a href="https://www.youtube.com/watch?v=vG2qxjkqOgA" target="_blank" rel="external">https://www.youtube.com/watch?v=vG2qxjkqOgA</a></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/22/Flink特性/" title="Flink特性" itemprop="url">Flink特性</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-22T06:13:34.000Z" itemprop="datePublished"> 发表于 2017-11-22</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>stateful operator可以追溯到前面的状态，例如count操作</p>
<p>stateful</p>
<ul>
<li>聚合操作</li>
<li>complex event processing</li>
<li>ML pattern</li>
</ul>
<p>stateless</p>
<ul>
<li>数据抽取</li>
<li>数据清洗</li>
<li>stateless的转化</li>
</ul>
<h4 id="queryable-state"><a href="#queryable-state" class="headerlink" title="queryable state"></a>queryable state</h4><p>如果设定了一个小时的窗口，在到达一小时之前这个数据一般是不可查询的。但是有了 queryable 是state，我们可以在未到时间窗口的时候，就进行查询计算。</p>
<h4 id="不想中断数据处理，但又想"><a href="#不想中断数据处理，但又想" class="headerlink" title="不想中断数据处理，但又想"></a>不想中断数据处理，但又想</h4><ul>
<li>修改worker的数量</li>
<li>迁移到另一个集群</li>
<li>修复代码bug</li>
<li>升级flink</li>
<li>测试不同的算法</li>
<li>……</li>
</ul>
<p>以上这些对于stateless任务其实是很简单的，直接操作就可以。停掉，重启。对于statefule的任务，就比较棘手。对于添加worker的需求，state需要reload或者redistribute。</p>
<p>Flink方案：savepoint。</p>
<ul>
<li>创建savepoint</li>
<li>修改</li>
<li>从savepoint重启</li>
</ul>
<p>对于session window的state也是很棘手的，Flink1.1会支持这个场景。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/21/flink的容错机制/" title="flink的容错机制" itemprop="url">flink的容错机制</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-21T08:44:02.000Z" itemprop="datePublished"> 发表于 2017-11-21</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Flink容错机制保证了，即便出现失败，程序的state也最终reflect每条记录exactly once，也可以降级到at least once。</p>
<p>这个容错机制持续的描绘出分布式数据流的snapshot。对于少有state的流式应用来说，这些snapshot是非常轻量的，可以在不影响到性能的前提下快速完成。流式应用的state会被存储在配置好的地方(比如master节点、hdfs等)。</p>
<p>如果程序失败了(机器原因、网络原因、软件问题等)，Flink会踢掉分布式数据流。然后系统会重启所有的operator，然后把他们重置到最近的成功的checkpoint。输入流也被重置到这个state snapshot的点。作为重新启动的并行dataflow的一部分，已经处理过的所有的记录都保证不属于前一个checkpoint state里的一部分。</p>
<p>注意：默认checkpoint是未启用的。</p>
<p>注意：要完全保证这个机制，需要数据流的source(一般是消息队列或者broker)能够支持重置位移。例如kafka就可以重置位移。</p>
<p>注意：以你为Flink的checkpoints是通过分布式snapshot实现的，我们可以交换使用snapshot和checkpoint这两个词语。</p>
<h2 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h2><p>Flinke容错机制的核心就是为分布式的数据流和操作状态进行snapshot。这些snapshot作为一致性的checkpoint供错误恢复使用。Flink执行snapshot的机制在<a href="http://arxiv.org/abs/1506.08603" target="_blank" rel="external"> “Lightweight Asynchronous Snapshots for Distributed Dataflows”.</a>有介绍。是由<a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/chandy.pdf" target="_blank" rel="external">Chandy-Lamport algorithm</a>实现的，这是一种分布式snapshot方法，而且兼容Flink的执行模型。</p>
<h4 id="Barrier栅栏"><a href="#Barrier栅栏" class="headerlink" title="Barrier栅栏"></a>Barrier栅栏</h4><p>Flink分布式snapshot的核心元素是stream barrier。这些栅栏被注入到data stream和flow当中作为data stream的一部分存在。barrier永远不会超过记录，flow是严格线性的。barrier负责把data stream中的数据进行切分，切分为两部分，一部分到当前的snapshot中，然后另外一部分是下一个snapshot里的。Each barrier carries the ID of the snapshot whose records it pushed in front of it. barrier并不会中断数据流处理，十分轻量。不同snampshot的多个barrier可能同时存在于stream中，这就是说可能会多个snapshot并发执行。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.3/fig/stream_barriers.svg" alt=""></p>
<p>Stream barrier在stream source被注入到并发的data flow中。snapshot n的barrier的点Sn被注入的位置是source stream知道覆盖到数据的snapshot【The point where the barriers for snapshot n are injected (let’s call it Sn) is the position in the source stream up to which the snapshot covers the data】。例如在kafka中，这个位置就是当前分区上一次访问的记录的offset。这个位置Sn就被汇报给checkpoint coordinator(Flink里就是JobManager)。</p>
<p>然后barrier继续向下执行。当一个中间oerator抽取到snapshot n的barrier时，它发射一个snapshot n的barrier给它所有的outgoing stream。一旦一个sink operator(DAG的最后)收到barrier n的时候，它就向checkpoint coordinator确认ack snapshot n。所有的sink都ack了这个snapshot的时候，它就被认为已经成功了。</p>
<p>snapshot n完成之后，job再也不会请求Sn之前的数据记录了，因为这些数据记录已经通过了整个数据流处理拓扑。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.3/fig/stream_aligning.svg" alt=""></p>
<p>接收多个input stream的operator必须排列多个input stream的snapshot barriers。上图内容</p>
<ul>
<li>operator接到单个input stream的snapshot barrier n的时候，不能立即处理这个stream的数据，需要等着其他input stream的barrier n也到达的时候才行。否则，它会把snapshot n的数据记录和snapshot n+1的数据记录弄混了。</li>
<li>已经汇报barrier n的input stream暂时被搁置。收到的数据记录暂时不处理，而是放进一个input buffer</li>
<li>最后一个stream也收到barrier n的时候，这个operator就发射所有pending的outing 记录，然后自己也发射snapshot n的barrier。</li>
<li>最后，它恢复处理所有input stream的数据记录，处理在此之前的input buffer里的数据记录，然后处理stream的记录。</li>
</ul>
<h4 id="state"><a href="#state" class="headerlink" title="state"></a>state</h4><p>如果operator包含任意形式的state，这个state就必须成为snapshot的一部分。operator statue可能是下面的几种：</p>
<ul>
<li>user-defined state。通过转化方法(例如map、filter)直接创建与修改的state。</li>
<li>system state。例如operator计算的一部分，数据缓存等。典型的例子是window buffer，在window buffer中通常收集聚合数据记录，直到window的计算或者被清空。</li>
</ul>
<p>operator在收到了它所有input stream的barrier n，并且没有发送barrier n给它的所有output stream之前，snapshot它的state。在这个时间点，barrier之前的所有的数据记录导致的state更新已经完成，并且没有根据已经执行的的barrier之后的数据记录进行任何更新。因为snapshot 的state可能会很大，它可以被存储在一个可配置的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/ops/state_backends.html" target="_blank" rel="external">后端</a>。默认情况下，是放在JobManager的内存里，对于生产环境，最好放在可靠的存储介质上，例如HDFS。在state被存储之后，operator ack这个checkpoint，发送这个snapshot barrier到output stream中。</p>
<p>现在snapshot包含了：</p>
<ul>
<li>对于每个并行的stream data source，snapshot开始的时候stream中的位置信息或者offset</li>
<li>对于每个operator，一个指向snapshot state仓库的pointer</li>
</ul>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.3/fig/checkpointing.svg" alt="checkpoint流程图"></p>
<h2 id="Exactly-Once还是At-least-once"><a href="#Exactly-Once还是At-least-once" class="headerlink" title="Exactly Once还是At least once"></a>Exactly Once还是At least once</h2><p>对于streaming program来说alignment操作可能会造成一些延迟。通差，这部分延迟是早毫秒级的，但是我们见过一些非常突出的延迟。对于那些坚持要求低延迟的应用，Flink有一个开关可以关闭checkpoint过程中的alignment操作。checkpoint snapshot仍然很快。</p>
<p>当alignment被跳过后，即便一些checkpoint barrier n已经到了，operator也要继续处理所有的输入。这样的话，在snapshot n完结之前，operator也会处理属于 snapshot n+1的数据。再回复的时候，这些记录就会被重复处理，因为他们都被记录在了snapshot n的state snapshot里，所以也会作为checkpoint n之后的数据被replay。</p>
<p>注意：alignment只会发生在具有多个前辈(join)，或者多个sender(在一个stream被repartition/shuffle)的operator。因此，对于只包含并行处理操作(map, flatmap, filter等)的dataflow来说，at least once模式下其实也是exactly once的。</p>
<h2 id="异步state-snapshot"><a href="#异步state-snapshot" class="headerlink" title="异步state snapshot"></a>异步state snapshot</h2><p>注意上面描述的机制意味着operator在奥村他们的snapshot state到state backend的时候，需要停止处理输入的记录。这个同步的state snapshot操作会造成一个小的时间延迟。</p>
<p>如果让这个存储操作异步执行的话，就能让operator继续执行下面的步骤了。要这样的话，operator必循能够生成一个state对象，这个state 对象能够被存储，而且后面operator state的更新不会影响到它。例如，copy-on-write数据结构，rocksdb里有这种操作。</p>
<p>接收到所有input stream的checkpoint barrier后，operator开始异步snapshot，copy他的state。它会马上发送barrier到它的output，然后继续下面的数据流处理。一旦后台的copy进程完成后，它就会向checkpoint coordinator(JobManager) ack这个checkpoint。 这个checkpoint现在只在所有的sink都收到barrier后，所有的statefule operator都ack他们完成了backup后(这个可能比barrier到达sink还要慢)才算完成。</p>
<h2 id="recovery"><a href="#recovery" class="headerlink" title="recovery"></a>recovery</h2><p>在这个机制下的recovery很直接：一旦发生失败，Flink选择最新的完成的checkpoint k。然后这个system重新部署整个的分布式数据流，然后给每个operator这个snapshot k对应的state，因为这也是checkpoint k的一部分。而且需要从数据源的Sk的位置开始读取数据流。如果是kafka的话，就是从offset为Sk的地方开始抽取数据。</p>
<p>如果state是增量snapshot的，那么operator要使用最新full snapshot的state，然后把后续的更新操作应用到这个state上。</p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/dev/restart_strategies.html" target="_blank" rel="external">更多</a></p>
<h2 id="operator-snapshot的实现"><a href="#operator-snapshot的实现" class="headerlink" title="operator snapshot的实现"></a>operator snapshot的实现</h2><p>当operator执行snapshot的时候，有两个部分：同步的和异步的。</p>
<p>operator和state backend是以java FutureTask的形式提供他们的snapshot的。这个task包含了同步部分已完成的state，但是异步部分可能还在pending状态。异步部分后面会被这个checkpoint的一个后台线程执行。</p>
<p>使用纯同步方式的operator checkpint会返回一个已经完成了的FutrueTask。如果异步操作需要被执行，就执行FutrueTask的run方法。</p>
<p>这些task是可以被cancel的，这样stream和其他的资源消费句柄就可以被release了。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/21/flink的window/" title="flink的window" itemprop="url">flink的window</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-21T07:28:54.000Z" itemprop="datePublished"> 发表于 2017-11-21</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>滑动窗口,sliding windows，比如我们每30s统计一下上一分钟的和。<br><img src="https://flink.apache.org/img/blog/window-intro/window-sliding-window.png" alt=""></p>
<p>当只有一个窗口处理器的时候，我们就只能串行处理一个数据流。每个流里的书都要去向某个指定的window。在Flink中对于Windows on a full stream are【一个完整的流的窗口】 称为 AllWindows。对很多app来说，数据流都要分发进入多个逻辑流，然后会有window operator处理每个逻辑流。假设我们从多个交通传感器获取交通工具的流量，每个交通传感器都监控不同地址的流量。我们可以把这些信息流通过交通传感器的id进行分组，然后分别并发的计算每个交通传感器所在位置的流量信息。在Flink中，我们把这种partitioned window叫做simple window，因为这是对分布式数据流很常见的处理方式。下图展示了一个通过(sernsorID, count)的流进行数据收集的滚动窗口<br><img src="https://flink.apache.org/img/blog/window-intro/windows-keyed.png" alt=""></p>
<p>通常，一个window在无穷的数据流中定义了一组有穷数据。这组数据可以是基于时间、计数、时间与技术结合、自定义的一些逻辑去分window。Flink的DataStream API提供了简洁的操作供常用的窗口操作，也留了接口让用户提供自定义的分窗口的逻辑。下面我们详细看一下基于时间与计数的窗口机制。</p>
<h2 id="基于时间的窗口"><a href="#基于时间的窗口" class="headerlink" title="基于时间的窗口"></a>基于时间的窗口</h2><p>下面是一个每分钟滚动一次的窗口，对所有的数据执行某个函数操作。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">// (sensorId, carCnt)形式的数据流</div><div class="line">val vehicleCnts: DataStream[(Int, Int)] = ...</div><div class="line"></div><div class="line">// 0，1是在数据中的位置</div><div class="line">val tumblingCnts: DataStream[(Int, Int)] = vehicleCnts</div><div class="line">  // 通过sensorId分区</div><div class="line">  .keyBy(0) </div><div class="line">  // 1分钟的窗口时间</div><div class="line">  .timeWindow(Time.minutes(1))</div><div class="line">  // 计算carCnt的和</div><div class="line">  .sum(1) </div><div class="line"></div><div class="line">val slidingCnts: DataStream[(Int, Int)] = vehicleCnts</div><div class="line">  .keyBy(0) </div><div class="line">  // 每30秒触发一次1分钟的数据窗口的执行</div><div class="line">  .timeWindow(Time.minutes(1), Time.seconds(30))</div><div class="line">  .sum(1)</div></pre></td></tr></table></figure></p>
<p>还有一个时间的概念我们要说明</p>
<ul>
<li>processing time。窗口是根据当前主机的1分钟去构建与计算窗口内数据的。</li>
<li>event time。event产生时的时间。相比processing time更好一些</li>
<li>Ingestion time。是processing  time和event time的杂交品种。一旦数据到达，就把当前机器的时间戳赋给这个数据记录，然后基于这个时间戳，使用event time去持续处理。</li>
</ul>
<h2 id="基于计数的窗口"><a href="#基于计数的窗口" class="headerlink" title="基于计数的窗口"></a>基于计数的窗口</h2><p>一个100个event作为窗口的程序。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">// (sensorId, carCnt)形式的数据流</div><div class="line">val vehicleCnts: DataStream[(Int, Int)] = ...</div><div class="line"></div><div class="line">val tumblingCnts: DataStream[(Int, Int)] = vehicleCnts</div><div class="line">  // 用sensorId分区</div><div class="line">  .keyBy(0)</div><div class="line">  // 100个数据为一个窗口</div><div class="line">  .countWindow(100)</div><div class="line">  .sum(1)</div><div class="line"></div><div class="line">val slidingCnts: DataStream[(Int, Int)] = vehicleCnts</div><div class="line">  .keyBy(0)</div><div class="line">  // 100个数据作为一个窗口，每10个触发一次窗口处理</div><div class="line">  .countWindow(100, 10)</div><div class="line">  .sum(1)</div></pre></td></tr></table></figure></p>
<h2 id="深入了解"><a href="#深入了解" class="headerlink" title="深入了解"></a>深入了解</h2><p>Flink内置的基于时间、计数的窗口已经覆盖了大多数的应用，但是对于一些需要自定义窗口划分逻辑的，需要使用DataStream API暴露的接口，这些接口给了窗口构建与计算的很有条理的控制方式。</p>
<p>下图是Flink窗口机制的详细图<br><img src="https://flink.apache.org/img/blog/window-intro/window-mechanics.png" alt=""></p>
<p>到达window operator的数据会先发给<code>WindowAssigner</code>. <code>WindowAssigner</code>把数据分配给一个或者多个window，也有可能要创建新的window。一个<code>Window</code>是一个一组数据、元数据(对于<code>TimeWindow</code>来说是起止时间)的唯一标识符。注意数据是可以被加入到多个window的，也就是说可能会同时存在多个window。</p>
<p>每个window拥有一个<code>Trigger</code>，它来决定当前window什么时候计算或者清空。这个trigger在每条数据到来的时候都会检验，如果前面注册的timer超时就会触发操作：执行计算、清空窗口、先计算再清空。<strong>如果只是触发计算，那么所有的数据就还留在window里</strong>，下次触发的时候还可以计算。<strong>一个window在被清空之前一直都可以被计算，这也代表着内存占用</strong>。</p>
<p>计算函数接收window的所有数据，输出一个或多个结果。DataStream API接受不同类型的计算函数，包括一些预定义的sum、min、max，ReduceFunction、FlodFunciton、WindowFunction等。最常见的是<code>WindowFunction</code>，它接收window对象的元数据，一组window对象，window key(如果是分区的window)作为参数。</p>
<p>这些组件构成了Flink的窗口机制。我们现在一步步看一下怎样实现自定义窗口逻辑。我们以DataStream[IN]类型的stream开始，用一个key选择器函数来抽取key，获得一个Keydtream[IN, KEY].<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">val input: DataStream[IN] = ...</div><div class="line"></div><div class="line">val keyed: KeyedStream[IN, KEY] = input</div><div class="line">  .keyBy(myKeySel: (IN) =&gt; KEY)</div><div class="line"></div><div class="line"></div><div class="line">// 通过WindowAssigner创建一个分窗口的stream。WindowAssigner 有默认的Trigger实现</div><div class="line">var windowed: WindowedStream[IN, KEY, WINDOW] = keyed</div><div class="line">  .window(myAssigner: WindowAssigner[IN, WINDOW])</div><div class="line">  </div><div class="line">// 不适用WindowAssigner默认的trigger</div><div class="line">windowed = windowed</div><div class="line">  .trigger(myTrigger: Trigger[IN, WINDOW])</div><div class="line"></div><div class="line">// 指定可选的evictor</div><div class="line">windowed = windowed</div><div class="line">  .evictor(myEvictor: Evictor[IN, WINDOW])</div><div class="line"></div><div class="line">// 最后，把window function传递给windowed stream</div><div class="line">val output: DataStream[OUT] = windowed</div><div class="line">  .apply(myWinFunc: WindowFunction[IN, OUT, KEY, WINDOW])</div></pre></td></tr></table></figure></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/20/centos上搭建ftp服务器/" title="centos上搭建ftp服务器" itemprop="url">centos上搭建ftp服务器</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-20T06:46:02.000Z" itemprop="datePublished"> 发表于 2017-11-20</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>首先安装服务：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install -y vsftpd</div></pre></td></tr></table></figure></p>
<p>创建只读的dataman用户：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">useradd -s /sbin/nologin dataman</div><div class="line">passwd dataman</div></pre></td></tr></table></figure></p>
<p>编辑配置文件<code>/etc/vsftpd/vsftpd.conf</code>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"># 修改默认端口</div><div class="line">listen_port=6888</div><div class="line"></div><div class="line"># 禁止匿名登陆</div><div class="line">anonymous_enable=NO</div><div class="line"></div><div class="line"># 指定用户单独的配置信息所在目录</div><div class="line">user_config_dir=/var/ftp</div><div class="line"></div><div class="line"># 不许用户登陆后切换目录</div><div class="line">chroot_local_user=YES</div></pre></td></tr></table></figure></p>
<p>然后到<code>/var/ftp</code>下新建dataman用户的ftp配置文件，这里只需要指定他的root目录就好了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">local_root=/server/files</div></pre></td></tr></table></figure></p>
<p>参考</p>
<ul>
<li><a href="https://jasonhzy.github.io/2016/03/11/linux-ftp/" target="_blank" rel="external">https://jasonhzy.github.io/2016/03/11/linux-ftp/</a></li>
<li><a href="http://cn.linux.vbird.org/linux_server/0410vsftpd.php" target="_blank" rel="external">http://cn.linux.vbird.org/linux_server/0410vsftpd.php</a></li>
</ul>
<p>坑</p>
<p>我们的网络原因导致，测试环境要连接线上的ftp服务器的话，需要通过一层运维提供的HAProxy代理。</p>
<p>这就引出了ftp服务器主动传输与被动传输的概念区别。</p>
<p>FTP协议有两种工作方式：PORT方式和PASV方式，中文意思为主动式和被动式。</p>
<p>PORT（主动）方式的连接过程是：客 户端向服务器的FTP端口（默认是21）发送连接请求，服务器接受连接，建立一条命令链路。当需要传送数据时，客户端在命令链路上用PORT命令告诉服务 器：“我打开了XXXX端口，你过来连接我”。于是服务器从20端口向客户端的XXXX端口发送连接请求，建立一条数据链路来传送数据。</p>
<p>PASV（被动）方式的连接过程是：客 户端向服务器的FTP端口（默认是21）发送连接请求，服务器接受连接，建立一条命令链路。当需要传送数据时，服务器在命令链路上用PASV命令告诉客户 端：“我打开了XXXX端口，你过来连接我”。于是客户端向服务器的XXXX端口发送连接请求，建立一条数据链路来传送数据。</p>
<h2 id="概括："><a href="#概括：" class="headerlink" title="概括： "></a>概括： </h2><p>主动模式：服务器向客户端敲门，然后客户端开门<br>被动模式：客户端向服务器敲门，然后服务器开门</p>
<p>所以，如果你是如果通过代理上网的话，就不能用主动模式，因为服务器敲的是上网代理服务器的门，而不是敲客户端的门<br>而且有时候，客户端也不是轻易就开门的，因为有防火墙阻挡，除非客户端开放大于1024的高端端口</p>
<p>vsftpd服务器端修改配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># passive</div><div class="line">tcp_wrappers=YES</div><div class="line">pasv_promiscuous=NO</div><div class="line"># 这个比较关键，10.103.70.27是我们的haproxy所在的IP</div><div class="line">pasv_address=10.103.70.27</div><div class="line">port_enable=YES</div><div class="line">port_promiscuous=NO</div><div class="line">pasv_enable=YES</div><div class="line">pasv_min_port=10000</div><div class="line">pasv_max_port=10010</div></pre></td></tr></table></figure></p>
<p>同时，HAProxy也需要配置到这些端口范围<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">listen ftp</div><div class="line">    bind *:6888,*:10000-10010</div><div class="line">    mode tcp</div><div class="line">    server ftpserver 10.2.19.62 check inter 3000 port 6888</div></pre></td></tr></table></figure></p>
<ul>
<li><a href="http://blog.sina.com.cn/s/blog_7f1d56650102v57p.html" target="_blank" rel="external">http://blog.sina.com.cn/s/blog_7f1d56650102v57p.html</a></li>
<li><a href="http://www.cnblogs.com/exclm/archive/2009/05/08/1452893.html" target="_blank" rel="external">http://www.cnblogs.com/exclm/archive/2009/05/08/1452893.html</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_5cdb72780100jwjt.html" target="_blank" rel="external">http://blog.sina.com.cn/s/blog_5cdb72780100jwjt.html</a></li>
<li><a href="https://serverfault.com/questions/441721/ftp-through-haproxy" target="_blank" rel="external">https://serverfault.com/questions/441721/ftp-through-haproxy</a></li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/16/ETL日常调度任务类型的思考/" title="ETL日常调度任务类型的思考" itemprop="url">ETL日常调度任务类型的思考</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-16T07:27:27.000Z" itemprop="datePublished"> 发表于 2017-11-16</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>对于有些需要等待上游非同质类型、而且是外部任务的任务方案：</p>
<h2 id="信号灯"><a href="#信号灯" class="headerlink" title="信号灯"></a>信号灯</h2><p>即所有的每个任务在完成之后，都设置一个信号灯，然后后面的任务需要此信号灯满足某个信号的时候才能触发执行。</p>
<p>信号灯的查看方式可以有多种：</p>
<ul>
<li>数据库访问，上游直接修改数据库，下游直接轮询数据库</li>
<li>rest接口访问，上有直接通过中心接口修改数据库，下游轮询一个中心接口</li>
<li>发布订阅模式，中间件设置eventbus</li>
</ul>
<p>执行：sql查询、接口与状态确认</p>
<h2 id="提供shell"><a href="#提供shell" class="headerlink" title="提供shell"></a>提供shell</h2><p>具体咋依赖，全都自己去写，这里啥也不限制，而且啥也不伺候</p>
<p>安全系数低</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/15/druid设计/" title="druid设计" itemprop="url">druid设计</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-15T06:28:59.000Z" itemprop="datePublished"> 发表于 2017-11-15</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="segment"><a href="#segment" class="headerlink" title="segment"></a>segment</h2><p>Druid的索引是存在segment文件中的，segment文件是按照时间分区的。一个segment文件对应一个时间间隔，时间间隔根据配置项<code>granularitySpec</code>里的<code>segmentGranularity</code>进行配置。推荐segment文件大小设置在300~700M之间。如果你的segment文件太大，那么请考虑修改时间间隔，或者为数据做分区，修改<code>partitioningSpec</code>的<code>targetPartitionSize</code>参数(可以试试五百万行)。</p>
<h4 id="文件数据结构"><a href="#文件数据结构" class="headerlink" title="文件数据结构"></a>文件数据结构</h4><p>segment是列式存储的：每一列都在不同的数据结构中。每个列都分开存储，druid就可以只访问查询应用到的列的数据。有三个基本的列类型：timestamp、维度、metric。</p>
<p><img src="http://druid.io/docs/img/druid-column-types.png" alt="实例"></p>
<p>timestamp和metric列比较简单：都是int或者float数组，使用LZ4算法压缩。一个query只要知道他需要查询那些行，就解压相关列的这部分文件，抽取对应的行，然后执行聚合计算操作即可。</p>
<p>dimension列有些不同，它要支持filter和groupby操作，所以需要下面三个数据结构</p>
<ul>
<li>一个字典，把值映射成int类型的id</li>
<li>使用上面字典编码的列值的list</li>
<li>列中每个不同的列指，都要弄一个bitmap对应所有的行，说明哪些行带有这个列指</li>
</ul>
<p>把原本的值映射成int的id是为了节省空间。上面第三个里的bitmap也就是倒排索引(inverted indexes)可以提供快速的过滤工作。最后，上面第二个结构里的值，是用来处理group by和topN拆线呢的。也就是说，基于filter的单独聚合指标不要要接触到第二个数据结构中的维度值。</p>
<p>基于上图中的数据，看一下例子，下面是针对列<code>Page</code>的<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">1: 映射编码的字典</div><div class="line">  &#123;</div><div class="line">    &quot;Justin Bieber&quot;: 0,</div><div class="line">    &quot;Ke$ha&quot;:         1</div><div class="line">  &#125;</div><div class="line"></div><div class="line">2: 按照1中映射后，这一列的字段值</div><div class="line">  [0,</div><div class="line">   0,</div><div class="line">   1,</div><div class="line">   1]</div><div class="line"></div><div class="line">3: 每一个或者说每一种列值都有自己的Bitmaps</div><div class="line">  value=&quot;Justin Bieber&quot;: [1,1,0,0]</div><div class="line">  value=&quot;Ke$ha&quot;:         [0,0,1,1]</div></pre></td></tr></table></figure></p>
<p>注意bitmap数据结构与前面个不同，前两个是随数据量线性增长的，而bitmap是数据量 * 每列各种值的个数。</p>
<h4 id="多值的列"><a href="#多值的列" class="headerlink" title="多值的列"></a>多值的列</h4><p>假设<code>Page</code>的第二行数据为<code>Ke$ha,Justin Bieber</code>，那么数据结构变化为下面：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">1: Dictionary that encodes column values</div><div class="line">  &#123;</div><div class="line">    &quot;Justin Bieber&quot;: 0,</div><div class="line">    &quot;Ke$ha&quot;:         1</div><div class="line">  &#125;</div><div class="line"></div><div class="line">2: Column data</div><div class="line">  [0,</div><div class="line">   [0,1],  &lt;--Row value of multi-value column can have array of values</div><div class="line">   1,</div><div class="line">   1]</div><div class="line"></div><div class="line">3: Bitmaps - one for each unique value</div><div class="line">  value=&quot;Justin Bieber&quot;: [1,1,0,0]</div><div class="line">  value=&quot;Ke$ha&quot;:         [0,1,1,1]</div><div class="line">                            ^</div><div class="line">                            |</div><div class="line">                            |</div><div class="line">    Multi-value column has multiple non-zero entries</div></pre></td></tr></table></figure></p>
<h4 id="命名约定"><a href="#命名约定" class="headerlink" title="命名约定"></a>命名约定</h4><p>segment文件的标识符一般是由数据源、开始时间、结束时间、版本构成的。如果数据在某个时间范围外还sharded了，那么也会带有一个分区数字。</p>
<p>例子：datasource_intervalStart_intervalEnd_version_partitionNum</p>
<h4 id="segment组件"><a href="#segment组件" class="headerlink" title="segment组件"></a>segment组件</h4><p>一个segment由几个文件组成</p>
<ul>
<li>version.bin。  4个字节，代表segment的version。</li>
<li>meta.smoosh。带有其他smoosh文件内容元数据(文件名、offset)的文件。</li>
<li>xxxx.smoosh。多个这种文件，都是二进制数据。</li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/15/hive2版本亮点/" title="hive2版本亮点" itemprop="url">hive2版本亮点</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-15T02:53:01.000Z" itemprop="datePublished"> 发表于 2017-11-15</time>
    
  </p>
</header>
    <div class="article-content">
        
        <ul>
<li>LLAP。</li>
</ul>
<p>Live Long and Process智能将数据缓存到多台机器的内存中，并允许所有客户端共享这些缓存的数据，同时保留了弹性伸缩能力。开启LLAP后，性能相比1版本提升25倍。</p>
<p>LLAP提供了一个高级的执行模式，他启用一个长时间存活的守护程序去和HDFS DataNode直接交互，也是一个紧密集成的DAG框架。这个守护程序中加入了缓存、预抓取、查询过程和访问控制等功能。短小的查询由守护程序执行，大的重的操作由YARN执行。</p>
<ul>
<li>支持使用HPL/SQL的存储过程</li>
</ul>
<p>支持使用变量、表达式、控制流声明、迭代来实现业务逻辑，支持使用异常处理程序和条件处理器来实现高级错误处理。</p>
<p>使用sql on hadoop更加动态：支持使用高级表达式、各种内置函数，基于用户配置、先前查询的结果、来自文件或者非hadoop数据源的数据、即时动态的生成SQL条件。</p>
<p>利用已有的存储过程SQL，提供函数和声明。</p>
<p>方便集成和支持多种类型数据仓库，可以实现单个脚本处理hadoop、RDBMS、Nossql等多个系统的数据。</p>
<ul>
<li>更智能的成本优化其CBO</li>
<li>提供全面的监控和诊断工具。hive server2的UI界面、LLAP 的UI、Tez的UI等。</li>
</ul>
<p>升级只需要升级hive的元数据库信息即可，2版本提供了升级脚本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hive-metastore/bin/schematool -upgradeSchema -dbType</div></pre></td></tr></table></figure></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






  <nav id="page-nav" class="clearfix">
    <a class="extend prev" rel="prev" href="/page/3/"><span></span>Prev</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/27/">27</a><a class="extend next" rel="next" href="/page/5/">Next<span></span></a>
  </nav>

</div>
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  


  

  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/youdaonote/" title="youdaonote">youdaonote<sup>209</sup></a></li>
			
		
			
				<li><a href="/tags/源码/" title="源码">源码<sup>10</sup></a></li>
			
		
			
				<li><a href="/tags/akka/" title="akka">akka<sup>9</sup></a></li>
			
		
			
				<li><a href="/tags/flume/" title="flume">flume<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/ETL/" title="ETL">ETL<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/solr/" title="solr">solr<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/spring/" title="spring">spring<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/调度平台/" title="调度平台">调度平台<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/azkaban/" title="azkaban">azkaban<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/mysql/" title="mysql">mysql<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/scala/" title="scala">scala<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/ambari/" title="ambari">ambari<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/quartz/" title="quartz">quartz<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/python/" title="python">python<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/ember/" title="ember">ember<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/nodejs/" title="nodejs">nodejs<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/R/" title="R">R<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/guava/" title="guava">guava<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/heroku/" title="heroku">heroku<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/hdfs/" title="hdfs">hdfs<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="https://github.com/willcup" target="_blank" title=" 我自己的github">github</a>
            
          </li>
        
          <li>
            
            	<a href="http://thisding.com" target="_blank" title="朋友的主页">Steven&#39;s Blog</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

  <div class="weiboshow">
  <p class="asidetitle">新浪微博</p>
    <iframe width="100%" height="119" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=null&verifier=&dpc=1"></iframe>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m Will Chen in MeiTuan. <br/>
			元 亨 利 贞.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
		<a href="mailto:chenxin15@meituan.com" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2017 
		
		<a href="/about" target="_blank" title="Will Chen">Will Chen</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>










<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3Fe6d1f421bbc9962127a50488f9ed37d1' type='text/javascript'%3E%3C/script%3E"));
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
 </html>
