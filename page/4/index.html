
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <script type="text/javascript">
    (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
    })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');
    
    _st('install','yNiKTKaAnwd1uuxVMfiE','2.0.0');
  </script>
  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?5b99dfd487346155d274c0c49c3fb869";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
  </script>

  
    <title>Will&#39;s Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Will Chen">
    

    
    <meta name="description" content="左右水色 右手天光">
<meta property="og:type" content="website">
<meta property="og:title" content="Will's Blog">
<meta property="og:url" content="https://runningdata.github.io/page/4/index.html">
<meta property="og:site_name" content="Will's Blog">
<meta property="og:description" content="左右水色 右手天光">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Will's Blog">
<meta name="twitter:description" content="左右水色 右手天光">

    
    <link rel="alternative" href="/atom.xml" title="Will&#39;s Blog" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="Will&#39;s Blog" title="Will&#39;s Blog"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Will&#39;s Blog">Will&#39;s Blog</a></h1>
				<h2 class="blog-motto">简易 变易 不易</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">首页</a></li>
					
						<li><a href="/archives">归档</a></li>
					
						<li><a href="/about">关于</a></li>
					
					<li>
 					
                                                <form class="search" action="/search/index.html" method="get" accept-charset="utf-8" target="_blank">
                                                        <label>搜索</label>
                                                <input name="s" type="hidden" value= null ><input type="text" class="st-default-search-input" name="q" size="30" placeholder="搜索"><br>
                                                </form>
					
					</li>
				</ul>
			</nav>			
</div>

    </header>
    <div id="container">
      <div id="main">

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/21/flink的window/" title="flink的window" itemprop="url">flink的window</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-21T07:28:54.000Z" itemprop="datePublished"> 发表于 2017-11-21</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>滑动窗口,sliding windows，比如我们每30s统计一下上一分钟的和。<br><img src="https://flink.apache.org/img/blog/window-intro/window-sliding-window.png" alt=""></p>
<p>当只有一个窗口处理器的时候，我们就只能串行处理一个数据流。每个流里的书都要去向某个指定的window。在Flink中对于Windows on a full stream are【一个完整的流的窗口】 称为 AllWindows。对很多app来说，数据流都要分发进入多个逻辑流，然后会有window operator处理每个逻辑流。假设我们从多个交通传感器获取交通工具的流量，每个交通传感器都监控不同地址的流量。我们可以把这些信息流通过交通传感器的id进行分组，然后分别并发的计算每个交通传感器所在位置的流量信息。在Flink中，我们把这种partitioned window叫做simple window，因为这是对分布式数据流很常见的处理方式。下图展示了一个通过(sernsorID, count)的流进行数据收集的滚动窗口<br><img src="https://flink.apache.org/img/blog/window-intro/windows-keyed.png" alt=""></p>
<p>通常，一个window在无穷的数据流中定义了一组有穷数据。这组数据可以是基于时间、计数、时间与技术结合、自定义的一些逻辑去分window。Flink的DataStream API提供了简洁的操作供常用的窗口操作，也留了接口让用户提供自定义的分窗口的逻辑。下面我们详细看一下基于时间与计数的窗口机制。</p>
<h2 id="基于时间的窗口"><a href="#基于时间的窗口" class="headerlink" title="基于时间的窗口"></a>基于时间的窗口</h2><p>下面是一个每分钟滚动一次的窗口，对所有的数据执行某个函数操作。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">// (sensorId, carCnt)形式的数据流</div><div class="line">val vehicleCnts: DataStream[(Int, Int)] = ...</div><div class="line"></div><div class="line">// 0，1是在数据中的位置</div><div class="line">val tumblingCnts: DataStream[(Int, Int)] = vehicleCnts</div><div class="line">  // 通过sensorId分区</div><div class="line">  .keyBy(0) </div><div class="line">  // 1分钟的窗口时间</div><div class="line">  .timeWindow(Time.minutes(1))</div><div class="line">  // 计算carCnt的和</div><div class="line">  .sum(1) </div><div class="line"></div><div class="line">val slidingCnts: DataStream[(Int, Int)] = vehicleCnts</div><div class="line">  .keyBy(0) </div><div class="line">  // 每30秒触发一次1分钟的数据窗口的执行</div><div class="line">  .timeWindow(Time.minutes(1), Time.seconds(30))</div><div class="line">  .sum(1)</div></pre></td></tr></table></figure></p>
<p>还有一个时间的概念我们要说明</p>
<ul>
<li>processing time。窗口是根据当前主机的1分钟去构建与计算窗口内数据的。</li>
<li>event time。event产生时的时间。相比processing time更好一些</li>
<li>Ingestion time。是processing  time和event time的杂交品种。一旦数据到达，就把当前机器的时间戳赋给这个数据记录，然后基于这个时间戳，使用event time去持续处理。</li>
</ul>
<h2 id="基于计数的窗口"><a href="#基于计数的窗口" class="headerlink" title="基于计数的窗口"></a>基于计数的窗口</h2><p>一个100个event作为窗口的程序。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">// (sensorId, carCnt)形式的数据流</div><div class="line">val vehicleCnts: DataStream[(Int, Int)] = ...</div><div class="line"></div><div class="line">val tumblingCnts: DataStream[(Int, Int)] = vehicleCnts</div><div class="line">  // 用sensorId分区</div><div class="line">  .keyBy(0)</div><div class="line">  // 100个数据为一个窗口</div><div class="line">  .countWindow(100)</div><div class="line">  .sum(1)</div><div class="line"></div><div class="line">val slidingCnts: DataStream[(Int, Int)] = vehicleCnts</div><div class="line">  .keyBy(0)</div><div class="line">  // 100个数据作为一个窗口，每10个触发一次窗口处理</div><div class="line">  .countWindow(100, 10)</div><div class="line">  .sum(1)</div></pre></td></tr></table></figure></p>
<h2 id="深入了解"><a href="#深入了解" class="headerlink" title="深入了解"></a>深入了解</h2><p>Flink内置的基于时间、计数的窗口已经覆盖了大多数的应用，但是对于一些需要自定义窗口划分逻辑的，需要使用DataStream API暴露的接口，这些接口给了窗口构建与计算的很有条理的控制方式。</p>
<p>下图是Flink窗口机制的详细图<br><img src="https://flink.apache.org/img/blog/window-intro/window-mechanics.png" alt=""></p>
<p>到达window operator的数据会先发给<code>WindowAssigner</code>. <code>WindowAssigner</code>把数据分配给一个或者多个window，也有可能要创建新的window。一个<code>Window</code>是一个一组数据、元数据(对于<code>TimeWindow</code>来说是起止时间)的唯一标识符。注意数据是可以被加入到多个window的，也就是说可能会同时存在多个window。</p>
<p>每个window拥有一个<code>Trigger</code>，它来决定当前window什么时候计算或者清空。这个trigger在每条数据到来的时候都会检验，如果前面注册的timer超时就会触发操作：执行计算、清空窗口、先计算再清空。<strong>如果只是触发计算，那么所有的数据就还留在window里</strong>，下次触发的时候还可以计算。<strong>一个window在被清空之前一直都可以被计算，这也代表着内存占用</strong>。</p>
<p>计算函数接收window的所有数据，输出一个或多个结果。DataStream API接受不同类型的计算函数，包括一些预定义的sum、min、max，ReduceFunction、FlodFunciton、WindowFunction等。最常见的是<code>WindowFunction</code>，它接收window对象的元数据，一组window对象，window key(如果是分区的window)作为参数。</p>
<p>这些组件构成了Flink的窗口机制。我们现在一步步看一下怎样实现自定义窗口逻辑。我们以DataStream[IN]类型的stream开始，用一个key选择器函数来抽取key，获得一个Keydtream[IN, KEY].<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">val input: DataStream[IN] = ...</div><div class="line"></div><div class="line">val keyed: KeyedStream[IN, KEY] = input</div><div class="line">  .keyBy(myKeySel: (IN) =&gt; KEY)</div><div class="line"></div><div class="line"></div><div class="line">// 通过WindowAssigner创建一个分窗口的stream。WindowAssigner 有默认的Trigger实现</div><div class="line">var windowed: WindowedStream[IN, KEY, WINDOW] = keyed</div><div class="line">  .window(myAssigner: WindowAssigner[IN, WINDOW])</div><div class="line">  </div><div class="line">// 不适用WindowAssigner默认的trigger</div><div class="line">windowed = windowed</div><div class="line">  .trigger(myTrigger: Trigger[IN, WINDOW])</div><div class="line"></div><div class="line">// 指定可选的evictor</div><div class="line">windowed = windowed</div><div class="line">  .evictor(myEvictor: Evictor[IN, WINDOW])</div><div class="line"></div><div class="line">// 最后，把window function传递给windowed stream</div><div class="line">val output: DataStream[OUT] = windowed</div><div class="line">  .apply(myWinFunc: WindowFunction[IN, OUT, KEY, WINDOW])</div></pre></td></tr></table></figure></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/20/centos上搭建ftp服务器/" title="centos上搭建ftp服务器" itemprop="url">centos上搭建ftp服务器</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-20T06:46:02.000Z" itemprop="datePublished"> 发表于 2017-11-20</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>首先安装服务：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install -y vsftpd</div></pre></td></tr></table></figure></p>
<p>创建只读的dataman用户：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">useradd -s /sbin/nologin dataman</div><div class="line">passwd dataman</div></pre></td></tr></table></figure></p>
<p>编辑配置文件<code>/etc/vsftpd/vsftpd.conf</code>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"># 修改默认端口</div><div class="line">listen_port=6888</div><div class="line"></div><div class="line"># 禁止匿名登陆</div><div class="line">anonymous_enable=NO</div><div class="line"></div><div class="line"># 指定用户单独的配置信息所在目录</div><div class="line">user_config_dir=/var/ftp</div><div class="line"></div><div class="line"># 不许用户登陆后切换目录</div><div class="line">chroot_local_user=YES</div></pre></td></tr></table></figure></p>
<p>然后到<code>/var/ftp</code>下新建dataman用户的ftp配置文件，这里只需要指定他的root目录就好了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">local_root=/server/files</div></pre></td></tr></table></figure></p>
<p>参考</p>
<ul>
<li><a href="https://jasonhzy.github.io/2016/03/11/linux-ftp/" target="_blank" rel="external">https://jasonhzy.github.io/2016/03/11/linux-ftp/</a></li>
<li><a href="http://cn.linux.vbird.org/linux_server/0410vsftpd.php" target="_blank" rel="external">http://cn.linux.vbird.org/linux_server/0410vsftpd.php</a></li>
</ul>
<p>坑</p>
<p>我们的网络原因导致，测试环境要连接线上的ftp服务器的话，需要通过一层运维提供的HAProxy代理。</p>
<p>这就引出了ftp服务器主动传输与被动传输的概念区别。</p>
<p>FTP协议有两种工作方式：PORT方式和PASV方式，中文意思为主动式和被动式。</p>
<p>PORT（主动）方式的连接过程是：客 户端向服务器的FTP端口（默认是21）发送连接请求，服务器接受连接，建立一条命令链路。当需要传送数据时，客户端在命令链路上用PORT命令告诉服务 器：“我打开了XXXX端口，你过来连接我”。于是服务器从20端口向客户端的XXXX端口发送连接请求，建立一条数据链路来传送数据。</p>
<p>PASV（被动）方式的连接过程是：客 户端向服务器的FTP端口（默认是21）发送连接请求，服务器接受连接，建立一条命令链路。当需要传送数据时，服务器在命令链路上用PASV命令告诉客户 端：“我打开了XXXX端口，你过来连接我”。于是客户端向服务器的XXXX端口发送连接请求，建立一条数据链路来传送数据。</p>
<h2 id="概括："><a href="#概括：" class="headerlink" title="概括： "></a>概括： </h2><p>主动模式：服务器向客户端敲门，然后客户端开门<br>被动模式：客户端向服务器敲门，然后服务器开门</p>
<p>所以，如果你是如果通过代理上网的话，就不能用主动模式，因为服务器敲的是上网代理服务器的门，而不是敲客户端的门<br>而且有时候，客户端也不是轻易就开门的，因为有防火墙阻挡，除非客户端开放大于1024的高端端口</p>
<p>vsftpd服务器端修改配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># passive</div><div class="line">tcp_wrappers=YES</div><div class="line">pasv_promiscuous=NO</div><div class="line"># 这个比较关键，10.103.70.27是我们的haproxy所在的IP</div><div class="line">pasv_address=10.103.70.27</div><div class="line">port_enable=YES</div><div class="line">port_promiscuous=NO</div><div class="line">pasv_enable=YES</div><div class="line">pasv_min_port=10000</div><div class="line">pasv_max_port=10010</div></pre></td></tr></table></figure></p>
<p>同时，HAProxy也需要配置到这些端口范围<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">listen ftp</div><div class="line">    bind *:6888,*:10000-10010</div><div class="line">    mode tcp</div><div class="line">    server ftpserver 10.2.19.62 check inter 3000 port 6888</div></pre></td></tr></table></figure></p>
<ul>
<li><a href="http://blog.sina.com.cn/s/blog_7f1d56650102v57p.html" target="_blank" rel="external">http://blog.sina.com.cn/s/blog_7f1d56650102v57p.html</a></li>
<li><a href="http://www.cnblogs.com/exclm/archive/2009/05/08/1452893.html" target="_blank" rel="external">http://www.cnblogs.com/exclm/archive/2009/05/08/1452893.html</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_5cdb72780100jwjt.html" target="_blank" rel="external">http://blog.sina.com.cn/s/blog_5cdb72780100jwjt.html</a></li>
<li><a href="https://serverfault.com/questions/441721/ftp-through-haproxy" target="_blank" rel="external">https://serverfault.com/questions/441721/ftp-through-haproxy</a></li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/16/ETL日常调度任务类型的思考/" title="ETL日常调度任务类型的思考" itemprop="url">ETL日常调度任务类型的思考</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-16T07:27:27.000Z" itemprop="datePublished"> 发表于 2017-11-16</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>对于有些需要等待上游非同质类型、而且是外部任务的任务方案：</p>
<h2 id="信号灯"><a href="#信号灯" class="headerlink" title="信号灯"></a>信号灯</h2><p>即所有的每个任务在完成之后，都设置一个信号灯，然后后面的任务需要此信号灯满足某个信号的时候才能触发执行。</p>
<p>信号灯的查看方式可以有多种：</p>
<ul>
<li>数据库访问，上游直接修改数据库，下游直接轮询数据库</li>
<li>rest接口访问，上有直接通过中心接口修改数据库，下游轮询一个中心接口</li>
<li>发布订阅模式，中间件设置eventbus</li>
</ul>
<p>执行：sql查询、接口与状态确认</p>
<h2 id="提供shell"><a href="#提供shell" class="headerlink" title="提供shell"></a>提供shell</h2><p>具体咋依赖，全都自己去写，这里啥也不限制，而且啥也不伺候</p>
<p>安全系数低</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/15/druid设计/" title="druid设计" itemprop="url">druid设计</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-15T06:28:59.000Z" itemprop="datePublished"> 发表于 2017-11-15</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="segment"><a href="#segment" class="headerlink" title="segment"></a>segment</h2><p>Druid的索引是存在segment文件中的，segment文件是按照时间分区的。一个segment文件对应一个时间间隔，时间间隔根据配置项<code>granularitySpec</code>里的<code>segmentGranularity</code>进行配置。推荐segment文件大小设置在300~700M之间。如果你的segment文件太大，那么请考虑修改时间间隔，或者为数据做分区，修改<code>partitioningSpec</code>的<code>targetPartitionSize</code>参数(可以试试五百万行)。</p>
<h4 id="文件数据结构"><a href="#文件数据结构" class="headerlink" title="文件数据结构"></a>文件数据结构</h4><p>segment是列式存储的：每一列都在不同的数据结构中。每个列都分开存储，druid就可以只访问查询应用到的列的数据。有三个基本的列类型：timestamp、维度、metric。</p>
<p><img src="http://druid.io/docs/img/druid-column-types.png" alt="实例"></p>
<p>timestamp和metric列比较简单：都是int或者float数组，使用LZ4算法压缩。一个query只要知道他需要查询那些行，就解压相关列的这部分文件，抽取对应的行，然后执行聚合计算操作即可。</p>
<p>dimension列有些不同，它要支持filter和groupby操作，所以需要下面三个数据结构</p>
<ul>
<li>一个字典，把值映射成int类型的id</li>
<li>使用上面字典编码的列值的list</li>
<li>列中每个不同的列指，都要弄一个bitmap对应所有的行，说明哪些行带有这个列指</li>
</ul>
<p>把原本的值映射成int的id是为了节省空间。上面第三个里的bitmap也就是倒排索引(inverted indexes)可以提供快速的过滤工作。最后，上面第二个结构里的值，是用来处理group by和topN拆线呢的。也就是说，基于filter的单独聚合指标不要要接触到第二个数据结构中的维度值。</p>
<p>基于上图中的数据，看一下例子，下面是针对列<code>Page</code>的<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">1: 映射编码的字典</div><div class="line">  &#123;</div><div class="line">    &quot;Justin Bieber&quot;: 0,</div><div class="line">    &quot;Ke$ha&quot;:         1</div><div class="line">  &#125;</div><div class="line"></div><div class="line">2: 按照1中映射后，这一列的字段值</div><div class="line">  [0,</div><div class="line">   0,</div><div class="line">   1,</div><div class="line">   1]</div><div class="line"></div><div class="line">3: 每一个或者说每一种列值都有自己的Bitmaps</div><div class="line">  value=&quot;Justin Bieber&quot;: [1,1,0,0]</div><div class="line">  value=&quot;Ke$ha&quot;:         [0,0,1,1]</div></pre></td></tr></table></figure></p>
<p>注意bitmap数据结构与前面个不同，前两个是随数据量线性增长的，而bitmap是数据量 * 每列各种值的个数。</p>
<h4 id="多值的列"><a href="#多值的列" class="headerlink" title="多值的列"></a>多值的列</h4><p>假设<code>Page</code>的第二行数据为<code>Ke$ha,Justin Bieber</code>，那么数据结构变化为下面：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">1: Dictionary that encodes column values</div><div class="line">  &#123;</div><div class="line">    &quot;Justin Bieber&quot;: 0,</div><div class="line">    &quot;Ke$ha&quot;:         1</div><div class="line">  &#125;</div><div class="line"></div><div class="line">2: Column data</div><div class="line">  [0,</div><div class="line">   [0,1],  &lt;--Row value of multi-value column can have array of values</div><div class="line">   1,</div><div class="line">   1]</div><div class="line"></div><div class="line">3: Bitmaps - one for each unique value</div><div class="line">  value=&quot;Justin Bieber&quot;: [1,1,0,0]</div><div class="line">  value=&quot;Ke$ha&quot;:         [0,1,1,1]</div><div class="line">                            ^</div><div class="line">                            |</div><div class="line">                            |</div><div class="line">    Multi-value column has multiple non-zero entries</div></pre></td></tr></table></figure></p>
<h4 id="命名约定"><a href="#命名约定" class="headerlink" title="命名约定"></a>命名约定</h4><p>segment文件的标识符一般是由数据源、开始时间、结束时间、版本构成的。如果数据在某个时间范围外还sharded了，那么也会带有一个分区数字。</p>
<p>例子：datasource_intervalStart_intervalEnd_version_partitionNum</p>
<h4 id="segment组件"><a href="#segment组件" class="headerlink" title="segment组件"></a>segment组件</h4><p>一个segment由几个文件组成</p>
<ul>
<li>version.bin。  4个字节，代表segment的version。</li>
<li>meta.smoosh。带有其他smoosh文件内容元数据(文件名、offset)的文件。</li>
<li>xxxx.smoosh。多个这种文件，都是二进制数据。</li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/15/hive2版本亮点/" title="hive2版本亮点" itemprop="url">hive2版本亮点</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-15T02:53:01.000Z" itemprop="datePublished"> 发表于 2017-11-15</time>
    
  </p>
</header>
    <div class="article-content">
        
        <ul>
<li>LLAP。</li>
</ul>
<p>Live Long and Process智能将数据缓存到多台机器的内存中，并允许所有客户端共享这些缓存的数据，同时保留了弹性伸缩能力。开启LLAP后，性能相比1版本提升25倍。</p>
<p>LLAP提供了一个高级的执行模式，他启用一个长时间存活的守护程序去和HDFS DataNode直接交互，也是一个紧密集成的DAG框架。这个守护程序中加入了缓存、预抓取、查询过程和访问控制等功能。短小的查询由守护程序执行，大的重的操作由YARN执行。</p>
<ul>
<li>支持使用HPL/SQL的存储过程</li>
</ul>
<p>支持使用变量、表达式、控制流声明、迭代来实现业务逻辑，支持使用异常处理程序和条件处理器来实现高级错误处理。</p>
<p>使用sql on hadoop更加动态：支持使用高级表达式、各种内置函数，基于用户配置、先前查询的结果、来自文件或者非hadoop数据源的数据、即时动态的生成SQL条件。</p>
<p>利用已有的存储过程SQL，提供函数和声明。</p>
<p>方便集成和支持多种类型数据仓库，可以实现单个脚本处理hadoop、RDBMS、Nossql等多个系统的数据。</p>
<ul>
<li>更智能的成本优化其CBO</li>
<li>提供全面的监控和诊断工具。hive server2的UI界面、LLAP 的UI、Tez的UI等。</li>
</ul>
<p>升级只需要升级hive的元数据库信息即可，2版本提供了升级脚本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hive-metastore/bin/schematool -upgradeSchema -dbType</div></pre></td></tr></table></figure></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/15/TPC-DS基准测试/" title="TPC-DS基准测试" itemprop="url">TPC-DS基准测试</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-15T02:44:25.000Z" itemprop="datePublished"> 发表于 2017-11-15</time>
    
  </p>
</header>
    <div class="article-content">
        
        <ul>
<li>测试数据加载<ul>
<li>系统准备</li>
<li>数据文件生成</li>
<li>测试数据库创建</li>
<li>基础表创建</li>
<li>数据加载</li>
<li>约束验证</li>
<li>辅助数据结构创建</li>
<li>表和辅助数据统计分析等</li>
</ul>
</li>
<li>查询顺序执行。power测试是单个查询的处理能力。</li>
<li>查询并行执行。throughput是并发查询的处理能力，分为数据查询与数据维护两个子步骤。</li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/09/sbt简记/" title="scalatra入门" itemprop="url">scalatra入门</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-09T08:08:49.000Z" itemprop="datePublished"> 发表于 2017-11-09</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h4 id="生成scalatra项目"><a href="#生成scalatra项目" class="headerlink" title="生成scalatra项目"></a>生成scalatra项目</h4><p>下载项目，并配置相关信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"># 从github上下载项目</div><div class="line">root@will-vm:/usr/local/will/learning# sbt new scalatra/scalatra.g8</div><div class="line">[info] Set current project to learning (in build file:/usr/local/will/learning/)</div><div class="line"># 用来发布项目的，一般就是反序域名[联想一下java包]</div><div class="line">organization [com.example]: com.will</div><div class="line"># scalatra app名字</div><div class="line">name [My Scalatra Web App]: willup</div><div class="line"># 项目版本，自己随便定义，比如0.0.1</div><div class="line">version [0.1.0-SNAPSHOT]: </div><div class="line"># 我们的servlet类的名字</div><div class="line">servlet_name [MyScalatraServlet]: Will</div><div class="line"># 所有的scala文件都属于一个pacakge</div><div class="line">package [com.example.app]: com.will.app</div><div class="line"># 使用的scala版本</div><div class="line">scala_version [2.12.3]: 2.12.1</div><div class="line"># 使用的sbt版本</div><div class="line">sbt_version [1.0.2]: 1.0.3</div><div class="line"># 使用的scalatra版本</div><div class="line">scalatra_version [2.5.4]: </div><div class="line"># 初始项目生成在willup目录了，有些像django</div><div class="line">Template applied in ./willup</div><div class="line">root@will-vm:/usr/local/will/learning# ll</div><div class="line">总用量 16</div><div class="line">drwxr-xr-x 4 root root 4096 11月  9 17:12 ./</div><div class="line">drwxr-xr-x 8 root root 4096 11月  9 16:06 ../</div><div class="line">drwxr-xr-x 3 root root 4096 11月  9 17:11 target/</div><div class="line">drwxr-xr-x 4 root root 4096 11月  9 17:12 willup/</div></pre></td></tr></table></figure></p>
<h4 id="构建"><a href="#构建" class="headerlink" title="构建"></a>构建</h4><p>进入willup, 执行<code>sbt</code>命令，sbt就会自动帮我们自动下载Scalatra的开发环境了，这需要些时间。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line">root@will-vm:/usr/local/will/learning/willup# sbt</div><div class="line">[info] Loading settings from plugins.sbt ...</div><div class="line">[info] Loading project definition from /usr/local/will/learning/willup/project</div><div class="line">[info] Updating &#123;file:/usr/local/will/learning/willup/project/&#125;willup-build...</div><div class="line">[info] downloading https://repo1.maven.org/maven2/com/amazonaws/jmespath-java/1.11.105/jmespath-java-1.11.105.jar ...</div><div class="line">[info] downloading https://repo.scala-sbt.org/scalasbt/sbt-plugin-releases/com.typesafe.sbt/sbt-twirl/scala_2.12/sbt_1.0/1.3.12/jars/sbt-twirl.jar ...</div><div class="line">[info] 	[SUCCESSFUL ] com.amazonaws#jmespath-java;1.11.105!jmespath-java.jar (824ms)</div><div class="line">[info] downloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar ...</div><div class="line">[info] 	[SUCCESSFUL ] com.typesafe.sbt#sbt-twirl;1.3.12!sbt-twirl.jar (3335ms)</div><div class="line">[info] downloading https://repo1.maven.org/maven2/org/scalatra/sbt/sbt-scalatra_2.12_1.0/1.0.1/sbt-scalatra-1.0.1.jar ...</div><div class="line">[info] 	[SUCCESSFUL ] org.apache.httpcomponents#httpclient;4.5.2!httpclient.jar (3126ms)</div><div class="line">[info] downloading https://repo1.maven.org/maven2/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar ...</div><div class="line">[info] 	[SUCCESSFUL ] org.scalatra.sbt#sbt-scalatra;1.0.1!sbt-scalatra.jar (1806ms)</div><div class="line">[info] downloading https://repo1.maven.org/maven2/com/typesafe/play/twirl-compiler_2.12/1.3.12/twirl-compiler_2.12-1.3.12.jar ...</div><div class="line">[info] 	[SUCCESSFUL ] com.typesafe.play#twirl-compiler_2.12;1.3.12!twirl-compiler_2.12.jar (883ms)</div><div class="line">[info] downloading https://repo1.maven.org/maven2/com/typesafe/play/twirl-api_2.12/1.3.12/twirl-api_2.12-1.3.12.jar ...</div><div class="line">[info] 	[SUCCESSFUL ] software.amazon.ion#ion-java;1.0.2!ion-java.jar(bundle) (1941ms)</div><div class="line">[info] downloading https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-databind/2.6.6/jackson-databind-2.6.6.jar ...</div><div class="line">[info] 	[SUCCESSFUL ] com.typesafe.play#twirl-api_2.12;1.3.12!twirl-api_2.12.jar (791ms)</div><div class="line">[info] downloading https://repo1.maven.org/maven2/com/typesafe/play/twirl-parser_2.12/1.3.12/twirl-parser_2.12-1.3.12.jar ...</div><div class="line">[info] 	[SUCCESSFUL ] com.typesafe.play#twirl-parser_2.12;1.3.12!twirl-parser_2.12.jar (866ms)</div><div class="line">[info] downloading https://repo.scala-sbt.org/scalasbt/sbt-plugin-releases/com.earldouglas/xsbt-web-plugin/scala_2.12/sbt_1.0/4.0.1/jars/xsbt-web-plugin.jar ...</div><div class="line">[info] 	[SUCCESSFUL ] com.fasterxml.jackson.core#jackson-databind;2.6.6!jackson-databind.jar(bundle) (2843ms)</div><div class="line">[info] downloading https://repo1.maven.org/maven2/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.6.6/jackson-dataformat-cbor-2.6.6.jar ...</div><div class="line">[info] 	[SUCCESSFUL ] com.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.6.6!jackson-dataformat-cbor.jar(bundle) (789ms)</div><div class="line">[info] downloading https://repo1.maven.org/maven2/joda-time/joda-time/2.8.1/joda-time-2.8.1.jar ...</div><div class="line">[info] 	[SUCCESSFUL ] com.earldouglas#xsbt-web-plugin;4.0.1!xsbt-web-plugin.jar (2691ms)</div><div class="line">[info] downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-elasticbeanstalk/1.11.105/aws-java-sdk-elasticbeanstalk-1.11.105.jar ...</div><div class="line">[info] 	[SUCCESSFUL ] joda-time#joda-time;2.8.1!joda-time.jar (1708ms)</div><div class="line">[info] downloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar ...</div><div class="line">[info] 	[SUCCESSFUL ] com.amazonaws#aws-java-sdk-elasticbeanstalk;1.11.105!aws-java-sdk-elasticbeanstalk.jar (1578ms)</div><div class="line">[info] downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-s3/1.11.105/aws-java-sdk-s3-1.11.105.jar ...</div><div class="line">[info] 	[SUCCESSFUL ] org.apache.httpcomponents#httpcore;4.4.4!httpcore.jar (1054ms)</div><div class="line">[info] downloading https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-annotations/2.6.0/jackson-annotations-2.6.0.jar ...</div><div class="line">[info] 	[SUCCESSFUL ] com.fasterxml.jackson.core#jackson-annotations;2.6.0!jackson-annotations.jar(bundle) (831ms)</div><div class="line">[info] downloading https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-core/2.6.6/jackson-core-2.6.6.jar ...</div><div class="line">[info] 	[SUCCESSFUL ] com.amazonaws#aws-java-sdk-s3;1.11.105!aws-java-sdk-s3.jar (1627ms)</div><div class="line">[info] downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-core/1.11.105/aws-java-sdk-core-1.11.105.jar ...</div><div class="line">[info] 	[SUCCESSFUL ] com.fasterxml.jackson.core#jackson-core;2.6.6!jackson-core.jar(bundle) (1238ms)</div><div class="line">[info] downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-kms/1.11.105/aws-java-sdk-kms-1.11.105.jar ...</div><div class="line">[info] 	[SUCCESSFUL ] com.amazonaws#aws-java-sdk-core;1.11.105!aws-java-sdk-core.jar (1825ms)</div><div class="line">[info] 	[SUCCESSFUL ] com.amazonaws#aws-java-sdk-kms;1.11.105!aws-java-sdk-kms.jar (1140ms)</div><div class="line">[info] Done updating.</div><div class="line">[info] Loading settings from build.sbt ...</div><div class="line">[info] Set current project to willup (in build file:/usr/local/will/learning/willup/)</div><div class="line">[info] sbt server started at 127.0.0.1:4841</div></pre></td></tr></table></figure>
<h4 id="Hello-world"><a href="#Hello-world" class="headerlink" title="Hello world"></a>Hello world</h4><p>到此为止Scalatra已经安装完了，咱们着手弄个小app吧。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/scala/">scala</a><a href="/tags/scalatra/">scalatra</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/09/scala集合视图/" title="scala集合视图" itemprop="url">scala集合视图</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-09T03:51:09.000Z" itemprop="datePublished"> 发表于 2017-11-09</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>场景：</p>
<ul>
<li>性能</li>
<li>像处理数据库视图一样处理集合</li>
</ul>
<p>视图就是推迟执行，该用多大内存还使用多大内存，该遍历多少元素还是遍历多少元素。说白了scala视图就跟数据库视图一样，不使用视图就跟数据库建立临时表一样。使用视图，当原始集合改变的时候，不需要重新跑transformers方法，使用视图则每次使用视图的时候都会跑一次transformers方法内容。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/08/ubuntu磁盘相关/" title="ubuntu磁盘相关" itemprop="url">ubuntu磁盘相关</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-08T06:40:17.000Z" itemprop="datePublished"> 发表于 2017-11-08</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>主要是自己工作用的ubuntu虚拟机因为最开始分配的磁盘不够，需要从外面额外扩展一下磁盘。</p>
<p>过程中，小小记录一下一些点，下次处理快一些。</p>
<h4 id="图形化磁盘分析工具"><a href="#图形化磁盘分析工具" class="headerlink" title="图形化磁盘分析工具"></a>图形化磁盘分析工具</h4><p>baobab，这个工具是ubuntu16里已经默认有了的。其实就类似du –max-depth=1 -h /，然后不用自己一层层去找所有目录的大小。它是一下子帮我们分析出所有的目录空间，当然时间就会长一些。相比命令行，优点当然就是查看与比较起来更加方便，快速定位到大磁盘，审慎地处理一些没用的数据。</p>
<p><img src="https://dn-linuxcn.qbox.me/data/attachment/album/201404/24/151605g7xh8uhk7a8b5suu.png" alt=""></p>
<p>当然，因为要统计所有目录空间大小，再呈现出来，所以速度会慢一些。</p>
<h4 id="图形化磁盘分区工具"><a href="#图形化磁盘分区工具" class="headerlink" title="图形化磁盘分区工具"></a>图形化磁盘分区工具</h4><p>通过vmware给虚拟机扩展磁盘到80以后，执行fdisk -l，发现并没有出现新的40G空间。</p>
<p>gparted, 这个需要额外通过apt进行安装。可以方便地完成磁盘格式化等操作，自己敲命令进行分区与格式化，会稍微有些不自信。</p>
<p><img src="http://1833.img.pp.sohu.com.cn/images/blog/2008/9/18/16/2/11d1b7819a1g213.jpg" alt=""></p>
<p>方案确认之后，点击上面的对勾，开始执行所有的变更操作。之后<code>fdisk -l</code>就可以看到新的空间了。</p>
<h4 id="挂载磁盘"><a href="#挂载磁盘" class="headerlink" title="挂载磁盘"></a>挂载磁盘</h4><p>一次性挂载，就使用mount命令就可以了。</p>
<p>永久的话，就需要编辑/etc/fstab了。但是在此之前，我们要通过<code>blkid</code>命令先获取到要挂载磁盘的UUID,，然后再添加下面内容。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">UUID=e23a1c1e-8d91-4df8-8fba-f0656a1080ab	/will_data	ext4	defaults,errors=remount-ro	0	1</div></pre></td></tr></table></figure>
<p>参考：</p>
<ul>
<li><a href="https://gist.github.com/gaoyifan/019ad7766f030ab5be50" target="_blank" rel="external">https://gist.github.com/gaoyifan/019ad7766f030ab5be50</a></li>
<li><a href="http://www.jianshu.com/p/ec5579ef15a6" target="_blank" rel="external">http://www.jianshu.com/p/ec5579ef15a6</a></li>
</ul>
<h4 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h4><p>妈蛋，后来发现是自己的Trash一直没有清空过….有5G的数据。清空后空间够了…..</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/07/hue中添加spark-shell的支持/" title="hue中添加spark-shell的支持" itemprop="url">hue中添加spark-shell的支持</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Will Chen" target="_blank" itemprop="author">Will Chen</a>
		
  <p class="article-time">
    <time datetime="2017-11-07T08:56:49.000Z" itemprop="datePublished"> 发表于 2017-11-07</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>计划： livy + hue + spark</p>
<p>通过ambari已经部署完成了livy，并且通过了curl的spark测试。</p>
<p>参考： <a href="http://gethue.com/how-to-use-the-livy-spark-rest-job-server-for-interactive-spark-2-2/" target="_blank" rel="external">http://gethue.com/how-to-use-the-livy-spark-rest-job-server-for-interactive-spark-2-2/</a></p>
<h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"># 修改spark配置</div><div class="line"></div><div class="line">[spark]</div><div class="line">  # Host address of the Livy Server.</div><div class="line">  livy_server_host=servicenode02.will.com</div><div class="line"></div><div class="line">  # Port of the Livy Server.</div><div class="line">  livy_server_port=8998</div><div class="line"></div><div class="line">  # Configure livy to start in local &apos;process&apos; mode, or &apos;yarn&apos; workers.</div><div class="line">  ivy_server_session_kind=yarn</div><div class="line"></div><div class="line">  # If livy should use proxy users when submitting a job.</div><div class="line">  ## livy_impersonation_enabled=true</div><div class="line"></div><div class="line">  # Host of the Sql Server</div><div class="line">  ## sql_server_host=localhost</div><div class="line"></div><div class="line">  # Port of the Sql Server</div><div class="line">  ## sql_server_port=10000</div><div class="line"></div><div class="line"></div><div class="line">[[[spark]]]</div><div class="line">  name=Scala</div><div class="line">  interface=livy</div><div class="line"></div><div class="line">[[[pyspark]]]</div><div class="line">  name=PySpark</div><div class="line">  interface=livy</div></pre></td></tr></table></figure>
<p>但是部署在hue中的时候，总是出现session问题, 在hue的example中下载了spark的测试notebook，执行pyspark的1+1+1时候出现提示</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">[07/Nov/2017 01:06:17 -0800] decorators   ERROR    error running &lt;function execute at 0x7f0ca465ae60&gt;</div><div class="line">Traceback (most recent call last):</div><div class="line">  File &quot;/server/hue/desktop/libs/notebook/src/notebook/decorators.py&quot;, line 81, in decorator</div><div class="line">    return func(*args, **kwargs)</div><div class="line">  File &quot;/server/hue/desktop/libs/notebook/src/notebook/api.py&quot;, line 109, in execute</div><div class="line">    response[&apos;handle&apos;] = get_api(request, snippet).execute(notebook, snippet)</div><div class="line">  File &quot;/server/hue/desktop/libs/notebook/src/notebook/connectors/spark_shell.py&quot;, line 194, in execute</div><div class="line">    raise e</div><div class="line">RestException: &quot;Session &apos;-1&apos; not found.&quot; (error 404)</div></pre></td></tr></table></figure>
<p>然后可以在livy server的rest api中看到session<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    &quot;from&quot;: 0,</div><div class="line">    &quot;total&quot;: 1,</div><div class="line">    &quot;sessions&quot;: [</div><div class="line">        &#123;</div><div class="line">            &quot;state&quot;: &quot;idle&quot;,</div><div class="line">            &quot;proxyUser&quot;: null,</div><div class="line">            &quot;id&quot;: 0,</div><div class="line">            &quot;kind&quot;: &quot;pyspark&quot;,</div><div class="line">            &quot;log&quot;: [</div><div class="line">                &quot;17/11/07 16:01:15 INFO SparkContext: Added file file:/usr/hdp/current/spark-client/python/lib/py4j-0.9-src.zip at file:/usr/hdp/current/spark-client/python/lib/py4j-0.9-src.zip with timestamp 1510041675612&quot;,</div><div class="line">                &quot;17/11/07 16:01:15 INFO Executor: Starting executor ID driver on host localhost&quot;,</div><div class="line">                &quot;17/11/07 16:01:15 INFO Utils: Successfully started service &apos;org.apache.spark.network.netty.NettyBlockTransferService&apos; on port 42523.&quot;,</div><div class="line">                &quot;17/11/07 16:01:15 INFO NettyBlockTransferService: Server created on 42523&quot;,</div><div class="line">                &quot;17/11/07 16:01:15 INFO BlockManagerMaster: Trying to register BlockManager&quot;,</div><div class="line">                &quot;17/11/07 16:01:15 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42523 with 511.1 MB RAM, BlockManagerId(driver, localhost, 42523)&quot;,</div><div class="line">                &quot;17/11/07 16:01:15 INFO BlockManagerMaster: Registered BlockManager&quot;,</div><div class="line">                &quot;17/11/07 16:01:16 WARN DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.&quot;,</div><div class="line">                &quot;17/11/07 16:01:16 INFO EventLoggingListener: Logging events to hdfs:///spark-history/local-1510041675669&quot;,</div><div class="line">                &quot;17/11/07 16:01:18 INFO ScalatraBootstrap: Calling http://servicenode02.will.com:8998/sessions/0/callback...&quot;</div><div class="line">            ]</div><div class="line">        &#125;</div><div class="line">    ]</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>点击recreate scala 的session后，发现scala代码是可以执行的。那么，我猜测，有可能pyspark也是一样的道理。</p>
<p>scala代码如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> data = <span class="type">Array</span>(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">45</span>,<span class="number">2</span>);</div><div class="line"><span class="keyword">val</span> disData = sc.parallelize(data);</div><div class="line">disData.map(s=&gt;s+<span class="number">1</span>).collect();</div></pre></td></tr></table></figure></p>
<p>而且观察到此时livy的sessions接口里的session也有了变化<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    &quot;from&quot;: 0,</div><div class="line">    &quot;total&quot;: 1,</div><div class="line">    &quot;sessions&quot;: [</div><div class="line">        &#123;</div><div class="line">            &quot;state&quot;: &quot;idle&quot;,</div><div class="line">            &quot;proxyUser&quot;: null,</div><div class="line">            &quot;id&quot;: 1,</div><div class="line">            &quot;kind&quot;: &quot;spark&quot;,</div><div class="line">            &quot;log&quot;: [</div><div class="line">                &quot;17/11/07 17:43:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2909 ms on localhost (5/8)&quot;,</div><div class="line">                ............</div><div class="line">                &quot;17/11/07 17:43:21 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:36806 in memory (size: 1257.0 B, free: 511.1 MB)&quot;</div><div class="line">            ]</div><div class="line">        &#125;</div><div class="line">    ]</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>到notebook的上面，点击pspark的recreate的地方，观察session变化：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    &quot;from&quot;: 0,</div><div class="line">    &quot;total&quot;: 2,</div><div class="line">    &quot;sessions&quot;: [</div><div class="line">        &#123;</div><div class="line">            &quot;state&quot;: &quot;idle&quot;,</div><div class="line">            &quot;proxyUser&quot;: null,</div><div class="line">            &quot;id&quot;: 2,</div><div class="line">            &quot;kind&quot;: &quot;pyspark&quot;,</div><div class="line">            &quot;log&quot;: [</div><div class="line">                &quot;17/11/07 17:45:18 INFO SparkContext: Added file file:/usr/hdp/current/spark-client/python/lib/py4j-0.9-src.zip at file:/usr/hdp/current/spark-client/python/lib/py4j-0.9-src.zip with timestamp 1510047918034&quot;,</div><div class="line">                .......</div><div class="line">                &quot;17/11/07 17:45:24 INFO ScalatraBootstrap: Calling http://servicenode02.will.com:8998/sessions/2/callback...&quot;</div><div class="line">            ]</div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line">            &quot;state&quot;: &quot;idle&quot;,</div><div class="line">            &quot;proxyUser&quot;: null,</div><div class="line">            &quot;id&quot;: 1,</div><div class="line">            &quot;kind&quot;: &quot;spark&quot;,</div><div class="line">            &quot;log&quot;: [</div><div class="line">                &quot;17/11/07 17:43:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2909 ms on localhost (5/8)&quot;,</div><div class="line">                ......</div><div class="line">                &quot;17/11/07 17:43:21 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:36806 in memory (size: 1257.0 B, free: 511.1 MB)&quot;</div><div class="line">            ]</div><div class="line">        &#125;</div><div class="line">    ]</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>多了一个。好，那么再次去执行我们的代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">file = sc.textFile(<span class="string">"/apps/hive/warehouse/sample_08/sample_08"</span>)</div><div class="line"></div><div class="line">file = file.flatMap(<span class="keyword">lambda</span> line: line.split(<span class="string">"\t"</span>)).map(<span class="keyword">lambda</span> word: (word, <span class="number">1</span>)).reduceByKey(<span class="keyword">lambda</span> a, b: a + b)</div><div class="line"></div><div class="line"><span class="keyword">for</span> row <span class="keyword">in</span> file.collect()[:<span class="number">5</span>]:</div><div class="line">  <span class="keyword">print</span> row</div></pre></td></tr></table></figure>
<p>然后就可以了。哈哈</p>
<p>查看一下livy server的log<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">17/11/07 17:44:50 INFO SparkProcessBuilder: Running sh -c /usr/hdp/current/spark-client/bin/spark-submit</div><div class="line">--name Livy </div><div class="line">--jars /usr/hdp/current/livy-server/repl-jars/mime-util-2.1.3.jar,/usr/hdp/current/livy-server/repl-jars/jetty-io-9.2.10.v20150310.jar,/usr/hdp/current/livy-server/repl-jars/jetty-security-9.2.10.v20150310.jar,/usr/hdp/current/livy-server/repl-jars/jetty-util-9.2.10.v20150310.jar,/usr/hdp/current/livy-server/repl-jars/livy-api-0.2.0.2.4.2.0-258.jar,/usr/hdp/current/livy-server/repl-jars/livy-core-0.2.0.2.4.2.0-258.jar,/usr/hdp/current/livy-server/repl-jars/rl_2.10-0.4.10.jar,/usr/hdp/current/livy-server/repl-jars/async-http-client-1.9.33.jar,/usr/hdp/current/livy-server/repl-jars/jetty-server-9.2.10.v20150310.jar,/usr/hdp/current/livy-server/repl-jars/commons-codec-1.9.jar,/usr/hdp/current/livy-server/repl-jars/joda-convert-1.6.jar,/usr/hdp/current/livy-server/repl-jars/scalatra-json_2.10-2.3.0.jar,/usr/hdp/current/livy-server/repl-jars/kryo-2.22.jar,/usr/hdp/current/livy-server/repl-jars/joda-time-2.3.jar,/usr/hdp/current/livy-server/repl-jars/grizzled-slf4j_2.10-1.0.2.jar,/usr/hdp/current/livy-server/repl-jars/scalatra-common_2.10-2.3.0.jar,/usr/hdp/current/livy-server/repl-jars/livy-client-common-0.2.0.2.4.2.0-258.jar,/usr/hdp/current/livy-server/repl-jars/livy-repl-0.2.0.2.4.2.0-258.jar,/usr/hdp/current/livy-server/repl-jars/jetty-http-9.2.10.v20150310.jar,/usr/hdp/current/livy-server/repl-jars/jetty-servlet-9.2.10.v20150310.jar,/usr/hdp/current/livy-server/repl-jars/scalatra_2.10-2.3.0.jar,/usr/hdp/current/livy-server/repl-jars/juniversalchardet-1.0.3.jar,/usr/hdp/current/livy-server/repl-jars/javax.servlet-api-3.1.0.jar,/usr/hdp/current/livy-server/repl-jars/netty-3.10.5.Final.jar </div><div class="line">--files /usr/hdp/current/spark-client/python/lib/pyspark.zip,/usr/hdp/current/spark-client/python/lib/py4j-0.9-src.zip </div><div class="line">--class com.cloudera.livy.repl.Main --conf spark.executor.memory=1G --conf spark.driver.memory=1G </div><div class="line">--conf spark.submit.pyFiles=/usr/hdp/current/spark-client/python/lib/pyspark.zip,/usr/hdp/current/spark-client/python/lib/py4j-0.9-src.zip </div><div class="line">--conf spark.driver.cores=1 </div><div class="line">--conf spark.livy.callbackUrl=http://servicenode02.will.com:8998/sessions/2/callback </div><div class="line">--conf spark.livy.port=0 </div><div class="line">--conf spark.yarn.isPython=true </div><div class="line">--conf spark.executor.cores=1 </div><div class="line">--queue default </div><div class="line">spark-internal pyspark</div><div class="line">17/11/07 17:44:50 INFO SessionManager: Registering new session 2</div></pre></td></tr></table></figure></p>
<p>竟然没有提交到yarn上执行！！上面的参数我们明明配置了yarn啊。再查一下livy server的<a href="https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.6.2/bk_command-line-installation/content/configure_livy2.html" target="_blank" rel="external">相关配置信息</a>。</p>
<p>到ambari添加配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">livy.spark.master=yarn-cluster</div></pre></td></tr></table></figure></p>
<p>重启。并没有生效。</p>
<p>看下配置，竟然是这样的<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">livy.environment production</div><div class="line">livy.impersonation.enabled false</div><div class="line">livy.server.port 8998</div><div class="line">livy.server.session.timeout 3600000</div><div class="line">livy.spark.master yarn-cluster</div></pre></td></tr></table></figure></p>
<p>中间的等号都没有了。</p>
<p>手动修改，暂时不用ambari了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">livy.environment =production</div><div class="line">livy.impersonation.enabled= false</div><div class="line">livy.server.port= 8998</div><div class="line">livy.server.session.timeout =3600000</div><div class="line">livy.spark.master= yarn-cluster</div></pre></td></tr></table></figure></p>
<p>而且通过<code>ps -ef | grep livy</code>发现，ambari 2.2.2.0的livy对于stop并不完整，会有泄露问题存在。虽然livy server关掉了，但是它打开的spark进程却仍然存在。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    

    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/youdaonote/">youdaonote</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






  <nav id="page-nav" class="clearfix">
    <a class="extend prev" rel="prev" href="/page/3/"><span></span>Prev</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/24/">24</a><a class="extend next" rel="next" href="/page/5/">Next<span></span></a>
  </nav>

</div>
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  


  

  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/youdaonote/" title="youdaonote">youdaonote<sup>187</sup></a></li>
			
		
			
				<li><a href="/tags/源码/" title="源码">源码<sup>10</sup></a></li>
			
		
			
				<li><a href="/tags/akka/" title="akka">akka<sup>9</sup></a></li>
			
		
			
				<li><a href="/tags/flume/" title="flume">flume<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/ETL/" title="ETL">ETL<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/solr/" title="solr">solr<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/spring/" title="spring">spring<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/调度平台/" title="调度平台">调度平台<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/azkaban/" title="azkaban">azkaban<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/mysql/" title="mysql">mysql<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/scala/" title="scala">scala<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/ambari/" title="ambari">ambari<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/quartz/" title="quartz">quartz<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/nodejs/" title="nodejs">nodejs<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Solr/" title="Solr">Solr<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/guava/" title="guava">guava<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/heroku/" title="heroku">heroku<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/hdfs/" title="hdfs">hdfs<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/hue/" title="hue">hue<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/ElasticSearch/" title="ElasticSearch">ElasticSearch<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="https://github.com/willcup" target="_blank" title=" 我自己的github">github</a>
            
          </li>
        
          <li>
            
            	<a href="http://thisding.com" target="_blank" title="朋友的主页">Steven&#39;s Blog</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

  <div class="weiboshow">
  <p class="asidetitle">新浪微博</p>
    <iframe width="100%" height="119" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=null&verifier=&dpc=1"></iframe>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m Will Chen in MeiTuan. <br/>
			元 亨 利 贞.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
		<a href="mailto:chenxin15@meituan.com" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2017 
		
		<a href="/about" target="_blank" title="Will Chen">Will Chen</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>










<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3Fe6d1f421bbc9962127a50488f9ed37d1' type='text/javascript'%3E%3C/script%3E"));
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
 </html>
